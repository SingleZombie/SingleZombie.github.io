<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"zhouyifan.net","root":"/","scheme":"Mist","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="A foresighted strategist with big-picture thinking. 大局观选手。">
<meta property="og:type" content="website">
<meta property="og:title" content="周弈帆的博客">
<meta property="og:url" content="https://zhouyifan.net/page/6/index.html">
<meta property="og:site_name" content="周弈帆的博客">
<meta property="og:description" content="A foresighted strategist with big-picture thinking. 大局观选手。">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="Zhou Yifan">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://zhouyifan.net/page/6/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'en'
  };
</script>

  <title>周弈帆的博客</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">周弈帆的博客</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>About</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://zhouyifan.net/2022/07/24/20220717-chinese-internet/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Zhou Yifan">
      <meta itemprop="description" content="A foresighted strategist with big-picture thinking. 大局观选手。">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="周弈帆的博客">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/07/24/20220717-chinese-internet/" class="post-title-link" itemprop="url">从我的公众号被诬告抄袭想到的：中国互联网不配有未来</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-07-24 00:33:06" itemprop="dateCreated datePublished" datetime="2022-07-24T00:33:06+08:00">2022-07-24</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%9D%82%E8%B0%88/" itemprop="url" rel="index"><span itemprop="name">杂谈</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%9D%82%E8%B0%88/%E9%9A%8F%E7%AC%94/" itemprop="url" rel="index"><span itemprop="name">随笔</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>今天，刚收到公众号官方的两条通知，说我的文章涉嫌整合他人内容，被暂时取消原创声明功能。</p>
<p><img src="/2022/07/24/20220717-chinese-internet/1.jpg" alt></p>
<p>一开始，我还以为是系统的检测算法出了故障，赶紧低声下气地提交了申诉，说明全网上我的文章都是由我自己完成的。</p>
<p>当我回过头来阅读通知时，愕然发现了“经用户投诉且经平台审核”这几个字，一时间怒火中烧：哦，原来我是被诬告了。</p>
<p>我是两三个月前才在开始在公开媒体上创作的，对一些规则可能不熟。有些长期做自媒体的人或许会劝我：唉，这种事正常啊。只要去申诉，给你恢复就行了。而且你看，就封了两天，之后不就正常了？忍一忍就过去了。你不要玻璃心了。</p>
<p>是啊，从利益的角度来看，这件事不就是让我两天发不了“原创”的文章？两天过后一切损失都抹平了。</p>
<p>才怪呢。</p>
<p>这件事对我真正的影响，是损害了我的名誉。</p>
<p>说实话，你可以说我水平差劲，说我没钱没势，说我狂妄自大。背后说，当面讲，拿着个大喇叭对全国人民喊。我都会不以为然。</p>
<p>问题是，对于我的作品，对于我辛辛苦苦创作出来的受到了客观认可的作品，你不能诋毁它。甚至不是去挖苦文章的内容，而是拿最恶劣的抄袭来指控我。这是对我名声的侮辱，对所有有尊严的创作者的侮辱，也是你们创作平台自己的耻辱。</p>
<p>通知里说“有用户举报”。我不知道是不是真的有人举报。如果是真的，那我也奈何不了那个人。在这件事上，我是弱势的一方。我也不知道是谁干的，也没有受到什么严重的经济损失，没有任何追责的可能。可能别人就是觉得好玩，顺手按了个举报按钮呢？我除了骂一句“此人卑鄙无耻”以外，也做不了什么。</p>
<p>真正有问题的是微信公众号的官方。你们的审核人员心慵意懒，玩忽职守。手握审核大权而不知善用，身着公正之衣而不辩是非。不察之下竟把抄袭之罪强加于光明磊落的原创作者，以至于颠倒是非，污人清白，真是岂有此理！</p>
<p>你以为你们平台做起来靠的是什么？靠的是你们掌握的数以亿计的流量？别开玩笑了。给你们带来价值的，是会下金蛋的鸡。看着满棚的金鸡，几位手持饲料的奴仆倒好像也长出了翅膀，以为自己也能下出金蛋一般，觉得随手杀掉一两只鸡也无所谓。真是可笑至极。</p>
<p>我这里还要好心奉劝一下所有的创作平台，烦请你们给审核人员的评估指标中加一个错审率，加大造成冤情的惩罚。同时，在认定冤情的申诉通过后，把“对不起”三个大字好好地打在私信里。</p>
<p>仔细一想，这事也怪不了公众号平台，整个环境毕竟就是这样的。</p>
<p>每天在平台上发送的内容那么多，审核员能够把每篇文章都过一遍都实属不易，出几个纰漏也是情理之中。这些道理我肯定都懂，也可以理解。</p>
<p>但趁着这口气，我还要发表一下对于中国内容创作平台的看法。</p>
<p>以前，去网上查编程知识的时候，查出来的全是低劣的复制粘贴文章。想要搜个教程，还要跳过那万年不变的前几个网站，去后面几个搜索结果的跟帖中翻出学习资源来。想在网络中找精品资源，可谓是沙里淘金，海底捞针。</p>
<p>现在，我学有小成，想在网上分享一些学习的心得。可是，又关注者寥寥。</p>
<p>是我不会用搜索引擎吗？是我写不出好的文章吗？</p>
<p>我看，是这个互联网的运行机制有问题啊。</p>
<p>在“后来者居上”的论坛中，优秀的帖子还是会被顶起，随后贴上“精品”的标签，供后人赏读。</p>
<p>而在以推荐机制为主的封闭创作平台当道之后，本来就稀有的精品内容便沉入了泥潭之下。只推荐自己喜欢的内容，有谁不乐意呢？坐揽着源源不断的流量，那哪平台不开心呢？这就是大势所趋啊。</p>
<p>平台只知道流量，只知道赚钱。但这也没有办法。很多平台看似规模宏大，实际上，他们还烧着投资人的钱，他们自己还身陷囹圄，入不敷出。因此，他们只能想尽一切办法，赶快扩大规模，赶快收割流量，赶快盈利。然而，哪怕真有一日，他们开始盈利了，也只会在只知道赚钱的道路上转不过弯，忘记了当年平台是怎么火起来的。</p>
<p>公益性地维护一个优质的内容平台。这种看上去吃力不讨好的事情，小平台不会做，大平台也不会做。</p>
<p>按他们这样下去，中国互联网上优质的文章只会越来越少见，看不到更好的未来啊。</p>
<p>质量和金钱，真的就是互斥的关系吗？</p>
<p>我看，只是运营这些平台的人太菜了吧。</p>
<p>一来，他们过于浮躁。在指定最优化目标时，只想到了赚钱，却不知道往里面加一点点的“情怀”。</p>
<p>二来，他们水平低下。但凡掺入了一些不赚钱的因素，就觉得要运营不下去了。</p>
<p>三来，他们目光短浅。以为创造没有利润的精品是在浪费时间，实际上有内涵的事物在多年后能够带来超出金钱的价值。</p>
<p>等我有钱了，我能够把这一切都做好。</p>
<p>我知道，十多年的寒窗苦读，对多数人来讲并不是什么愉快的经历。很多时候，并不是自己没有学好，而是教育的方法有问题。这一问题在大学之后尤为突出。倘若当年能够收获一些优质的知识，也不至于会走那么多的弯路。</p>
<p>等我有钱了，我会设法建立一个吸引优秀创作者的平台，把优质的内容结合并组织起来，把名声打响，让大家都能来这里学习。我不仅要做一些“公益”的事情，我还要赚钱，我要把平台持久地运营下去。我会扶正互联网的创作风气，还互联网一个蓬勃发展的未来。</p>
<p>在这篇文章里，我也只能随口嚷嚷。诸君把这些话当作笑谈即可。不过，在当下，我还是会慢慢地行动着，创作着。</p>
<p>如果未来优秀的中文内容越来越多，说不定不再是我们计算机学生抱着一堆机械工业出版社的黑书，而是美国的教授拿着一本本从中文英化过去的参考书。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://zhouyifan.net/2022/07/24/DLS-note-11-2/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Zhou Yifan">
      <meta itemprop="description" content="A foresighted strategist with big-picture thinking. 大局观选手。">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="周弈帆的博客">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/07/24/DLS-note-11-2/" class="post-title-link" itemprop="url">吴恩达《深度学习专项》代码实战（十一）：用 TensorFlow 实现 ResNet 并验证残差连接的有效性</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-07-24 00:31:40" itemprop="dateCreated datePublished" datetime="2022-07-24T00:31:40+08:00">2022-07-24</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">学习</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E5%AD%A6%E4%B9%A0/%E7%9F%A5%E8%AF%86%E8%AE%B0%E5%BD%95/" itemprop="url" rel="index"><span itemprop="name">知识记录</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>在这篇文章中，我会介绍如何用TensorFlow实现下面4个模型：</p>
<ol>
<li>ResNet-18</li>
<li>ResNet-18 无跳连</li>
<li>ResNet-50</li>
<li>ResNet-50 无跳连</li>
</ol>
<p>实现结束后，我会在一个简单的数据集上训练这4个模型。从实验结果中，我们能直观地看出ResNet中残差连接的作用。</p>
<p>项目链接：<a target="_blank" rel="noopener" href="https://github.com/SingleZombie/DL-Demos">https://github.com/SingleZombie/DL-Demos</a></p>
<p>主要代码在<code>dldemos/ResNet/tf_main.py</code>这个文件里。</p>
<h2 id="模型实现"><a href="#模型实现" class="headerlink" title="模型实现"></a>模型实现</h2><h3 id="主要结构"><a href="#主要结构" class="headerlink" title="主要结构"></a>主要结构</h3><p>ResNet中有跳连的结构，直接用<code>tf.keras.Sequenctial</code>串行模型不太方便。因此，我们要自己把模型的各模块连起来，对应的TensorFlow写法是这样的：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Initialize input</span></span><br><span class="line"><span class="built_in">input</span> = layers.Input(input_shape)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Get output</span></span><br><span class="line">output = ...</span><br><span class="line"></span><br><span class="line"><span class="comment"># Build model</span></span><br><span class="line">model = models.Model(inputs=<span class="built_in">input</span>, outputs=output)</span><br><span class="line"><span class="built_in">print</span>(model.summary())</span><br><span class="line"><span class="keyword">return</span> model</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>用<code>layers.Input</code>创建一个输入张量后，就可以对这个张量进行计算，并在最后用<code>tf.keras.models.Model</code>把和该张量相关的计算图搭起来。</p>
<p>接下来，我们看看这个<code>output</code>具体是怎么算出来的。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">init_model</span>(<span class="params"></span></span></span><br><span class="line"><span class="params"><span class="function">        input_shape=(<span class="params"><span class="number">224</span>, <span class="number">224</span>, <span class="number">3</span></span>), model_name=<span class="string">&#x27;ResNet18&#x27;</span>, use_shortcut=<span class="literal">True</span></span>):</span></span><br><span class="line">    <span class="comment"># Initialize input</span></span><br><span class="line">    <span class="built_in">input</span> = layers.Input(input_shape)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Get output</span></span><br><span class="line">    x = layers.Conv2D(<span class="number">64</span>, <span class="number">7</span>, (<span class="number">2</span>, <span class="number">2</span>), padding=<span class="string">&#x27;same&#x27;</span>)(<span class="built_in">input</span>)</span><br><span class="line">    x = layers.MaxPool2D((<span class="number">3</span>, <span class="number">3</span>), (<span class="number">2</span>, <span class="number">2</span>))(x)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> model_name == <span class="string">&#x27;ResNet18&#x27;</span>:</span><br><span class="line">        x = identity_block_2(x, <span class="number">3</span>, use_shortcut)</span><br><span class="line">        x = identity_block_2(x, <span class="number">3</span>, use_shortcut)</span><br><span class="line">        x = convolution_block_2(x, <span class="number">3</span>, <span class="number">128</span>, <span class="number">2</span>, use_shortcut)</span><br><span class="line">        x = identity_block_2(x, <span class="number">3</span>, use_shortcut)</span><br><span class="line">        x = convolution_block_2(x, <span class="number">3</span>, <span class="number">256</span>, <span class="number">2</span>, use_shortcut)</span><br><span class="line">        x = identity_block_2(x, <span class="number">3</span>, use_shortcut)</span><br><span class="line">        x = convolution_block_2(x, <span class="number">3</span>, <span class="number">512</span>, <span class="number">2</span>, use_shortcut)</span><br><span class="line">        x = identity_block_2(x, <span class="number">3</span>, use_shortcut)</span><br><span class="line">    <span class="keyword">elif</span> model_name == <span class="string">&#x27;ResNet50&#x27;</span>:</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">block_group</span>(<span class="params">x, fs1, fs2, count</span>):</span></span><br><span class="line">            x = convolution_block_3(x, <span class="number">3</span>, fs1, fs2, <span class="number">2</span>, use_shortcut)</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(count - <span class="number">1</span>):</span><br><span class="line">                x = identity_block_3(x, <span class="number">3</span>, fs1, fs2, use_shortcut)</span><br><span class="line">            <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">        x = block_group(x, <span class="number">64</span>, <span class="number">256</span>, <span class="number">3</span>)</span><br><span class="line">        x = block_group(x, <span class="number">128</span>, <span class="number">512</span>, <span class="number">4</span>)</span><br><span class="line">        x = block_group(x, <span class="number">256</span>, <span class="number">1024</span>, <span class="number">6</span>)</span><br><span class="line">        x = block_group(x, <span class="number">512</span>, <span class="number">2048</span>, <span class="number">3</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">raise</span> NotImplementedError(<span class="string">f&#x27;No such model <span class="subst">&#123;model_name&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    x = layers.AveragePooling2D((<span class="number">2</span>, <span class="number">2</span>), (<span class="number">2</span>, <span class="number">2</span>))(x)</span><br><span class="line">    x = layers.Flatten()(x)</span><br><span class="line">    output = layers.Dense(<span class="number">1</span>, <span class="string">&#x27;sigmoid&#x27;</span>)(x)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Build model</span></span><br><span class="line">    model = models.Model(inputs=<span class="built_in">input</span>, outputs=output)</span><br><span class="line">    <span class="built_in">print</span>(model.summary())</span><br><span class="line">    <span class="keyword">return</span> model</span><br></pre></td></tr></table></figure>
<p>构建模型时，我们需要给出输入张量的形状。同时，这个函数用<code>model_name</code>控制模型的结构，<code>use_shortcut</code>控制是否使用跳连。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">init_model</span>(<span class="params"></span></span></span><br><span class="line"><span class="params"><span class="function">        input_shape=(<span class="params"><span class="number">224</span>, <span class="number">224</span>, <span class="number">3</span></span>), model_name=<span class="string">&#x27;ResNet18&#x27;</span>, use_shortcut=<span class="literal">True</span></span>):</span></span><br></pre></td></tr></table></figure>
<p>在ResNet中，主要有两种残差块。</p>
<p><img src="/2022/07/24/DLS-note-11-2/1.jpg" alt></p>
<p>第一种是上图中实线连接的，这种残差块的输入输出形状相同，输入可以直接加到激活函数之前的输出上；第二种是上图中虚线连接的，这种残差块输入输出形状不同，需要用一个1x1卷积调整宽高和通道数。</p>
<p>此外，每种残差块用两种实现方式。</p>
<p><img src="/2022/07/24/DLS-note-11-2/2.jpg" alt></p>
<p>第一种实现方式如上图左半部分所示，这样的残差块由两个通道数相同的3x3卷积构成，只有一个需要决定的通道数；第二种实现方式采用了瓶颈(bottlenect)结构，先用1x1卷积降低了通道数，再进行3x3卷积，共有两个要决定的通道数（第1, 2个卷积和第3个卷积的通道数），如上图右半部分所示。</p>
<p>代码中，我用<code>identity_block_2</code>, <code>identity_block_3</code>分别表示输入输出相同的残差块的两种实现，<code>convolution_block_2</code>, <code>convolution_block_3</code>分别表示输入输出不同的残差块的两种实现。这些代码会在下一小节里给出。</p>
<p>现在，我们来看看该如何用这些模块构成ResNet-18和ResNet-50。首先，我们看一看原论文中这几个ResNet的结构图。</p>
<p><img src="/2022/07/24/DLS-note-11-2/3.jpg" alt></p>
<p>对于这两种架构，它们一开始都要经过一个大卷积层和一个池化层，最后都要做一次平均池化并输入全连接层。不同之处在于中间的卷积层。ResNet-18和ResNet-50使用了实现方式不同且个数不同的卷积层组。</p>
<p>在代码中，开始的大卷积及池化是这样写的：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x = layers.Conv2D(<span class="number">64</span>, <span class="number">7</span>, (<span class="number">2</span>, <span class="number">2</span>), padding=<span class="string">&#x27;same&#x27;</span>)(<span class="built_in">input</span>)</span><br><span class="line">x = layers.MaxPool2D((<span class="number">3</span>, <span class="number">3</span>), (<span class="number">2</span>, <span class="number">2</span>))(x)</span><br></pre></td></tr></table></figure>
<p>ResNet-18的实现是：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> model_name == <span class="string">&#x27;ResNet18&#x27;</span>:</span><br><span class="line">    x = identity_block_2(x, <span class="number">3</span>, use_shortcut)</span><br><span class="line">    x = identity_block_2(x, <span class="number">3</span>, use_shortcut)</span><br><span class="line">    x = convolution_block_2(x, <span class="number">3</span>, <span class="number">128</span>, <span class="number">2</span>, use_shortcut)</span><br><span class="line">    x = identity_block_2(x, <span class="number">3</span>, use_shortcut)</span><br><span class="line">    x = convolution_block_2(x, <span class="number">3</span>, <span class="number">256</span>, <span class="number">2</span>, use_shortcut)</span><br><span class="line">    x = identity_block_2(x, <span class="number">3</span>, use_shortcut)</span><br><span class="line">    x = convolution_block_2(x, <span class="number">3</span>, <span class="number">512</span>, <span class="number">2</span>, use_shortcut)</span><br><span class="line">    x = identity_block_2(x, <span class="number">3</span>, use_shortcut)</span><br></pre></td></tr></table></figure>
<p>其中，<code>identity_block_2</code>的参数分别为输入张量、卷积核边长、是否使用短路。<code>convolution_block_2</code>的参数分别为输入张量、卷积核边长、输出通道数、步幅、是否使用短路。</p>
<p>ResNet-50的实现是：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">elif</span> model_name == <span class="string">&#x27;ResNet50&#x27;</span>:</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">block_group</span>(<span class="params">x, fs1, fs2, count</span>):</span></span><br><span class="line">        x = convolution_block_3(x, <span class="number">3</span>, fs1, fs2, <span class="number">2</span>, use_shortcut)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(count - <span class="number">1</span>):</span><br><span class="line">            x = identity_block_3(x, <span class="number">3</span>, fs1, fs2, use_shortcut)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">    x = block_group(x, <span class="number">64</span>, <span class="number">256</span>, <span class="number">3</span>)</span><br><span class="line">    x = block_group(x, <span class="number">128</span>, <span class="number">512</span>, <span class="number">4</span>)</span><br><span class="line">    x = block_group(x, <span class="number">256</span>, <span class="number">1024</span>, <span class="number">6</span>)</span><br><span class="line">    x = block_group(x, <span class="number">512</span>, <span class="number">2048</span>, <span class="number">3</span>)</span><br></pre></td></tr></table></figure>
<p>其中，<code>identity_block_3</code>的参数分别为输入张量、卷积核边长、中间和输出通道数、是否使用短路。<code>convolution_block_3</code>的参数分别为输入张量、卷积核边长、中间和输出通道数、步幅、是否使用短路。</p>
<p>最后是计算分类输出的代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">x = layers.AveragePooling2D((<span class="number">2</span>, <span class="number">2</span>), (<span class="number">2</span>, <span class="number">2</span>))(x)</span><br><span class="line">x = layers.Flatten()(x)</span><br><span class="line">output = layers.Dense(<span class="number">1</span>, <span class="string">&#x27;sigmoid&#x27;</span>)(x)</span><br></pre></td></tr></table></figure>
<h3 id="残差块实现"><a href="#残差块实现" class="headerlink" title="残差块实现"></a>残差块实现</h3><p><img src="/2022/07/24/DLS-note-11-2/4.jpg" alt></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">identity_block_2</span>(<span class="params">x, f, use_shortcut=<span class="literal">True</span></span>):</span></span><br><span class="line">    _, _, _, C = x.shape</span><br><span class="line">    x_shortcut = x</span><br><span class="line">    x = layers.Conv2D(C, f, padding=<span class="string">&#x27;same&#x27;</span>)(x)</span><br><span class="line">    x = layers.BatchNormalization(axis=<span class="number">3</span>)(x)</span><br><span class="line">    x = layers.ReLU()(x)</span><br><span class="line">    x = layers.Conv2D(C, f, padding=<span class="string">&#x27;same&#x27;</span>)(x)</span><br><span class="line">    x = layers.BatchNormalization(axis=<span class="number">3</span>)(x)</span><br><span class="line">    <span class="keyword">if</span> use_shortcut:</span><br><span class="line">        x = x + x_shortcut</span><br><span class="line">    x = layers.ReLU()(x)</span><br><span class="line">    <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>
<p><img src="/2022/07/24/DLS-note-11-2/5.jpg" alt></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">convolution_block_2</span>(<span class="params">x, f, filters, s: <span class="built_in">int</span>, use_shortcut=<span class="literal">True</span></span>):</span></span><br><span class="line">    x_shortcut = x</span><br><span class="line">    x = layers.Conv2D(filters, f, strides=(s, s), padding=<span class="string">&#x27;same&#x27;</span>)(x)</span><br><span class="line">    x = layers.BatchNormalization(axis=<span class="number">3</span>)(x)</span><br><span class="line">    x = layers.ReLU()(x)</span><br><span class="line">    x = layers.Conv2D(filters, f, padding=<span class="string">&#x27;same&#x27;</span>)(x)</span><br><span class="line">    x = layers.BatchNormalization(axis=<span class="number">3</span>)(x)</span><br><span class="line">    <span class="keyword">if</span> use_shortcut:</span><br><span class="line">        x_shortcut = layers.Conv2D(filters, <span class="number">1</span>, strides=(s, s),</span><br><span class="line">                                   padding=<span class="string">&#x27;valid&#x27;</span>)(x_shortcut)</span><br><span class="line">        x_shortcut = layers.BatchNormalization(axis=<span class="number">3</span>)(x_shortcut)</span><br><span class="line">        x = x + x_shortcut</span><br><span class="line">    x = layers.ReLU()(x)</span><br><span class="line">    <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>
<p><img src="/2022/07/24/DLS-note-11-2/6.jpg" alt></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">identity_block_3</span>(<span class="params">x, f, filters1, filters2, use_shortcut=<span class="literal">True</span></span>):</span></span><br><span class="line">    x_shortcut = x</span><br><span class="line">    x = layers.Conv2D(filters1, <span class="number">1</span>, padding=<span class="string">&#x27;valid&#x27;</span>)(x)</span><br><span class="line">    x = layers.BatchNormalization(axis=<span class="number">3</span>)(x)</span><br><span class="line">    x = layers.Conv2D(filters1, f, padding=<span class="string">&#x27;same&#x27;</span>)(x)</span><br><span class="line">    x = layers.BatchNormalization(axis=<span class="number">3</span>)(x)</span><br><span class="line">    x = layers.ReLU()(x)</span><br><span class="line">    x = layers.Conv2D(filters2, <span class="number">1</span>, padding=<span class="string">&#x27;valid&#x27;</span>)(x)</span><br><span class="line">    x = layers.BatchNormalization(axis=<span class="number">3</span>)(x)</span><br><span class="line">    <span class="keyword">if</span> use_shortcut:</span><br><span class="line">        x = x + x_shortcut</span><br><span class="line">    x = layers.ReLU()(x)</span><br><span class="line">    <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>
<p><img src="/2022/07/24/DLS-note-11-2/7.jpg" alt></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">convolution_block_3</span>(<span class="params">x, f, filters1, filters2, s: <span class="built_in">int</span>, use_shortcut=<span class="literal">True</span></span>):</span></span><br><span class="line">    x_shortcut = x</span><br><span class="line">    x = layers.Conv2D(filters1, <span class="number">1</span>, strides=(s, s), padding=<span class="string">&#x27;valid&#x27;</span>)(x)</span><br><span class="line">    x = layers.BatchNormalization(axis=<span class="number">3</span>)(x)</span><br><span class="line">    x = layers.Conv2D(filters1, f, padding=<span class="string">&#x27;same&#x27;</span>)(x)</span><br><span class="line">    x = layers.BatchNormalization(axis=<span class="number">3</span>)(x)</span><br><span class="line">    x = layers.ReLU()(x)</span><br><span class="line">    x = layers.Conv2D(filters2, <span class="number">1</span>, padding=<span class="string">&#x27;valid&#x27;</span>)(x)</span><br><span class="line">    x = layers.BatchNormalization(axis=<span class="number">3</span>)(x)</span><br><span class="line">    <span class="keyword">if</span> use_shortcut:</span><br><span class="line">        x_shortcut = layers.Conv2D(filters2, <span class="number">1</span>, strides=(s, s),</span><br><span class="line">                                   padding=<span class="string">&#x27;same&#x27;</span>)(x_shortcut)</span><br><span class="line">        x_shortcut = layers.BatchNormalization(axis=<span class="number">3</span>)(x_shortcut)</span><br><span class="line">        x = x + x_shortcut</span><br><span class="line">    x = layers.ReLU()(x)</span><br><span class="line">    <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>
<p>这些代码中有一个细节要注意：在<code>convolution_block_3</code>中，<code>stride=2</code>是放在第一个还是第二个卷积层中没有定论。不同框架似乎对此有不同的实现方式。这里是把它放到了第一个1x1卷积里。</p>
<h2 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h2><p>在这个项目中，我已经准备好了数据集预处理的代码。可以轻松地生成数据集并用TensorFlow训练模型。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span>():</span></span><br><span class="line">    train_X, train_Y, test_X, test_Y = get_cat_set(</span><br><span class="line">        <span class="string">&#x27;dldemos/LogisticRegression/data/archive/dataset&#x27;</span>,</span><br><span class="line">        train_size=<span class="number">500</span>,</span><br><span class="line">        test_size=<span class="number">50</span>)</span><br><span class="line">    <span class="built_in">print</span>(train_X.shape)  <span class="comment"># (m, 224, 224, 3)</span></span><br><span class="line">    <span class="built_in">print</span>(train_Y.shape)  <span class="comment"># (m , 1)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">#model = init_model()</span></span><br><span class="line">    <span class="comment">#model = init_model(use_shortcut=False)</span></span><br><span class="line">    model = init_model(model_name=<span class="string">&#x27;ResNet50&#x27;</span>)</span><br><span class="line">    <span class="comment"># model = init_model(model_name=&#x27;ResNet50&#x27;, use_shortcut=False)</span></span><br><span class="line">    model.<span class="built_in">compile</span>(optimizer=<span class="string">&#x27;adam&#x27;</span>,</span><br><span class="line">                  loss=<span class="string">&#x27;binary_crossentropy&#x27;</span>,</span><br><span class="line">                  metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line"></span><br><span class="line">    model.fit(train_X, train_Y, epochs=<span class="number">20</span>, batch_size=<span class="number">16</span>)</span><br><span class="line">    model.evaluate(test_X, test_Y)</span><br></pre></td></tr></table></figure>
<p>为了让训练尽快结束，我只训了20个epoch，且使用的数据集比较小。我在ResNet-18中使用了3000个训练样本，ResNet-50中使用了1000个训练样本。数据的多少不影响对比结果，我们只需要知道模型的训练误差，便足以比较这四个模型了。</p>
<p>以下是我在四个实验中得到的结果。</p>
<p><strong>ResNet-18</strong><br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line">Epoch 1/20</span><br><span class="line">63/63 [==============================] - 75s 1s/step - loss: 1.9463 - accuracy: 0.5485</span><br><span class="line">Epoch 2/20</span><br><span class="line">63/63 [==============================] - 71s 1s/step - loss: 0.9758 - accuracy: 0.5423</span><br><span class="line">Epoch 3/20</span><br><span class="line">63/63 [==============================] - 81s 1s/step - loss: 0.8490 - accuracy: 0.5941</span><br><span class="line">Epoch 4/20</span><br><span class="line">63/63 [==============================] - 73s 1s/step - loss: 0.8309 - accuracy: 0.6188</span><br><span class="line">Epoch 5/20</span><br><span class="line">63/63 [==============================] - 72s 1s/step - loss: 0.7375 - accuracy: 0.6402</span><br><span class="line">Epoch 6/20</span><br><span class="line">63/63 [==============================] - 77s 1s/step - loss: 0.7932 - accuracy: 0.6769</span><br><span class="line">Epoch 7/20</span><br><span class="line">63/63 [==============================] - 78s 1s/step - loss: 0.7782 - accuracy: 0.6713</span><br><span class="line">Epoch 8/20</span><br><span class="line">63/63 [==============================] - 76s 1s/step - loss: 0.6272 - accuracy: 0.7147</span><br><span class="line">Epoch 9/20</span><br><span class="line">63/63 [==============================] - 77s 1s/step - loss: 0.6303 - accuracy: 0.7059</span><br><span class="line">Epoch 10/20</span><br><span class="line">63/63 [==============================] - 74s 1s/step - loss: 0.6250 - accuracy: 0.7108</span><br><span class="line">Epoch 11/20</span><br><span class="line">63/63 [==============================] - 73s 1s/step - loss: 0.6065 - accuracy: 0.7142</span><br><span class="line">Epoch 12/20</span><br><span class="line">63/63 [==============================] - 74s 1s/step - loss: 0.5289 - accuracy: 0.7754</span><br><span class="line">Epoch 13/20</span><br><span class="line">63/63 [==============================] - 73s 1s/step - loss: 0.5005 - accuracy: 0.7506</span><br><span class="line">Epoch 14/20</span><br><span class="line">63/63 [==============================] - 73s 1s/step - loss: 0.3961 - accuracy: 0.8141</span><br><span class="line">Epoch 15/20</span><br><span class="line">63/63 [==============================] - 74s 1s/step - loss: 0.4417 - accuracy: 0.8121</span><br><span class="line">Epoch 16/20</span><br><span class="line">63/63 [==============================] - 74s 1s/step - loss: 0.3761 - accuracy: 0.8136</span><br><span class="line">Epoch 17/20</span><br><span class="line">63/63 [==============================] - 73s 1s/step - loss: 0.2764 - accuracy: 0.8809</span><br><span class="line">Epoch 18/20</span><br><span class="line">63/63 [==============================] - 71s 1s/step - loss: 0.2698 - accuracy: 0.8878</span><br><span class="line">Epoch 19/20</span><br><span class="line">63/63 [==============================] - 72s 1s/step - loss: 0.1483 - accuracy: 0.9457</span><br><span class="line">Epoch 20/20</span><br><span class="line">63/63 [==============================] - 72s 1s/step - loss: 0.2495 - accuracy: 0.9079</span><br></pre></td></tr></table></figure></p>
<p><strong>ResNet-18 无跳连</strong></p>
<figure class="highlight plaintext"><figcaption><span>text</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line">Epoch 1/20</span><br><span class="line">63/63 [==============================] - 63s 963ms/step - loss: 1.4874 - accuracy: 0.5111</span><br><span class="line">Epoch 2/20</span><br><span class="line">63/63 [==============================] - 62s 990ms/step - loss: 0.7654 - accuracy: 0.5386</span><br><span class="line">Epoch 3/20</span><br><span class="line">63/63 [==============================] - 65s 1s/step - loss: 0.6799 - accuracy: 0.6210</span><br><span class="line">Epoch 4/20</span><br><span class="line">63/63 [==============================] - 62s 990ms/step - loss: 0.6891 - accuracy: 0.6086</span><br><span class="line">Epoch 5/20</span><br><span class="line">63/63 [==============================] - 65s 1s/step - loss: 0.7921 - accuracy: 0.5182</span><br><span class="line">Epoch 6/20</span><br><span class="line">63/63 [==============================] - 65s 1s/step - loss: 0.7123 - accuracy: 0.5643</span><br><span class="line">Epoch 7/20</span><br><span class="line">63/63 [==============================] - 64s 1s/step - loss: 0.7071 - accuracy: 0.5173</span><br><span class="line">Epoch 8/20</span><br><span class="line">63/63 [==============================] - 64s 1s/step - loss: 0.6653 - accuracy: 0.6227</span><br><span class="line">Epoch 9/20</span><br><span class="line">63/63 [==============================] - 65s 1s/step - loss: 0.6675 - accuracy: 0.6249</span><br><span class="line">Epoch 10/20</span><br><span class="line">63/63 [==============================] - 64s 1s/step - loss: 0.6959 - accuracy: 0.6130</span><br><span class="line">Epoch 11/20</span><br><span class="line">63/63 [==============================] - 66s 1s/step - loss: 0.6730 - accuracy: 0.6182</span><br><span class="line">Epoch 12/20</span><br><span class="line">63/63 [==============================] - 63s 1s/step - loss: 0.6321 - accuracy: 0.6491</span><br><span class="line">Epoch 13/20</span><br><span class="line">63/63 [==============================] - 63s 992ms/step - loss: 0.6413 - accuracy: 0.6569</span><br><span class="line">Epoch 14/20</span><br><span class="line">63/63 [==============================] - 63s 1s/step - loss: 0.6130 - accuracy: 0.6885</span><br><span class="line">Epoch 15/20</span><br><span class="line">63/63 [==============================] - 62s 988ms/step - loss: 0.6750 - accuracy: 0.6056</span><br><span class="line">Epoch 16/20</span><br><span class="line">63/63 [==============================] - 66s 1s/step - loss: 0.6341 - accuracy: 0.6526</span><br><span class="line">Epoch 17/20</span><br><span class="line">63/63 [==============================] - 68s 1s/step - loss: 0.6384 - accuracy: 0.6676</span><br><span class="line">Epoch 18/20</span><br><span class="line">63/63 [==============================] - 65s 1s/step - loss: 0.5750 - accuracy: 0.6997</span><br><span class="line">Epoch 19/20</span><br><span class="line">63/63 [==============================] - 63s 997ms/step - loss: 0.5932 - accuracy: 0.7094</span><br><span class="line">Epoch 20/20</span><br><span class="line">63/63 [==============================] - 62s 990ms/step - loss: 0.6133 - accuracy: 0.6420</span><br></pre></td></tr></table></figure>
<p><strong>ResNet-50</strong></p>
<figure class="highlight plaintext"><figcaption><span>text</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line">Epoch 1/20</span><br><span class="line">63/63 [==============================] - 72s 1s/step - loss: 3.4660 - accuracy: 0.4970</span><br><span class="line">Epoch 2/20</span><br><span class="line">63/63 [==============================] - 67s 1s/step - loss: 1.3429 - accuracy: 0.5686</span><br><span class="line">Epoch 3/20</span><br><span class="line">63/63 [==============================] - 68s 1s/step - loss: 1.0294 - accuracy: 0.5616</span><br><span class="line">Epoch 4/20</span><br><span class="line">63/63 [==============================] - 68s 1s/step - loss: 0.7920 - accuracy: 0.6186</span><br><span class="line">Epoch 5/20</span><br><span class="line">63/63 [==============================] - 70s 1s/step - loss: 0.6698 - accuracy: 0.6773</span><br><span class="line">Epoch 6/20</span><br><span class="line">63/63 [==============================] - 70s 1s/step - loss: 0.6884 - accuracy: 0.7289</span><br><span class="line">Epoch 7/20</span><br><span class="line">63/63 [==============================] - 70s 1s/step - loss: 0.7144 - accuracy: 0.6399</span><br><span class="line">Epoch 8/20</span><br><span class="line">63/63 [==============================] - 69s 1s/step - loss: 0.7088 - accuracy: 0.6698</span><br><span class="line">Epoch 9/20</span><br><span class="line">63/63 [==============================] - 68s 1s/step - loss: 0.6385 - accuracy: 0.6446</span><br><span class="line">Epoch 10/20</span><br><span class="line">63/63 [==============================] - 69s 1s/step - loss: 0.5389 - accuracy: 0.7417</span><br><span class="line">Epoch 11/20</span><br><span class="line">63/63 [==============================] - 71s 1s/step - loss: 0.4954 - accuracy: 0.7832</span><br><span class="line">Epoch 12/20</span><br><span class="line">63/63 [==============================] - 73s 1s/step - loss: 0.4489 - accuracy: 0.7782</span><br><span class="line">Epoch 13/20</span><br><span class="line">63/63 [==============================] - 69s 1s/step - loss: 0.3987 - accuracy: 0.8257</span><br><span class="line">Epoch 14/20</span><br><span class="line">63/63 [==============================] - 72s 1s/step - loss: 0.3228 - accuracy: 0.8519</span><br><span class="line">Epoch 15/20</span><br><span class="line">63/63 [==============================] - 70s 1s/step - loss: 0.2089 - accuracy: 0.9235</span><br><span class="line">Epoch 16/20</span><br><span class="line">63/63 [==============================] - 69s 1s/step - loss: 0.4766 - accuracy: 0.7756</span><br><span class="line">Epoch 17/20</span><br><span class="line">63/63 [==============================] - 75s 1s/step - loss: 0.2148 - accuracy: 0.9181</span><br><span class="line">Epoch 18/20</span><br><span class="line">63/63 [==============================] - 70s 1s/step - loss: 0.3086 - accuracy: 0.8623</span><br><span class="line">Epoch 19/20</span><br><span class="line">63/63 [==============================] - 69s 1s/step - loss: 0.3544 - accuracy: 0.8732</span><br><span class="line">Epoch 20/20</span><br><span class="line">63/63 [==============================] - 70s 1s/step - loss: 0.0796 - accuracy: 0.9704</span><br></pre></td></tr></table></figure>
<p><strong>ResNet-50 无跳连</strong></p>
<figure class="highlight plaintext"><figcaption><span>text</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line">Epoch 1/20</span><br><span class="line">63/63 [==============================] - 60s 882ms/step - loss: 1.2093 - accuracy: 0.5034</span><br><span class="line">Epoch 2/20</span><br><span class="line">63/63 [==============================] - 56s 892ms/step - loss: 0.8433 - accuracy: 0.4861</span><br><span class="line">Epoch 3/20</span><br><span class="line">63/63 [==============================] - 59s 931ms/step - loss: 0.7512 - accuracy: 0.5235</span><br><span class="line">Epoch 4/20</span><br><span class="line">63/63 [==============================] - 62s 991ms/step - loss: 0.7395 - accuracy: 0.4887</span><br><span class="line">Epoch 5/20</span><br><span class="line">63/63 [==============================] - 62s 990ms/step - loss: 0.7770 - accuracy: 0.5316</span><br><span class="line">Epoch 6/20</span><br><span class="line">63/63 [==============================] - 60s 945ms/step - loss: 0.7408 - accuracy: 0.4947</span><br><span class="line">Epoch 7/20</span><br><span class="line">63/63 [==============================] - 67s 1s/step - loss: 0.7345 - accuracy: 0.5434</span><br><span class="line">Epoch 8/20</span><br><span class="line">63/63 [==============================] - 62s 984ms/step - loss: 0.7214 - accuracy: 0.5605</span><br><span class="line">Epoch 9/20</span><br><span class="line">63/63 [==============================] - 60s 950ms/step - loss: 0.7770 - accuracy: 0.4784</span><br><span class="line">Epoch 10/20</span><br><span class="line">63/63 [==============================] - 60s 956ms/step - loss: 0.7171 - accuracy: 0.5203</span><br><span class="line">Epoch 11/20</span><br><span class="line">63/63 [==============================] - 63s 994ms/step - loss: 0.7045 - accuracy: 0.4921</span><br><span class="line">Epoch 12/20</span><br><span class="line">63/63 [==============================] - 63s 1s/step - loss: 0.6884 - accuracy: 0.5430</span><br><span class="line">Epoch 13/20</span><br><span class="line">63/63 [==============================] - 60s 958ms/step - loss: 0.7333 - accuracy: 0.5278</span><br><span class="line">Epoch 14/20</span><br><span class="line">63/63 [==============================] - 61s 966ms/step - loss: 0.7050 - accuracy: 0.5106</span><br><span class="line">Epoch 15/20</span><br><span class="line">63/63 [==============================] - 59s 943ms/step - loss: 0.6958 - accuracy: 0.5622</span><br><span class="line">Epoch 16/20</span><br><span class="line">63/63 [==============================] - 60s 954ms/step - loss: 0.7398 - accuracy: 0.5172</span><br><span class="line">Epoch 17/20</span><br><span class="line">63/63 [==============================] - 69s 1s/step - loss: 0.7104 - accuracy: 0.5023</span><br><span class="line">Epoch 18/20</span><br><span class="line">63/63 [==============================] - 74s 1s/step - loss: 0.7411 - accuracy: 0.4747</span><br><span class="line">Epoch 19/20</span><br><span class="line">63/63 [==============================] - 67s 1s/step - loss: 0.7056 - accuracy: 0.4706</span><br><span class="line">Epoch 20/20</span><br><span class="line">63/63 [==============================] - 81s 1s/step - loss: 0.7901 - accuracy: 0.4898</span><br></pre></td></tr></table></figure>
<p>对比ResNet-18和ResNet-50，可以看出，ResNet-50的拟合能力确实更强一些。</p>
<p>对比无跳连的ResNet-18和ResNet-50，可以看出，ResNet-50的拟合能力反而逊于ResNet-18。这符合ResNet的初衷，如果不加残差连接的话，过深的网络反而会因为梯度问题而有更高的训练误差。</p>
<p>此外，不同模型的训练速度也值得一讲。在训练数据量减少到原来的1/3后，ResNet-50和ResNet-18的训练速度差不多。ResNet-50看上去比ResNet-18多了很多层，网络中间也使用了通道数很大的卷积，但整体的参数量并没有增大多少，这多亏了能降低运算量的瓶颈结构。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>在这篇文章中，我展示了ResNet-18和ResNet-50的TensorFlow实现。这份代码包括了经典ResNet中两种残差块的两种实现，完整地复现了原论文的模型模块。同时，经实验分析，我验证了ResNet残差连接的有效性。</p>
<p>未来我还会写一篇ResNet的PyTorch实现，并附上论文的详细解读。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://zhouyifan.net/2022/07/24/DLS-note-11/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Zhou Yifan">
      <meta itemprop="description" content="A foresighted strategist with big-picture thinking. 大局观选手。">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="周弈帆的博客">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/07/24/DLS-note-11/" class="post-title-link" itemprop="url">吴恩达《深度学习专项》笔记（十一）：深度卷积模型——从示例中学习</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-07-24 00:31:30" itemprop="dateCreated datePublished" datetime="2022-07-24T00:31:30+08:00">2022-07-24</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">学习</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E5%AD%A6%E4%B9%A0/%E7%9F%A5%E8%AF%86%E8%AE%B0%E5%BD%95/" itemprop="url" rel="index"><span itemprop="name">知识记录</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="学习提示"><a href="#学习提示" class="headerlink" title="学习提示"></a>学习提示</h1><p>上周，我们学完了CNN的基础组成模块。而从这周开始，我们要换一种学习方式：我们会认识一些经典的CNN架构，从示例中学习。一方面来说，通过了解他人的网络，阅读他人的代码，我们能够更快地掌握如何整合CNN的基础模块；另一方面，CNN架构往往泛化能力较强，学会了其他任务中成熟的架构，可以把这些架构直接用到我们自己的任务中。</p>
<p>接下来，我们会按照CNN的发展历史，认识许多CNN架构。首先是经典网络：</p>
<ul>
<li>LeNet-5</li>
<li>AlexNet</li>
<li>VGG</li>
</ul>
<p>之后是近年来的一些网络：</p>
<ul>
<li>ResNet</li>
<li>Inception</li>
<li>MobileNet</li>
</ul>
<p>我们不会把这些研究的论文详细过一遍，而只会学习各研究中最精华的部分。学有余力的话，最好能在课后把论文自己过一遍。</p>
<h1 id="课堂笔记"><a href="#课堂笔记" class="headerlink" title="课堂笔记"></a>课堂笔记</h1><h2 id="经典网络"><a href="#经典网络" class="headerlink" title="经典网络"></a>经典网络</h2><h3 id="LeNet-5"><a href="#LeNet-5" class="headerlink" title="LeNet-5"></a>LeNet-5</h3><p>LeNet-5是用于手写数字识别（识别0~9的阿拉伯数字）的网络。它的结构如下：</p>
<p><img src="/2022/07/24/DLS-note-11/1.jpg" alt></p>
<p>网络是输入是一张[32, 32, 1]的灰度图像，输入经过4个卷积+池化层，再经过两个全连接层，输出一个0~9的数字。这个网络和我们上周见过的网络十分相似，数据体的宽和高在不断变小，而通道数在不断变多。</p>
<p>这篇工作是1998年发表的，当时的神经网络架构和现在我们学的有不少区别：</p>
<ul>
<li>当时padding还没有得到广泛使用，数据体的分辨率会越降越小。</li>
<li>当时主要使用平均池化，而现在最大池化更常见。</li>
<li>网络只输出一个值，表示识别出来的数字。而现在的多分类任务一般会输出10个值并使用softmax激活函数。</li>
<li>当时激活函数只用sigmoid和tanh，没有人用ReLU。</li>
<li>当时的算力没有现在这么强，原工作在计算每个通道卷积时使用了很多复杂的小技巧。而现在我们直接算就行了。</li>
</ul>
<p>LeNet-5只有6万个参数。随着算力的增长，后来的网络越来越大了。</p>
<h3 id="AlexNet"><a href="#AlexNet" class="headerlink" title="AlexNet"></a>AlexNet</h3><p>AlexNet是2012年发表的有关图像分类的CNN结构。它的输入是[227, 227, 3]的图像，输出是一个1000类的分类结果。</p>
<blockquote>
<p>原论文里写的是输入形状是[224, 224, 3]，但实际上这个分辨率是有问题的，按照这个分辨率是算不出后续结果的分辨率的。但现在一些框架对AlexNet的复现中，还是会令输入的分辨率是224。这是因为框架在第一层卷积中加了一个padding的操作，强行让后续数据的分辨率和原论文对上了。 </p>
</blockquote>
<p><img src="/2022/07/24/DLS-note-11/2.jpg" alt></p>
<p>AlexNet和LeNet-5在架构上十分接近。但是，AlexNet做出了以下改进：</p>
<ul>
<li>AlexNet用了更多的参数，一共有约6000万个参数。</li>
<li>使用ReLU作为激活函数。</li>
</ul>
<p>AlexNet还提出了其他一些创新，但与我们要学的知识没有那么多关系：</p>
<ul>
<li>当时算力还是比较紧张，AlexNet用了双GPU训练。论文里写了很多相关的工程细节。</li>
<li>使用了Local Response Normalization这种归一化层。现在几乎没人用这种归一化。</li>
</ul>
<p>AlexNet中的一些技术在今天看来，已经是常识般的存在。而在那个年代，尽管深度学习在语音识别等任务上已经初露锋芒，人们还没有开始重视深度学习这项技术。正是由于AlexNet这一篇工作的出现，计算机视觉的研究者开始关注起了深度学习。甚至在后来，这篇工作的影响力已经远超出了计算机视觉社区。</p>
<h3 id="VGG-16"><a href="#VGG-16" class="headerlink" title="VGG-16"></a>VGG-16</h3><p>VGG-16也是一个图像分类网络。VGG的出发点是：为了简化网络结构，只用3x3等长(same)卷积和2x2最大池化。</p>
<p><img src="/2022/07/24/DLS-note-11/3.jpg" alt></p>
<p>可以看出，VGG也是经过了一系列的卷积和池化层，最后使用全连接层和softmax输出结果。顺带一提，VGG-16里的16表示有16个带参数的层。</p>
<p>VGG非常庞大，有138M(1.38亿)个参数。但是它简洁的结构吸引了很多人的关注。</p>
<p>吴恩达老师鼓励大家去读一读这三篇论文。可以先看AlexNet，再看VGG。LeNet有点难读，可以放到最后去读。</p>
<h2 id="ResNets（基于残差的网络）"><a href="#ResNets（基于残差的网络）" class="headerlink" title="ResNets（基于残差的网络）"></a>ResNets（基于残差的网络）</h2><p>非常非常深的神经网络是很难训练的，这主要是由梯度爆炸/弥散问题导致的。在这一节中，我们要学一种叫做“跳连(skip connection)”的网络模块连接方式。使用跳连，我们能让浅层模块的输出直接对接到深层模块的输入上，进而搭建基于残差的网络，解决梯度爆炸/弥散问题，训练深达100层的网络。</p>
<h3 id="残差块"><a href="#残差块" class="headerlink" title="残差块"></a>残差块</h3><p>回忆一下，在全连接网络中，假如我们有中间层的输出$a^{[l]}, a^{[l+2]}$，$a^{[l+2]}$是怎么由$a^{[l]}$算出来的呢？我们之前用的公式如下：</p>
<script type="math/tex; mode=display">
\begin{aligned}
z^{[l+1]}&=W^{[l+1]}a^{[l]}+b^{[l+1]} \\
a^{[l+1]}&=g(z^{[l+1]}) \\
z^{[l+2]}&=W^{[l+2]}a^{[l+1]}+b^{[l+2]} \\
a^{[l+2]}&=g(z^{[l+2]}) \\
\end{aligned}</script><p>也就是说，$a^{[l]}$要经过一个线性层、一个激活函数、一个线性层、一个激活函数，才能传递到$a^{[l+2]}$，这条路径非常长：</p>
<p><img src="/2022/07/24/DLS-note-11/4.jpg" alt></p>
<p>而在残差块(Residual block)中，我们使用了一种新的连接方法：</p>
<p><img src="/2022/07/24/DLS-note-11/5.jpg" alt></p>
<p>$a^{[l]}$的值被直接加到了第二个ReLU层之前的线性输出上，这是一种类似电路中短路的连接方法（又称跳连）。这样，浅层的信息能更好地传到深层了。</p>
<p>使用这种方法后，计算公式变更为：</p>
<script type="math/tex; mode=display">
\begin{aligned}
z^{[l+1]}&=W^{[l+1]}a^{[l]}+b^{[l+1]} \\
a^{[l+1]}&=g(z^{[l+1]}) \\
z^{[l+2]}&=W^{[l+2]}a^{[l+1]}+b^{[l+2]} \\
a^{[l+2]}&=g(z^{[l+2]}+a^{[l]}) \\
\end{aligned}</script><p>残差块中还有一个要注意的细节。$a^{[l+2]}=g(z^{[l+2]}+a^{[l]})$这个式子能够成立，实际上是默认了$a^{[l+2]}, a^{[l]}$的维度相同。而一旦$a^{[l+2]}$的维度发生了变化，就需要用下面这种方式来调整了。</p>
<p>$a^{[l+2]}=g(z^{[l+2]}+W’a^{[l]})$</p>
<p>我们可以用一个$W’$来完成维度的转换。为了方便理解，我们先让所有$a$都是一维向量，$W’$是矩阵。这样，假设$a^{[l+2]}$的长度是256，$a^{[l]}$的长度是128，则$W’$的形状就是$256 \times 128$。</p>
<p>但实际上，$a$是一个三维的图像张量，三个维度的长度都可能发生变化。因此，对于图像，上式中的$W’$应该表示的是一个卷积操作。通过卷积操作，我们能够减小图像的宽高，调整图像的通道数，使得$a^{[l]}$和$a^{[l+2]}$的维度完全相同。</p>
<h3 id="残差网络"><a href="#残差网络" class="headerlink" title="残差网络"></a>残差网络</h3><p>在构建残差网络ResNet时，只要把这种残差块一个一个拼接起来即可。或者从另一个角度来看，对于一个“平坦网络”（”plain network”, ResNet论文中用的词，用于表示非残差网络），我们只要把线性层两两打包，添加跳连即可。</p>
<p><img src="/2022/07/24/DLS-note-11/6.jpg" alt></p>
<p>残差块起到了什么作用呢？让我们看看在网络层数变多时，平坦网络和残差网络训练误差的变化趋势：</p>
<p><img src="/2022/07/24/DLS-note-11/7.jpg" alt></p>
<p>理论上来说，层数越深，训练误差应该越低。但在实际中，对平坦网络增加深度，反而会让误差变高。而使用ResNet后，随着深度增加，训练误差起码不会降低了。</p>
<p>正是有这样的特性，我们可以用ResNet架构去训练非常深的网络。</p>
<p>为什么ResNet是有这样的特性呢？我们还是从刚刚那个ResNet的公式里找答案。</p>
<p>假设我们设计好了一个网络，又给它新加了一个残差块，即多加了两个卷积层，那么最后的输出可以写成：</p>
<script type="math/tex; mode=display">
a^{[l+2]}=g(z^{[l+2]}+a^{[l]}),</script><p>即</p>
<script type="math/tex; mode=display">
\begin{aligned}
a^{[l+2]}&=g(z^{[l+2]}+a^{[l]}) \\
a^{[l+2]}&=g(W^{[l+2]}a^{[l+1]}+b^{[l+2]}+a^{[l]}) \\
\end{aligned}</script><p>由于正则化的存在，所有$W$和$b$都倾向于变得更小。极端情况下，$W, b$都变为0了。那么，</p>
<script type="math/tex; mode=display">
\begin{aligned}
a^{[l+2]}&=g(W^{[l+2]}a^{[l+1]}+b^{[l+2]}+a^{[l]}), \\
a^{[l+2]}&=g(a^{[l]}). \\
\end{aligned}</script><p>再不妨设$g=ReLU$。则因为$a^{[l]}$也是ReLU的输出，有</p>
<script type="math/tex; mode=display">
\begin{aligned}
a^{[l+2]}&=g(a^{[l]}), \\
a^{[l+2]}&=a^{[l]}. \\
\end{aligned}</script><p>这其实是一个恒等映射，也就是说，新加的残差块对之前的输出没有任何影响。网络非常容易学习到恒等映射。这样，最起码能够保证较深的网络不比浅的网络差。</p>
<p>准备好了所有基础知识，我们来看看完整的ResNet长什么样。</p>
<p><img src="/2022/07/24/DLS-note-11/7_2.jpg" alt></p>
<p>ResNet有几个参数量不同的版本。这里展示的叫做ResNet-34。完整的网络很长，我们只用关注其中一小部分就行了。</p>
<p>一开始，网络还是用一个大卷积核大步幅的卷积以及一个池化操作快速降低图像的宽度，再把数据传入残差块中。和我们刚刚学的一样，残差块有两种，一种是维度相同可以直接相加的（实线），一种是要调整维度的（虚线）。整个网络就是由这若干个这样的残差块组构成。经过所有残差块后，还是和经典的网络一样，用全连接层输出结果。</p>
<p>这里，我们只学习了残差连接的基本原理。ResNet的论文里还有更多有关网络结构、实验的细节。最好能读一读论文。当然，这周的编程实战里我们也会复现ResNet，以加深对其的理解。</p>
<h2 id="Inception-网络"><a href="#Inception-网络" class="headerlink" title="Inception 网络"></a>Inception 网络</h2><p>我们已经见过不少CNN的示例了。当我们仿照它们设计自己的网络时，或许会感到迷茫：有3x3, 5x5卷积，有池化，该怎么选择每一个模块呢？Inception网络给了一个解决此问题的答案：我全都要。</p>
<p>Inception网络用到了一种特殊的1x1卷积。我们会先学习1x1卷积，再学习Inception网络的知识。</p>
<h3 id="1x1卷积"><a href="#1x1卷积" class="headerlink" title="1x1卷积"></a>1x1卷积</h3><p>用1x1的卷积核去卷一幅图像，似乎是一件很滑稽的事情。假设一幅图像的数字是[1, 2, 3]，卷积核是[2]，那么卷出来的图像就是[2, 4, 6]。这不就是把每个数都做了一次乘法吗？</p>
<p>对于通道数为1的图像，1x1卷积确实没什么大用。而当通道数多起来后，1x1卷积的意义就逐渐显现出来了。思考一下，对多通道的图像做1x1卷积，就是把某像素所有通道的数字各乘一个数，求和，加一个bias，再通过激活函数。这是计算一个输出结果的过程，而如果有多个卷积核，就可以计算出多个结果。（下图中，蓝色的数据体是输入图像，黄色的数据体是1x1的卷积核。两个数据体重合部分的数据会先做乘法，再求和，加bias，经过激活函数。）</p>
<p><img src="/2022/07/24/DLS-note-11/7_3.jpg" alt></p>
<p>这个过程让你想起了什么？没错，正是最早学习的全连接网络。1x1卷积，实际上就是在各通道上做了一次全连接的计算。1x1卷积的输入通道数，就是全连接层上一层神经元的数量；1x1卷积核的数量，就是这一层神经元的数量。</p>
<p>1x1卷积主要用于变换图像的通道数。比如要把一个192通道数的图像变成32通道的，就应该用32个1x1卷积去卷原图像。</p>
<h3 id="Inception块的原理"><a href="#Inception块的原理" class="headerlink" title="Inception块的原理"></a>Inception块的原理</h3><p>在Inception网络中，我们会使用这样一种混合模块：对原数据做1x1, 3x3, 5x5卷积以及最大池化，得到通道数不同的数据体。这些数据体会被拼接起来，作为整个模块的输出。</p>
<p><img src="/2022/07/24/DLS-note-11/7_4.jpg" alt></p>
<p>值得注意的是，这里的池化操作和我们之前见过的不太一样。为了保持输出张量的宽高，这个池化的步幅为1，且使用了等长填充。另外，为了调整池化操作输出的通道数，这条数据处理路线上还有一个用1x1卷积变换通道数的操作。这份图省略了很多这样的细节，下一节我们会见到这幅图的完整版。</p>
<p>在实现这样一种模块时，会碰到计算量过大的问题。比如把上面$28 \times 28 \times 192$的数据体用$5 \times 5$卷积卷成$28 \times 28 \times 32$的数据体，需要多少次乘法计算呢？对每个像素单独考虑，一个通道上的卷积要做$5 \times 5$此乘法，192个通道的卷积要做$192 \times 5 \times 5$次乘法。32个这样的卷积在$28 \times 28$的图片上要做$28 \times 28 \times 32 \times 192 \times 5 \times 5 \approx 120M$次乘法。这个计算量太大了。</p>
<p>为此，我们可以巧妙地先利用1x1卷积减少通道数，再做5x5卷积。这样，计算量就少得多了。</p>
<p><img src="/2022/07/24/DLS-note-11/7_5.jpg" alt></p>
<p>这样一种两头大，中间小的结构被形象地称为瓶颈(bottlenect)。这种结构被广泛用在许多典型网络中。</p>
<h3 id="Inception网络"><a href="#Inception网络" class="headerlink" title="Inception网络"></a>Inception网络</h3><p>有了之前的知识，我们可以看Inception模块的完整结构了。1x1卷积没有什么特别的。为了减少3x3卷积和5x5卷积的计算量，做这两种卷积之前都会用1x1卷积减少通道数。而为了改变池化结果的通道数，池化后接了一个1x1卷积操作。</p>
<p><img src="/2022/07/24/DLS-note-11/7_6.jpg" alt></p>
<p>实际上，理解了Inception块，也就能看懂Inception网络了。如下图所示，红框内的模块都是Inception块。而这个网络还有一些小细节：除了和普通网络一样在网络的最后使用softmax输出结果外，这个网络还根据中间结果也输出了几个结果。当然，这些都是早期网络的设计技巧了。</p>
<p><img src="/2022/07/24/DLS-note-11/7_7.jpg" alt></p>
<h2 id="MobileNet"><a href="#MobileNet" class="headerlink" title="MobileNet"></a>MobileNet</h2><p>MobileNet，顾名思义，这是一种适用于移动(mobile)设备的神经网络。移动设备的计算资源通常十分紧缺，因此，MobileNet对网络的计算量进行了极致的压缩。</p>
<h3 id="减少卷积运算量"><a href="#减少卷积运算量" class="headerlink" title="减少卷积运算量"></a>减少卷积运算量</h3><p>再回顾一遍，一次卷积操作中主要的计算量如下：</p>
<p><img src="/2022/07/24/DLS-note-11/7_8.jpg" alt></p>
<p>计算量这么大，主要问题出在每一个输出通道都要与每一个输入通道“全连接”上。为此，我们可以考虑让输出通道只由部分的输入通道决定。这样一种卷积的策略叫逐深度可分卷积(Depthwise Separable Convolution)。</p>
<blockquote>
<p>这里的depthwise是“逐深度”的意思，但我觉得“逐通道”这个称呼会更容易理解一点。</p>
</blockquote>
<p>逐深度可分卷积分为两步：逐深度卷积(depthwise convolution)，逐点卷积(pointwise convolution)。逐深度卷积生成新的通道，逐点卷积把各通道的信息关联起来。</p>
<p><img src="/2022/07/24/DLS-note-11/7_9.jpg" alt></p>
<p>之前，要对下图中的三通道图片做卷积，需要3个卷积核分别处理3个通道。而在逐深度卷积中，我们只要1个卷积核。这个卷积核会把输入图像当成三个单通道图像来看待，分别对原图像的各个通道进行卷积，并生成3个单通道图像，最后把3个单通道图像拼回一个三通道图像。也就是说，逐深度卷积只能生成一幅通道数相同的新图像。</p>
<blockquote>
<p>逐深度卷积可以通过设置卷积在编程框架中的<code>groups</code>参数来实现。参见我<a href>讲解卷积的文章</a>。</p>
</blockquote>
<p><img src="/2022/07/24/DLS-note-11/7_10.jpg" alt></p>
<p>下一步，是逐点卷积，也就是1x1卷积。它用来改变图片的通道数。</p>
<p><img src="/2022/07/24/DLS-note-11/7_11.jpg" alt></p>
<p>之前的卷积有2160次乘法，现在只有432+240=672次，计算量确实减少了不少。实际上，优化后计算量占原计算量的比例是：</p>
<script type="math/tex; mode=display">
\frac{1}{n_c'} + \frac{1}{f^2}</script><p>其中$n_c’$是输出通道数，$f$是卷积核边长。一般来说计算量都会少10倍。</p>
<h3 id="网络结构"><a href="#网络结构" class="headerlink" title="网络结构"></a>网络结构</h3><p>知道了MobileNet的基本思想，我们来看几个不同版本的MobileNet。</p>
<h4 id="MobileNet-v1"><a href="#MobileNet-v1" class="headerlink" title="MobileNet v1"></a>MobileNet v1</h4><p>13个逐深度可分卷积模块，之后接通常的池化、全连接、softmax。</p>
<p><img src="/2022/07/24/DLS-note-11/8.jpg" alt></p>
<h4 id="MobileNet-v2"><a href="#MobileNet-v2" class="headerlink" title="MobileNet v2"></a>MobileNet v2</h4><p>两个改进：</p>
<ol>
<li>残差连接</li>
<li>扩张(expansion)操作</li>
</ol>
<p><img src="/2022/07/24/DLS-note-11/9.jpg" alt></p>
<p>残差连接和ResNet一样。这里我们关注一下第二个改进。</p>
<p>在MobileNet v2中，先做一个扩张维度的1x1卷积，再做逐深度卷积，最后做之前的逐点1x1卷积。由于最后的逐点卷积起到的是减小维度的作用，所以最后一步操作也叫做投影。</p>
<p><img src="/2022/07/24/DLS-note-11/10.jpg" alt></p>
<p>这种架构很好地解决了性能和效果之间的矛盾：在模块之间，数据的通道数只有3，占用内存少；在模块之内，更高通道的数据能拟合更复杂的函数。</p>
<h2 id="EfficientNet"><a href="#EfficientNet" class="headerlink" title="EfficientNet"></a>EfficientNet</h2><p>EfficientNet能根据设备的计算能力，自动调整网络占用的资源。</p>
<p>让我们想想，哪些因素决定了一个网络占用的运算资源？我们很快能想到下面这些因素：</p>
<ul>
<li>图像分辨率</li>
<li>网络深度</li>
<li>特征的长度（即卷积核数量或神经元数量）</li>
</ul>
<p>在EfficientNet中，我们可以在这三个维度上缩放网络，动态改变网络的计算量。EfficientNet的开源实现中，一般会提供各设备下的最优参数。</p>
<h2 id="卷积网络实现细节"><a href="#卷积网络实现细节" class="headerlink" title="卷积网络实现细节"></a>卷积网络实现细节</h2><h3 id="使用开源实现"><a href="#使用开源实现" class="headerlink" title="使用开源实现"></a>使用开源实现</h3><p>由于深度学习项目涉及很多训练上的细节，想复现一个前人的工作是很耗时的。最好的学习方法是找到别人的开源代码，在现有代码的基础上学习。</p>
<p>深度学习的开源代码一般在GitHub上都能找到。如果是想看PyTorch实现，可以直接去GitHub上搜索OpenMMLab。</p>
<h3 id="使用迁移学习"><a href="#使用迁移学习" class="headerlink" title="使用迁移学习"></a>使用迁移学习</h3><p>如第三门课第二周所学，我们可以用迁移学习，导入别人训练好的模型里的权重为初始权重，加速我们自己模型的训练。</p>
<p>还是以多分类任务的迁移学习为例（比如把一个1000分类的分类器迁移到一个猫、狗、其他的三分类模型上）。迁移后，新的网络至少要删除输出层，并按照新的多分类个数，重新初始化一个输出层。之后，根据新任务的数据集大小，冻结网络的部分参数，从导入的权重开始重新训练网络的其他部分：</p>
<p><img src="/2022/07/24/DLS-note-11/11.jpg" alt></p>
<p>当然，可以多删除几个较深的层，也可以多加入几个除了输出层以外的隐藏层。</p>
<h3 id="数据增强"><a href="#数据增强" class="headerlink" title="数据增强"></a>数据增强</h3><p>由于CV任务总是缺少数据，数据增强是一种常见的提升网络性能的手段。</p>
<p>常见的改变形状的数据增强手段有：</p>
<ul>
<li>镜像</li>
<li>裁剪</li>
<li>旋转</li>
<li>扭曲</li>
</ul>
<p>此外，还可以改变图像的颜色。比如对三个颜色通道都随机加一个偏移量。</p>
<p>数据增强有一些实现上的细节：数据的读取及增强是放在CPU上运行的，训练是放在CPU或GPU上运行的。这两步其实是独立的，可以并行完成。最常见的做法是，在CPU上用多进程（发挥多核的优势）读取数据并进行数据增强，之后把数据搬到GPU上训练。</p>
<h3 id="计算机视觉的现状与相关建议"><a href="#计算机视觉的现状与相关建议" class="headerlink" title="计算机视觉的现状与相关建议"></a>计算机视觉的现状与相关建议</h3><p>一般来说，算法从两个来源获取知识：标注的数据，人工设计的特征。这二者是互补的关系。对于人工智能任务来说，如果有足够的数据，设计一个很简单的网络就行了；而如果数据量不足，则需要去精心设计网络结构。</p>
<p>像语音识别这种任务就数据充足，用简单的网络就行了。而大部分计算机视觉任务都处于数据不足的状态。哪怕计算机视觉中比较基础的图像分类任务，都需要设计结构复杂的网络，更不用说目标检测这些更难的任务了。</p>
<p>如果你想用深度学习模型参加刷精度的比赛，可以使用以下几个小技巧：</p>
<ul>
<li>同时开始训练多个网络，算结果时取它们的平均值。</li>
<li>对图像分类任务，可以把图像随机裁剪一部分并输入网络，多次执行这一步骤并取平均分类结果。</li>
</ul>
<p>也就是说，只是为了提高精度的话，可以想办法对同一份输入执行多次条件不同的推理，并对结果求平均。当然，实际应用中是不可能用性能这么低的方法。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>这节课是CNN中最重要的一节课。通过学习一些经典的CNN架构，我们掌握了很多有关搭建CNN的知识。总结一下：</p>
<ul>
<li>早期CNN<ul>
<li>卷积、池化、全连接</li>
<li>边长减小，通道数增加</li>
</ul>
</li>
<li>ResNet<ul>
<li>为什么使用ResNet？</li>
<li>梯度问题是怎么被解决的？</li>
<li>残差块的一般结构</li>
<li>输入输出通道数不同的残差块</li>
<li>了解ResNet的结构(ResNet-18, ResNet-50)</li>
</ul>
</li>
<li>Incpetion 网络<ul>
<li>1x1卷积</li>
<li>用1x1卷积减少计算量</li>
<li>Inception网络的基本模块</li>
</ul>
</li>
<li>MobileNet<ul>
<li>逐深度可分卷积</li>
<li>MobileNet v2中的瓶颈结构</li>
</ul>
</li>
</ul>
<p>这节课介绍的都是比较前沿的CNN架构。在深度学习技术日新月异的今天，最好的学习方式是读论文，尽快一步一步跟上最新的技术。这堂课中提及的比较新的几篇论文，都有很高的阅读价值。</p>
<p>我打算在学完CNN的四周课后，暂时不去学第五门课，而是去阅读这些经典CNN论文并分享一下笔记。</p>
<p>在这周的代码实战里，我会分享一下如何用TensorFlow和PyTorch编写ResNet，同时介绍两种框架的进阶用法。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://zhouyifan.net/2022/07/24/DLS-note-10-5/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Zhou Yifan">
      <meta itemprop="description" content="A foresighted strategist with big-picture thinking. 大局观选手。">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="周弈帆的博客">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/07/24/DLS-note-10-5/" class="post-title-link" itemprop="url">吴恩达《深度学习专项》代码实战（十）：4. 算子反向传播的实现思路（以NumPy版卷积为例）</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-07-24 00:31:03" itemprop="dateCreated datePublished" datetime="2022-07-24T00:31:03+08:00">2022-07-24</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">学习</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E5%AD%A6%E4%B9%A0/%E7%9F%A5%E8%AF%86%E8%AE%B0%E5%BD%95/" itemprop="url" rel="index"><span itemprop="name">知识记录</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>在之前的文章中，我介绍了<a href>如何用NumPy实现卷积正向传播</a>。<br>在这篇文章里，我会继续介绍如何用NumPy复现二维卷积的反向传播，并用PyTorch来验证结果的正确性。通过阅读这篇文章，大家不仅能进一步理解卷积的实现原理，更能领悟到一般算子的反向传播实现是怎么推导、编写出来的。</p>
<p>项目网址：<a target="_blank" rel="noopener" href="https://github.com/SingleZombie/DL-Demos/tree/master/dldemos/BasicCNN">https://github.com/SingleZombie/DL-Demos/tree/master/dldemos/BasicCNN</a></p>
<p>本文代码在<code>dldemos/BasicCNN/np_conv_backward.py</code>这个文件里。</p>
<h2 id="实现思路"><a href="#实现思路" class="headerlink" title="实现思路"></a>实现思路</h2><p>回忆一下，在正向传播中，我们是这样做卷积运算的：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i_h <span class="keyword">in</span> <span class="built_in">range</span>(h_o):</span><br><span class="line">    <span class="keyword">for</span> i_w <span class="keyword">in</span> <span class="built_in">range</span>(w_o):</span><br><span class="line">        <span class="keyword">for</span> i_c <span class="keyword">in</span> <span class="built_in">range</span>(c_o):</span><br><span class="line">            h_lower = i_h * stride</span><br><span class="line">            h_upper = i_h * stride + f</span><br><span class="line">            w_lower = i_w * stride</span><br><span class="line">            w_upper = i_w * stride + f</span><br><span class="line">            input_slice = input_pad[h_lower:h_upper, w_lower:w_upper, :]</span><br><span class="line">            kernel_slice = weight[i_c]</span><br><span class="line">            output[i_h, i_w, i_c] = np.<span class="built_in">sum</span>(input_slice * kernel_slice)</span><br><span class="line">            output[i_h, i_w, i_c] += bias[i_c]</span><br></pre></td></tr></table></figure>
<p>我们遍历输出图像的每一个位置，选择该位置对应的输入图像切片和卷积核，做一遍乘法，再加上bias。</p>
<p>其实，一轮运算写成数学公式的话，就是一个线性函数<code>y=wx+b</code>。对<code>w, x, b</code>求导非常简单：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">dw_i = x * dy</span><br><span class="line">dx_i = w * dy</span><br><span class="line">db_i = dy</span><br></pre></td></tr></table></figure>
<p>在反向传播中，我们只需要遍历所有这样的线性运算，计算这轮运算对各参数的导数的贡献即可。最后，累加所有的贡献，就能得到各参数的导数。当然，在用代码实现这段逻辑时，可以不用最后再把所有贡献加起来，而是一算出来就加上。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">dw += x * dy</span><br><span class="line">dx += w * dy</span><br><span class="line">db += dy</span><br></pre></td></tr></table></figure>
<p>这里要稍微补充一点。在前向传播的实现中，我加入了<code>dilation, groups</code>这两个参数。为了简化反向传播的实现代码，只展示反向传播中最精华的部分，我在这份卷积实现中没有使用这两个参数。</p>
<h2 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h2><p>在开始实现反向传播之前，我们先思考一个问题：反向传播的函数应该有哪些参数？从数学上来讲，反向传播和正向传播的参数是相反的。设正向传播的输入是<code>A_prev, W, b</code>（输入图像、卷积核组、偏差），则应该输出<code>Z</code>（输出图像）。那么，在反向传播中，应该输入<code>dZ</code>，输出<code>dA_prev, dW, db</code>。可是，在写代码时，我们还需要一些其他的输入参数。</p>
<p>我的反向传播函数的函数定义如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">conv2d_backward</span>(<span class="params">dZ: np.ndarray, cache: <span class="type">Dict</span>[<span class="built_in">str</span>, np.ndarray], stride: <span class="built_in">int</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">                    padding: <span class="built_in">int</span></span>) -&gt; <span class="type">Tuple</span>[np.ndarray, np.ndarray, np.ndarray]:</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;2D Convolution Backward Implemented with NumPy</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        dZ: (np.ndarray): The derivative of the output of conv.</span></span><br><span class="line"><span class="string">        cache (Dict[str, np.ndarray]): Record output &#x27;Z&#x27;, weight &#x27;W&#x27;, bias &#x27;b&#x27;</span></span><br><span class="line"><span class="string">            and input &#x27;A_prev&#x27; of forward function.</span></span><br><span class="line"><span class="string">        stride (int): Stride for convolution.</span></span><br><span class="line"><span class="string">        padding (int): The count of zeros to pad on both sides.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Outputs:</span></span><br><span class="line"><span class="string">        Tuple[np.ndarray, np.ndarray, np.ndarray]: The derivative of W, b,</span></span><br><span class="line"><span class="string">            A_prev.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>
<p>虽然我这里把所有参数都写在了一起，但从逻辑上来看，这些参数应该分成三个类别。在编程框架中，这三类参数会储存在不同的地方。</p>
<ul>
<li><code>dZ</code>: 反向传播函数真正的输入。</li>
<li><code>cache</code>: 正向传播中的一些中间变量<code>Z, W, b</code>。由于我们必须在一个独立的函数里完成反向传播，这些中间变量得以输入参数的形式供函数访问。</li>
<li><code>stride, padding</code>: 这两个参数是卷积的属性。如果卷积层是用一个类表示的话，这些参数应该放在类属性里，而不应该放在反向传播的输入里。</li>
</ul>
<p>给定这三类参数，就足以完成反向传播计算了。下面我来介绍<code>conv2d_backward</code>的具体实现。</p>
<p>首先，获取<code>cache</code>中的参数，并且新建储存梯度的张量。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">W = cache[<span class="string">&#x27;W&#x27;</span>]</span><br><span class="line">b = cache[<span class="string">&#x27;b&#x27;</span>]</span><br><span class="line">A_prev = cache[<span class="string">&#x27;A_prev&#x27;</span>]</span><br><span class="line">dW = np.zeros(W.shape)</span><br><span class="line">db = np.zeros(b.shape)</span><br><span class="line">dA_prev = np.zeros(A_prev.shape)</span><br><span class="line"></span><br><span class="line">_, _, c_i = A_prev.shape</span><br><span class="line">c_o, f, f_2, c_k = W.shape</span><br><span class="line">h_o, w_o, c_o_2 = dZ.shape</span><br><span class="line"></span><br><span class="line"><span class="keyword">assert</span> (f == f_2)</span><br><span class="line"><span class="keyword">assert</span> (c_i == c_k)</span><br><span class="line"><span class="keyword">assert</span> (c_o == c_o_2)</span><br></pre></td></tr></table></figure>
<p>之后，为了实现填充操作，我们要把<code>A_prev</code>和<code>dA_prev</code>都填充一下。注意，算完了所有梯度后，别忘了要重新把<code>dA_prev</code>从<code>dA_prev_pad</code>里抠出来。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">A_prev_pad = np.pad(A_prev, [(padding, padding), (padding, padding),</span><br><span class="line">                                (<span class="number">0</span>, <span class="number">0</span>)])</span><br><span class="line">dA_prev_pad = np.pad(dA_prev, [(padding, padding), (padding, padding),</span><br><span class="line">                                (<span class="number">0</span>, <span class="number">0</span>)])</span><br></pre></td></tr></table></figure>
<p>接下来，就是梯度的计算了。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i_h <span class="keyword">in</span> <span class="built_in">range</span>(h_o):</span><br><span class="line">    <span class="keyword">for</span> i_w <span class="keyword">in</span> <span class="built_in">range</span>(w_o):</span><br><span class="line">        <span class="keyword">for</span> i_c <span class="keyword">in</span> <span class="built_in">range</span>(c_o):</span><br><span class="line">            h_lower = i_h * stride</span><br><span class="line">            h_upper = i_h * stride + f</span><br><span class="line">            w_lower = i_w * stride</span><br><span class="line">            w_upper = i_w * stride + f</span><br><span class="line"></span><br><span class="line">            input_slice = A_prev_pad[h_lower:h_upper, w_lower:w_upper, :]</span><br><span class="line">            <span class="comment"># forward</span></span><br><span class="line">            <span class="comment"># kernel_slice = W[i_c]</span></span><br><span class="line">            <span class="comment"># Z[i_h, i_w, i_c] = np.sum(input_slice * kernel_slice)</span></span><br><span class="line">            <span class="comment"># Z[i_h, i_w, i_c] += b[i_c]</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># backward</span></span><br><span class="line">            dW[i_c] += input_slice * dZ[i_h, i_w, i_c]</span><br><span class="line">            dA_prev_pad[h_lower:h_upper,</span><br><span class="line">                        w_lower:w_upper, :] += W[i_c] * dZ[i_h, i_w, i_c]</span><br><span class="line">            db[i_c] += dZ[i_h, i_w, i_c]</span><br></pre></td></tr></table></figure>
<p>在算导数时，我们应该对照着正向传播的计算，算出每一条计算对导数的贡献。如前文所述，卷积操作只是一个简单的<code>y=wx+b</code>，把对应的<code>w, x, b</code>从变量里正确地取出来并做运算即可。</p>
<p>最后，要把这些导数返回。别忘了把填充后的<code>dA_prev</code>恢复一下。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> padding &gt; <span class="number">0</span>:</span><br><span class="line">    dA_prev = dA_prev_pad[padding:-padding, padding:-padding, :]</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    dA_prev = dA_prev_pad</span><br><span class="line"><span class="keyword">return</span> dW, db, dA_prev</span><br></pre></td></tr></table></figure>
<p>这里有一个细节：如果<code>padding==0</code>，则在取切片时范围会变成<code>[0:-0]</code>，这样会取出一个长度为<code>0</code>的切片，而不是我们期望的原长度的切片。因此，要特判一下<code>padding&lt;=0</code>的情况。</p>
<h2 id="单元测试"><a href="#单元测试" class="headerlink" title="单元测试"></a>单元测试</h2><p>为了方便地进行单元测试，我使用了pytest这个单元测试库。可以直接pip一键安装：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install pytest</span><br></pre></td></tr></table></figure>
<p>之后就可以用pytest执行我的这份代码，代码里所有以<code>test_</code>开头的函数会被认为是单元测试的主函数。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pytest dldemos/BasicCNN/np_conv_backward.py</span><br></pre></td></tr></table></figure>
<p>单元测试函数的定义如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@pytest.mark.parametrize(<span class="params"><span class="string">&#x27;c_i, c_o&#x27;</span>, [(<span class="params"><span class="number">3</span>, <span class="number">6</span></span>), (<span class="params"><span class="number">2</span>, <span class="number">2</span></span>)]</span>)</span></span><br><span class="line"><span class="meta">@pytest.mark.parametrize(<span class="params"><span class="string">&#x27;kernel_size&#x27;</span>, [<span class="number">3</span>, <span class="number">5</span>]</span>)</span></span><br><span class="line"><span class="meta">@pytest.mark.parametrize(<span class="params"><span class="string">&#x27;stride&#x27;</span>, [<span class="number">1</span>, <span class="number">2</span>]</span>)</span></span><br><span class="line"><span class="meta">@pytest.mark.parametrize(<span class="params"><span class="string">&#x27;padding&#x27;</span>, [<span class="number">0</span>, <span class="number">1</span>]</span>)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">test_conv</span>(<span class="params">c_i: <span class="built_in">int</span>, c_o: <span class="built_in">int</span>, kernel_size: <span class="built_in">int</span>, stride: <span class="built_in">int</span>, padding: <span class="built_in">str</span></span>):</span></span><br></pre></td></tr></table></figure>
<p><code>@pytest.mark.parametrize</code>用于设置单元测试参数的可选值。我设置了4组参数，每组参数有2个可选值，经过排列组合后可以生成<code>2^4=16</code>个单元测试，pytest会自动帮我们执行不同的测试。</p>
<p>在单元测试中，我打算测试<code>conv2d</code>在各种输入通道数、输出通道数、卷积核大小、步幅、填充数的情况。</p>
<p>测试函数是这样写的：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">test_conv</span>(<span class="params">c_i: <span class="built_in">int</span>, c_o: <span class="built_in">int</span>, kernel_size: <span class="built_in">int</span>, stride: <span class="built_in">int</span>, padding: <span class="built_in">str</span></span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Preprocess</span></span><br><span class="line">    <span class="built_in">input</span> = np.random.randn(<span class="number">20</span>, <span class="number">20</span>, c_i)</span><br><span class="line">    weight = np.random.randn(c_o, kernel_size, kernel_size, c_i)</span><br><span class="line">    bias = np.random.randn(c_o)</span><br><span class="line"></span><br><span class="line">    torch_input = torch.from_numpy(np.transpose(</span><br><span class="line">        <span class="built_in">input</span>, (<span class="number">2</span>, <span class="number">0</span>, <span class="number">1</span>))).unsqueeze(<span class="number">0</span>).requires_grad_()</span><br><span class="line">    torch_weight = torch.from_numpy(np.transpose(</span><br><span class="line">        weight, (<span class="number">0</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>))).requires_grad_()</span><br><span class="line">    torch_bias = torch.from_numpy(bias).requires_grad_()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># forward</span></span><br><span class="line">    torch_output_tensor = torch.conv2d(torch_input, torch_weight, torch_bias,</span><br><span class="line">                                       stride, padding)</span><br><span class="line">    torch_output = np.transpose(</span><br><span class="line">        torch_output_tensor.detach().numpy().squeeze(<span class="number">0</span>), (<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>))</span><br><span class="line"></span><br><span class="line">    cache = conv2d_forward(<span class="built_in">input</span>, weight, bias, stride, padding)</span><br><span class="line">    numpy_output = cache[<span class="string">&#x27;Z&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">assert</span> np.allclose(torch_output, numpy_output)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># backward</span></span><br><span class="line">    torch_sum = torch.<span class="built_in">sum</span>(torch_output_tensor)</span><br><span class="line">    torch_sum.backward()</span><br><span class="line">    torch_dW = np.transpose(torch_weight.grad.numpy(), (<span class="number">0</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>))</span><br><span class="line">    torch_db = torch_bias.grad.numpy()</span><br><span class="line">    torch_dA_prev = np.transpose(torch_input.grad.numpy().squeeze(<span class="number">0</span>),</span><br><span class="line">                                 (<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>))</span><br><span class="line"></span><br><span class="line">    dZ = np.ones(numpy_output.shape)</span><br><span class="line">    dW, db, dA_prev = conv2d_backward(dZ, cache, stride, padding)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">assert</span> np.allclose(dW, torch_dW)</span><br><span class="line">    <span class="keyword">assert</span> np.allclose(db, torch_db)</span><br><span class="line">    <span class="keyword">assert</span> np.allclose(dA_prev, torch_dA_prev)</span><br></pre></td></tr></table></figure>
<p>整个测试函数可以分成三部分：变量预处理、前向传播、反向传播。在前向传播和反向传播中，我们要分别用刚编写的卷积核PyTorch中的卷积进行计算，并比较两个运算结果是否相同。</p>
<p>预处理时，我们要创建NumPy和PyTorch的输入。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Preprocess</span></span><br><span class="line"><span class="built_in">input</span> = np.random.randn(<span class="number">20</span>, <span class="number">20</span>, c_i)</span><br><span class="line">weight = np.random.randn(c_o, kernel_size, kernel_size, c_i)</span><br><span class="line">bias = np.random.randn(c_o)</span><br><span class="line"></span><br><span class="line">torch_input = torch.from_numpy(np.transpose(</span><br><span class="line">    <span class="built_in">input</span>, (<span class="number">2</span>, <span class="number">0</span>, <span class="number">1</span>))).unsqueeze(<span class="number">0</span>).requires_grad_()</span><br><span class="line">torch_weight = torch.from_numpy(np.transpose(</span><br><span class="line">    weight, (<span class="number">0</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>))).requires_grad_()</span><br><span class="line">torch_bias = torch.from_numpy(bias).requires_grad_()</span><br></pre></td></tr></table></figure>
<p>之后是正向传播。计算结果和中间变量会被存入<code>cache</code>中。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># forward</span></span><br><span class="line">torch_output_tensor = torch.conv2d(torch_input, torch_weight, torch_bias,</span><br><span class="line">                                    stride, padding)</span><br><span class="line">torch_output = np.transpose(</span><br><span class="line">    torch_output_tensor.detach().numpy().squeeze(<span class="number">0</span>), (<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>))</span><br><span class="line"></span><br><span class="line">cache = conv2d_forward(<span class="built_in">input</span>, weight, bias, stride, padding)</span><br><span class="line">numpy_output = cache[<span class="string">&#x27;Z&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="keyword">assert</span> np.allclose(torch_output, numpy_output)</span><br></pre></td></tr></table></figure>
<p>最后是反向传播。在那之前，要补充说明一下如何在PyTorch里手动求一些数据的导数。在PyTorch中，各个张量默认是不可训练的。为了让框架知道我们想求哪几个参数的导数，我们要执行张量的<code>required_grad_()</code>方法，如：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">torch_input = torch.from_numpy(np.transpose(</span><br><span class="line">        <span class="built_in">input</span>, (<span class="number">2</span>, <span class="number">0</span>, <span class="number">1</span>))).unsqueeze(<span class="number">0</span>).requires_grad_()</span><br></pre></td></tr></table></figure>
<p>这样，在正向传播时，PyTorch就会自动把对可训练参数的运算搭成计算图了。</p>
<p>正向传播后，对结果张量调用<code>backward()</code>即可执行反向传播。但是，PyTorch要求调用<code>backward()</code>的张量必须是一个标量，也就是它不能是矩阵，不能是任何长度大于1的数据。而这里PyTorch的卷积结果又是一个四维张量。因此，我把PyTorch卷积结果做了求和，得到了一个标量，用它来调用<code>backward()</code>。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">torch_sum = torch.<span class="built_in">sum</span>(torch_output_tensor)</span><br><span class="line">torch_sum.backward()</span><br></pre></td></tr></table></figure>
<p>这样，就可以用<code>tensor.grad</code>获取<code>tensor</code>的导数了，如</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">torch_weight.grad</span><br><span class="line">torch_bias.grad</span><br><span class="line">torch_input.grad</span><br></pre></td></tr></table></figure>
<p>整个反向传播测试的代码如下。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># backward</span></span><br><span class="line">torch_sum = torch.<span class="built_in">sum</span>(torch_output_tensor)</span><br><span class="line">torch_sum.backward()</span><br><span class="line">torch_dW = np.transpose(torch_weight.grad.numpy(), (<span class="number">0</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>))</span><br><span class="line">torch_db = torch_bias.grad.numpy()</span><br><span class="line">torch_dA_prev = np.transpose(torch_input.grad.numpy().squeeze(<span class="number">0</span>),</span><br><span class="line">                                (<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>))</span><br><span class="line"></span><br><span class="line">dZ = np.ones(numpy_output.shape)</span><br><span class="line">dW, db, dA_prev = conv2d_backward(dZ, cache, stride, padding)</span><br></pre></td></tr></table></figure>
<p>再补充一下，在求导时，运算结果的导数是1。因此，新建<code>dZ</code>时，我用的是<code>np.ones</code>（全1张量）。同理，PyTorch也会默认运算结果的导数为1，即这里<code>torch_sum.grad==1</code>。而执行加法运算不会改变导数，所以<code>torch_output_tensor.grad</code>也是一个全是1的张量，和NumPy的<code>dZ</code>的值是一模一样的。</p>
<p>写完单元测试函数后，运行前面提到的单元测试命令，pytest就会输出很多测试的结果。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pytest dldemos/BasicCNN/np_conv_backward.py</span><br></pre></td></tr></table></figure>
<p>如果看到了类似的输出，就说明我们的代码是正确的。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">==== 16 passed in 1.04s ====</span><br></pre></td></tr></table></figure>
<h2 id="反向传播的编写思路"><a href="#反向传播的编写思路" class="headerlink" title="反向传播的编写思路"></a>反向传播的编写思路</h2><p>通过阅读上面的实现过程，相信大家已经明白如何编写卷积的反向传播了。接下来，我将总结一下实现一般算子的正向、反向传播的思路。无论是用NumPy，还是PyTorch等编程框架，甚至是纯C++，这种思路都是适用的。</p>
<p>一开始，我们要明白，一个算子总共会涉及到这些参数：</p>
<ul>
<li>输入与输出：算子的输入张量和输出张量。正向传播和反向传播的输入输出恰好是相反的。</li>
<li>属性：算子的超参数。比如卷积的<code>stride, padding</code>。</li>
<li>中间变量：前向传播传递给反向传播的变量。</li>
</ul>
<p>一般情况下，我们应该编写一个算子类。在初始化算子类时，算子的属性就以类属性的形式存储下来了。</p>
<p>在正向传播时，我们按照算子定义直接顺着写下去就行。这个时候，可以先准备好<code>cache</code>变量，但先不去管它，等写到反向传播的时候再处理。</p>
<p>接着，编写反向传播。由于反向传播和正向传播的运算步骤相似，我们可以直接把正向传播的代码复制一份。在这个基础上，思考每一步正向传播运算产生了哪些导数，对照着写出导数计算的代码即可。这时，我们会用到一些正向传播的中间结果，这下就可以去正向传播代码里填写<code>cache</code>，在反向传播里取出来了。</p>
<p>最后，写完了算子，一定要做单元测试。如果该算子有现成的实现，用现成的实现来对齐运算结果是最简单的一种实现单元测试的方式。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>在这篇文章中，我介绍了以下内容：</p>
<ul>
<li>卷积反向传播的NumPy实现</li>
<li>如何用PyTorch手动求导</li>
<li>如何编写完整的算子单元测试</li>
<li>实现算子正向传播、反向传播的思路</li>
</ul>
<p>如果你也想把代码基础打牢，一定一定要像这样自己动手从头写一份代码。在写代码，调bug的过程中，一定会有很多收获。</p>
<p>由于现在的编程框架都比较成熟，搞科研时基本不会碰到自己动手写底层算子的情况。但是，如果你想出了一个特别棒的idea，想出了一个全新的神经网络模块，却在写代码时碰到了阻碍，那可就太可惜了。学一学反向传播的实现还是很有用的。</p>
<p>在模型部署中，反向传播可能完全派不上用场。但是，一般框架在实现算子的正向传播时，是会照顾反向传播的。也就是说，如果抛掉反向传播，正向传播的实现或许可以写得更加高效。这样看来，了解反向传播的实现也是很有帮助的。我们可以用这些知识看懂别人的正向传播、反向传播的实现，进而优化代码的性能。</p>
<h2 id="附录：完整代码"><a href="#附录：完整代码" class="headerlink" title="附录：完整代码"></a>附录：完整代码</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> <span class="type">Dict</span>, <span class="type">Tuple</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pytest</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">conv2d_forward</span>(<span class="params"><span class="built_in">input</span>: np.ndarray, weight: np.ndarray, bias: np.ndarray,</span></span></span><br><span class="line"><span class="params"><span class="function">                   stride: <span class="built_in">int</span>, padding: <span class="built_in">int</span></span>) -&gt; <span class="type">Dict</span>[<span class="built_in">str</span>, np.ndarray]:</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;2D Convolution Forward Implemented with NumPy</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        input (np.ndarray): The input NumPy array of shape (H, W, C).</span></span><br><span class="line"><span class="string">        weight (np.ndarray): The weight NumPy array of shape</span></span><br><span class="line"><span class="string">            (C&#x27;, F, F, C).</span></span><br><span class="line"><span class="string">        bias (np.ndarray | None): The bias NumPy array of shape (C&#x27;).</span></span><br><span class="line"><span class="string">            Default: None.</span></span><br><span class="line"><span class="string">        stride (int): Stride for convolution.</span></span><br><span class="line"><span class="string">        padding (int): The count of zeros to pad on both sides.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Outputs:</span></span><br><span class="line"><span class="string">        Dict[str, np.ndarray]: Cached data for backward prop.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    h_i, w_i, c_i = <span class="built_in">input</span>.shape</span><br><span class="line">    c_o, f, f_2, c_k = weight.shape</span><br><span class="line"></span><br><span class="line">    <span class="keyword">assert</span> (f == f_2)</span><br><span class="line">    <span class="keyword">assert</span> (c_i == c_k)</span><br><span class="line">    <span class="keyword">assert</span> (bias.shape[<span class="number">0</span>] == c_o)</span><br><span class="line"></span><br><span class="line">    input_pad = np.pad(<span class="built_in">input</span>, [(padding, padding), (padding, padding), (<span class="number">0</span>, <span class="number">0</span>)])</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">cal_new_sidelngth</span>(<span class="params">sl, s, f, p</span>):</span></span><br><span class="line">        <span class="keyword">return</span> (sl + <span class="number">2</span> * p - f) // s + <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    h_o = cal_new_sidelngth(h_i, stride, f, padding)</span><br><span class="line">    w_o = cal_new_sidelngth(w_i, stride, f, padding)</span><br><span class="line"></span><br><span class="line">    output = np.empty((h_o, w_o, c_o), dtype=<span class="built_in">input</span>.dtype)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i_h <span class="keyword">in</span> <span class="built_in">range</span>(h_o):</span><br><span class="line">        <span class="keyword">for</span> i_w <span class="keyword">in</span> <span class="built_in">range</span>(w_o):</span><br><span class="line">            <span class="keyword">for</span> i_c <span class="keyword">in</span> <span class="built_in">range</span>(c_o):</span><br><span class="line">                h_lower = i_h * stride</span><br><span class="line">                h_upper = i_h * stride + f</span><br><span class="line">                w_lower = i_w * stride</span><br><span class="line">                w_upper = i_w * stride + f</span><br><span class="line">                input_slice = input_pad[h_lower:h_upper, w_lower:w_upper, :]</span><br><span class="line">                kernel_slice = weight[i_c]</span><br><span class="line">                output[i_h, i_w, i_c] = np.<span class="built_in">sum</span>(input_slice * kernel_slice)</span><br><span class="line">                output[i_h, i_w, i_c] += bias[i_c]</span><br><span class="line"></span><br><span class="line">    cache = <span class="built_in">dict</span>()</span><br><span class="line">    cache[<span class="string">&#x27;Z&#x27;</span>] = output</span><br><span class="line">    cache[<span class="string">&#x27;W&#x27;</span>] = weight</span><br><span class="line">    cache[<span class="string">&#x27;b&#x27;</span>] = bias</span><br><span class="line">    cache[<span class="string">&#x27;A_prev&#x27;</span>] = <span class="built_in">input</span></span><br><span class="line">    <span class="keyword">return</span> cache</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">conv2d_backward</span>(<span class="params">dZ: np.ndarray, cache: <span class="type">Dict</span>[<span class="built_in">str</span>, np.ndarray], stride: <span class="built_in">int</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">                    padding: <span class="built_in">int</span></span>) -&gt; <span class="type">Tuple</span>[np.ndarray, np.ndarray, np.ndarray]:</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;2D Convolution Backward Implemented with NumPy</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        dZ: (np.ndarray): The derivative of the output of conv.</span></span><br><span class="line"><span class="string">        cache (Dict[str, np.ndarray]): Record output &#x27;Z&#x27;, weight &#x27;W&#x27;, bias &#x27;b&#x27;</span></span><br><span class="line"><span class="string">            and input &#x27;A_prev&#x27; of forward function.</span></span><br><span class="line"><span class="string">        stride (int): Stride for convolution.</span></span><br><span class="line"><span class="string">        padding (int): The count of zeros to pad on both sides.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Outputs:</span></span><br><span class="line"><span class="string">        Tuple[np.ndarray, np.ndarray, np.ndarray]: The derivative of W, b,</span></span><br><span class="line"><span class="string">            A_prev.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    W = cache[<span class="string">&#x27;W&#x27;</span>]</span><br><span class="line">    b = cache[<span class="string">&#x27;b&#x27;</span>]</span><br><span class="line">    A_prev = cache[<span class="string">&#x27;A_prev&#x27;</span>]</span><br><span class="line">    dW = np.zeros(W.shape)</span><br><span class="line">    db = np.zeros(b.shape)</span><br><span class="line">    dA_prev = np.zeros(A_prev.shape)</span><br><span class="line"></span><br><span class="line">    _, _, c_i = A_prev.shape</span><br><span class="line">    c_o, f, f_2, c_k = W.shape</span><br><span class="line">    h_o, w_o, c_o_2 = dZ.shape</span><br><span class="line"></span><br><span class="line">    <span class="keyword">assert</span> (f == f_2)</span><br><span class="line">    <span class="keyword">assert</span> (c_i == c_k)</span><br><span class="line">    <span class="keyword">assert</span> (c_o == c_o_2)</span><br><span class="line"></span><br><span class="line">    A_prev_pad = np.pad(A_prev, [(padding, padding), (padding, padding),</span><br><span class="line">                                 (<span class="number">0</span>, <span class="number">0</span>)])</span><br><span class="line">    dA_prev_pad = np.pad(dA_prev, [(padding, padding), (padding, padding),</span><br><span class="line">                                   (<span class="number">0</span>, <span class="number">0</span>)])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i_h <span class="keyword">in</span> <span class="built_in">range</span>(h_o):</span><br><span class="line">        <span class="keyword">for</span> i_w <span class="keyword">in</span> <span class="built_in">range</span>(w_o):</span><br><span class="line">            <span class="keyword">for</span> i_c <span class="keyword">in</span> <span class="built_in">range</span>(c_o):</span><br><span class="line">                h_lower = i_h * stride</span><br><span class="line">                h_upper = i_h * stride + f</span><br><span class="line">                w_lower = i_w * stride</span><br><span class="line">                w_upper = i_w * stride + f</span><br><span class="line"></span><br><span class="line">                input_slice = A_prev_pad[h_lower:h_upper, w_lower:w_upper, :]</span><br><span class="line">                <span class="comment"># forward</span></span><br><span class="line">                <span class="comment"># kernel_slice = W[i_c]</span></span><br><span class="line">                <span class="comment"># Z[i_h, i_w, i_c] = np.sum(input_slice * kernel_slice)</span></span><br><span class="line">                <span class="comment"># Z[i_h, i_w, i_c] += b[i_c]</span></span><br><span class="line"></span><br><span class="line">                <span class="comment"># backward</span></span><br><span class="line">                dW[i_c] += input_slice * dZ[i_h, i_w, i_c]</span><br><span class="line">                dA_prev_pad[h_lower:h_upper,</span><br><span class="line">                            w_lower:w_upper, :] += W[i_c] * dZ[i_h, i_w, i_c]</span><br><span class="line">                db[i_c] += dZ[i_h, i_w, i_c]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> padding &gt; <span class="number">0</span>:</span><br><span class="line">        dA_prev = dA_prev_pad[padding:-padding, padding:-padding, :]</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        dA_prev = dA_prev_pad</span><br><span class="line">    <span class="keyword">return</span> dW, db, dA_prev</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@pytest.mark.parametrize(<span class="params"><span class="string">&#x27;c_i, c_o&#x27;</span>, [(<span class="params"><span class="number">3</span>, <span class="number">6</span></span>), (<span class="params"><span class="number">2</span>, <span class="number">2</span></span>)]</span>)</span></span><br><span class="line"><span class="meta">@pytest.mark.parametrize(<span class="params"><span class="string">&#x27;kernel_size&#x27;</span>, [<span class="number">3</span>, <span class="number">5</span>]</span>)</span></span><br><span class="line"><span class="meta">@pytest.mark.parametrize(<span class="params"><span class="string">&#x27;stride&#x27;</span>, [<span class="number">1</span>, <span class="number">2</span>]</span>)</span></span><br><span class="line"><span class="meta">@pytest.mark.parametrize(<span class="params"><span class="string">&#x27;padding&#x27;</span>, [<span class="number">0</span>, <span class="number">1</span>]</span>)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">test_conv</span>(<span class="params">c_i: <span class="built_in">int</span>, c_o: <span class="built_in">int</span>, kernel_size: <span class="built_in">int</span>, stride: <span class="built_in">int</span>, padding: <span class="built_in">str</span></span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Preprocess</span></span><br><span class="line">    <span class="built_in">input</span> = np.random.randn(<span class="number">20</span>, <span class="number">20</span>, c_i)</span><br><span class="line">    weight = np.random.randn(c_o, kernel_size, kernel_size, c_i)</span><br><span class="line">    bias = np.random.randn(c_o)</span><br><span class="line"></span><br><span class="line">    torch_input = torch.from_numpy(np.transpose(</span><br><span class="line">        <span class="built_in">input</span>, (<span class="number">2</span>, <span class="number">0</span>, <span class="number">1</span>))).unsqueeze(<span class="number">0</span>).requires_grad_()</span><br><span class="line">    torch_weight = torch.from_numpy(np.transpose(</span><br><span class="line">        weight, (<span class="number">0</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>))).requires_grad_()</span><br><span class="line">    torch_bias = torch.from_numpy(bias).requires_grad_()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># forward</span></span><br><span class="line">    torch_output_tensor = torch.conv2d(torch_input, torch_weight, torch_bias,</span><br><span class="line">                                       stride, padding)</span><br><span class="line">    torch_output = np.transpose(</span><br><span class="line">        torch_output_tensor.detach().numpy().squeeze(<span class="number">0</span>), (<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>))</span><br><span class="line"></span><br><span class="line">    cache = conv2d_forward(<span class="built_in">input</span>, weight, bias, stride, padding)</span><br><span class="line">    numpy_output = cache[<span class="string">&#x27;Z&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">assert</span> np.allclose(torch_output, numpy_output)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># backward</span></span><br><span class="line">    torch_sum = torch.<span class="built_in">sum</span>(torch_output_tensor)</span><br><span class="line">    torch_sum.backward()</span><br><span class="line">    torch_dW = np.transpose(torch_weight.grad.numpy(), (<span class="number">0</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>))</span><br><span class="line">    torch_db = torch_bias.grad.numpy()</span><br><span class="line">    torch_dA_prev = np.transpose(torch_input.grad.numpy().squeeze(<span class="number">0</span>),</span><br><span class="line">                                 (<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>))</span><br><span class="line"></span><br><span class="line">    dZ = np.ones(numpy_output.shape)</span><br><span class="line">    dW, db, dA_prev = conv2d_backward(dZ, cache, stride, padding)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">assert</span> np.allclose(dW, torch_dW)</span><br><span class="line">    <span class="keyword">assert</span> np.allclose(db, torch_db)</span><br><span class="line">    <span class="keyword">assert</span> np.allclose(dA_prev, torch_dA_prev)</span><br></pre></td></tr></table></figure>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://zhouyifan.net/2022/07/24/DLS-note-10-4/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Zhou Yifan">
      <meta itemprop="description" content="A foresighted strategist with big-picture thinking. 大局观选手。">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="周弈帆的博客">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/07/24/DLS-note-10-4/" class="post-title-link" itemprop="url">吴恩达《深度学习专项》代码实战（十）：3.用 NumPy 复现参数一致的 torch.conv2d 前向传播</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-07-24 00:30:59" itemprop="dateCreated datePublished" datetime="2022-07-24T00:30:59+08:00">2022-07-24</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">学习</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E5%AD%A6%E4%B9%A0/%E7%9F%A5%E8%AF%86%E8%AE%B0%E5%BD%95/" itemprop="url" rel="index"><span itemprop="name">知识记录</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>《深度学习专项》只介绍了卷积的stride, padding这两个参数。实际上，编程框架中常用的卷积还有其他几个参数。在这篇文章里，我会介绍如何用NumPy复现PyTorch中的二维卷积<code>torch.conv2d</code>的前向传播。如果大家也想多学一点的话，建议看完本文后也<strong>自己动手</strong>写一遍卷积，彻底理解卷积中常见的参数。</p>
<p>项目网址：<a target="_blank" rel="noopener" href="https://github.com/SingleZombie/DL-Demos/tree/master/dldemos/BasicCNN">https://github.com/SingleZombie/DL-Demos/tree/master/dldemos/BasicCNN</a></p>
<p>本文代码在<code>dldemos/BasicCNN/np_conv.py</code>这个文件里。</p>
<h2 id="卷积参数介绍"><a href="#卷积参数介绍" class="headerlink" title="卷积参数介绍"></a>卷积参数介绍</h2><p>与<code>torch.conv2d</code>类似，在这份实现中，我们的卷积应该有类似如下的函数定义（张量的形状写在docstring中）：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">conv2d</span>(<span class="params"><span class="built_in">input</span>: np.ndarray,</span></span></span><br><span class="line"><span class="params"><span class="function">           weight: np.ndarray,</span></span></span><br><span class="line"><span class="params"><span class="function">           stride: <span class="built_in">int</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">           padding: <span class="built_in">int</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">           dilation: <span class="built_in">int</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">           groups: <span class="built_in">int</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">           bias: np.ndarray = <span class="literal">None</span></span>) -&gt; np.ndarray:</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;2D Convolution Implemented with NumPy</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        input (np.ndarray): The input NumPy array of shape (H, W, C).</span></span><br><span class="line"><span class="string">        weight (np.ndarray): The weight NumPy array of shape</span></span><br><span class="line"><span class="string">            (C&#x27;, F, F, C / groups).</span></span><br><span class="line"><span class="string">        stride (int): Stride for convolution.</span></span><br><span class="line"><span class="string">        padding (int): The count of zeros to pad on both sides.</span></span><br><span class="line"><span class="string">        dilation (int): The space between kernel elements.</span></span><br><span class="line"><span class="string">        groups (int): Split the input to groups.</span></span><br><span class="line"><span class="string">        bias (np.ndarray | None): The bias NumPy array of shape (C&#x27;).</span></span><br><span class="line"><span class="string">            Default: None.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Outputs:</span></span><br><span class="line"><span class="string">        np.ndarray: The output NumPy array of shape (H&#x27;, W&#x27;, C&#x27;)</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure></p>
<p>我们知道，对于不加任何参数的卷积，其计算方式如下：</p>
<p><img src="/2022/07/24/DLS-note-10-4/1.gif" alt></p>
<p>此图中，下面蓝色的区域是一张$4 \times 4$的输入图片，输入图片上深蓝色的区域是一个$3 \times 3$的卷积核。这样，会生成上面那个$2 \times 2$的绿色的输出图片。每轮计算输出图片上一个深绿色的元素时，卷积核所在位置会标出来。</p>
<p>接下来，使用类似图例，我们来看看卷积各参数的详细解释。</p>
<h3 id="stride（步幅）"><a href="#stride（步幅）" class="headerlink" title="stride（步幅）"></a>stride（步幅）</h3><p><img src="/2022/07/24/DLS-note-10-4/2.gif" alt></p>
<p>每轮计算后，卷积核向右或向下移动多格，而不仅仅是1格。每轮移动的格子数用stride表示。上图是stride=2的情况。</p>
<h3 id="padding（填充数）"><a href="#padding（填充数）" class="headerlink" title="padding（填充数）"></a>padding（填充数）</h3><p><img src="/2022/07/24/DLS-note-10-4/3.gif" alt></p>
<p>卷积开始前，向输入图片四周填充数字（最常见的情况是填充0），填充的数字个数用padding表示。这样，输出图片的边长会更大一些。一般我们会为了让输出图片和输入图片一样大而调整padding，比如上图那种padding=1的情况。</p>
<h3 id="dilation（扩充数）"><a href="#dilation（扩充数）" class="headerlink" title="dilation（扩充数）"></a>dilation（扩充数）</h3><p><img src="/2022/07/24/DLS-note-10-4/4.gif" alt></p>
<p>被卷积的相邻像素之间有间隔，这个间隔等于dilation。等价于在卷积核相邻位置之间填0，再做普通的卷积。上图是dilation=2的情况。</p>
<blockquote>
<p>dliated convolution 被翻译成空洞卷积。</p>
</blockquote>
<h3 id="groups（分组数）"><a href="#groups（分组数）" class="headerlink" title="groups（分组数）"></a>groups（分组数）</h3><p>下图展示了输入通道数12，输出通道数6的卷积在两种不同groups下的情况。左边是group=1的普通卷积，右边是groups=3的分组卷积。在具体看分组卷积的介绍前，大家可以先仔细观察这张图，看看能不能猜出分组卷积是怎么运算的。</p>
<p><img src="/2022/07/24/DLS-note-10-4/1.png" alt></p>
<p>当输入图片有多个通道时，卷积核也应该有相同数量的通道。输入图片的形状是(H, W, C)的话，卷积核的形状就应该是(f, f, C)。</p>
<p>但是，这样一轮运算只能算出一张单通道的图片。为了算多通道的图片，应该使用多个卷积核。因此，如果输入图片的形状是(H, W, C)，想要生成(H, W, C’)的输出图片，则应该有C’个形状为(f, f, C)的卷积核，或者说卷积核组的形状是(C’, f, f, C)。</p>
<p>如分组卷积示意图的左图所示，对于普通卷积，每一个输出通道都需要用到所有输入通道的数据。为了减少计算量，我们可以把输入通道和输出通道分组。每组的输出通道仅由该组的输入通道决定。如示意图的右图所示，我们令分组数groups=3，这样，一共有6个卷积核，每组的输入通道有4个，输出通道有2个（即使用2个卷积核）。这时候，卷积核组的形状应该是(C’=6, f, f, C=4)。</p>
<blockquote>
<p>groups最常见的应用是令groups=C，即depth-wise convolution。《深度学习专项》第四门课第二周会介绍有关的知识。</p>
</blockquote>
<h2 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h2><p>理解了所有参数，下面让我们来用NumPy实现这样一个卷积。</p>
<p>完整的代码是：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">conv2d</span>(<span class="params"><span class="built_in">input</span>: np.ndarray,</span></span></span><br><span class="line"><span class="params"><span class="function">           weight: np.ndarray,</span></span></span><br><span class="line"><span class="params"><span class="function">           stride: <span class="built_in">int</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">           padding: <span class="built_in">int</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">           dilation: <span class="built_in">int</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">           groups: <span class="built_in">int</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">           bias: np.ndarray = <span class="literal">None</span></span>) -&gt; np.ndarray:</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;2D Convolution Implemented with NumPy</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        input (np.ndarray): The input NumPy array of shape (H, W, C).</span></span><br><span class="line"><span class="string">        weight (np.ndarray): The weight NumPy array of shape</span></span><br><span class="line"><span class="string">            (C&#x27;, F, F, C / groups).</span></span><br><span class="line"><span class="string">        stride (int): Stride for convolution.</span></span><br><span class="line"><span class="string">        padding (int): The count of zeros to pad on both sides.</span></span><br><span class="line"><span class="string">        dilation (int): The space between kernel elements.</span></span><br><span class="line"><span class="string">        groups (int): Split the input to groups.</span></span><br><span class="line"><span class="string">        bias (np.ndarray | None): The bias NumPy array of shape (C&#x27;).</span></span><br><span class="line"><span class="string">            Default: None.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Outputs:</span></span><br><span class="line"><span class="string">        np.ndarray: The output NumPy array of shape (H&#x27;, W&#x27;, C&#x27;)</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    h_i, w_i, c_i = <span class="built_in">input</span>.shape</span><br><span class="line">    c_o, f, f_2, c_k = weight.shape</span><br><span class="line"></span><br><span class="line">    <span class="keyword">assert</span> (f == f_2)</span><br><span class="line">    <span class="keyword">assert</span> (c_i % groups == <span class="number">0</span>)</span><br><span class="line">    <span class="keyword">assert</span> (c_o % groups == <span class="number">0</span>)</span><br><span class="line">    <span class="keyword">assert</span> (c_i // groups == c_k)</span><br><span class="line">    <span class="keyword">if</span> bias <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        <span class="keyword">assert</span> (bias.shape[<span class="number">0</span>] == c_o)</span><br><span class="line"></span><br><span class="line">    f_new = f + (f - <span class="number">1</span>) * (dilation - <span class="number">1</span>)</span><br><span class="line">    weight_new = np.zeros((c_o, f_new, f_new, c_k), dtype=weight.dtype)</span><br><span class="line">    <span class="keyword">for</span> i_c_o <span class="keyword">in</span> <span class="built_in">range</span>(c_o):</span><br><span class="line">        <span class="keyword">for</span> i_c_k <span class="keyword">in</span> <span class="built_in">range</span>(c_k):</span><br><span class="line">            <span class="keyword">for</span> i_f <span class="keyword">in</span> <span class="built_in">range</span>(f):</span><br><span class="line">                <span class="keyword">for</span> j_f <span class="keyword">in</span> <span class="built_in">range</span>(f):</span><br><span class="line">                    i_f_new = i_f * dilation</span><br><span class="line">                    j_f_new = j_f * dilation</span><br><span class="line">                    weight_new[i_c_o, i_f_new, j_f_new, i_c_k] = \</span><br><span class="line">                        weight[i_c_o, i_f, j_f, i_c_k]</span><br><span class="line"></span><br><span class="line">    input_pad = np.pad(<span class="built_in">input</span>, [(padding, padding), (padding, padding), (<span class="number">0</span>, <span class="number">0</span>)])</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">cal_new_sidelngth</span>(<span class="params">sl, s, f, p</span>):</span></span><br><span class="line">        <span class="keyword">return</span> (sl + <span class="number">2</span> * p - f) // s + <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    h_o = cal_new_sidelngth(h_i, stride, f_new, padding)</span><br><span class="line">    w_o = cal_new_sidelngth(w_i, stride, f_new, padding)</span><br><span class="line"></span><br><span class="line">    output = np.empty((h_o, w_o, c_o), dtype=<span class="built_in">input</span>.dtype)</span><br><span class="line"></span><br><span class="line">    c_o_per_group = c_o // groups</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i_h <span class="keyword">in</span> <span class="built_in">range</span>(h_o):</span><br><span class="line">        <span class="keyword">for</span> i_w <span class="keyword">in</span> <span class="built_in">range</span>(w_o):</span><br><span class="line">            <span class="keyword">for</span> i_c <span class="keyword">in</span> <span class="built_in">range</span>(c_o):</span><br><span class="line">                i_g = i_c // c_o_per_group</span><br><span class="line">                h_lower = i_h * stride</span><br><span class="line">                h_upper = i_h * stride + f_new</span><br><span class="line">                w_lower = i_w * stride</span><br><span class="line">                w_upper = i_w * stride + f_new</span><br><span class="line">                c_lower = i_g * c_k</span><br><span class="line">                c_upper = (i_g + <span class="number">1</span>) * c_k</span><br><span class="line">                input_slice = input_pad[h_lower:h_upper, w_lower:w_upper,</span><br><span class="line">                                        c_lower:c_upper]</span><br><span class="line">                kernel_slice = weight_new[i_c]</span><br><span class="line">                output[i_h, i_w, i_c] = np.<span class="built_in">sum</span>(input_slice * kernel_slice)</span><br><span class="line">                <span class="keyword">if</span> bias:</span><br><span class="line">                    output[i_h, i_w, i_c] += bias[i_c]</span><br><span class="line">    <span class="keyword">return</span> output</span><br></pre></td></tr></table></figure>
<p>先回顾一下我们要用到的参数。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">conv2d</span>(<span class="params"><span class="built_in">input</span>: np.ndarray,</span></span></span><br><span class="line"><span class="params"><span class="function">           weight: np.ndarray,</span></span></span><br><span class="line"><span class="params"><span class="function">           stride: <span class="built_in">int</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">           padding: <span class="built_in">int</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">           dilation: <span class="built_in">int</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">           groups: <span class="built_in">int</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">           bias: np.ndarray = <span class="literal">None</span></span>) -&gt; np.ndarray:</span></span><br></pre></td></tr></table></figure>
<p>再次提醒，<code>input</code>的形状是<code>(H, W, C)</code>，卷积核组<code>weight</code>的形状是<code>(C&#39;, H, W, C_k)</code>。其中<code>C_k = C / groups</code>。同时<code>C&#39;</code>也必须能够被<code>groups</code>整除。<code>bias</code>的形状是<code>(C&#39;)</code>。</p>
<p>一开始，把要用到的形状从<code>shape</code>里取出来，并检查一下形状是否满足要求。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">h_i, w_i, c_i = <span class="built_in">input</span>.shape</span><br><span class="line">c_o, f, f_2, c_k = weight.shape</span><br><span class="line"></span><br><span class="line"><span class="keyword">assert</span> (f == f_2)</span><br><span class="line"><span class="keyword">assert</span> (c_i % groups == <span class="number">0</span>)</span><br><span class="line"><span class="keyword">assert</span> (c_o % groups == <span class="number">0</span>)</span><br><span class="line"><span class="keyword">assert</span> (c_i // groups == c_k)</span><br><span class="line"><span class="keyword">if</span> bias <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">    <span class="keyword">assert</span> (bias.shape[<span class="number">0</span>] == c_o)</span><br></pre></td></tr></table></figure>
<p>回忆一下，空洞卷积可以用卷积核扩充实现。因此，在开始卷积前，可以先预处理好扩充后的卷积核。我们先算好扩充后卷积核的形状，并创建好新的卷积核，最后用多重循环给新卷积核赋值。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">f_new = f + (f - <span class="number">1</span>) * (dilation - <span class="number">1</span>)</span><br><span class="line">    weight_new = np.zeros((c_o, f_new, f_new, c_k), dtype=weight.dtype)</span><br><span class="line">    <span class="keyword">for</span> i_c_o <span class="keyword">in</span> <span class="built_in">range</span>(c_o):</span><br><span class="line">        <span class="keyword">for</span> i_c_k <span class="keyword">in</span> <span class="built_in">range</span>(c_k):</span><br><span class="line">            <span class="keyword">for</span> i_f <span class="keyword">in</span> <span class="built_in">range</span>(f):</span><br><span class="line">                <span class="keyword">for</span> j_f <span class="keyword">in</span> <span class="built_in">range</span>(f):</span><br><span class="line">                    i_f_new = i_f * dilation</span><br><span class="line">                    j_f_new = j_f * dilation</span><br><span class="line">                    weight_new[i_c_o, i_f_new, j_f_new, i_c_k] = \</span><br><span class="line">                        weight[i_c_o, i_f, j_f, i_c_k]</span><br></pre></td></tr></table></figure>
<p>接下来，我们要考虑padding。<code>np.pad</code>就是填充操作使用的函数。该函数第一个参数是输入，第二个参数是填充数量，要分别写出每个维度上左上和右下的填充数量。我们只填充图片的前两维，并且左上和右下填的数量一样多。因此，填充的写法如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">input_pad = np.pad(<span class="built_in">input</span>, [(padding, padding), (padding, padding), (<span class="number">0</span>, <span class="number">0</span>)])</span><br></pre></td></tr></table></figure>
<p>预处理都做好了，马上要开始卷积计算了。在计算开始前，我们还要把算出输出张量的形状并将其初始化。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">cal_new_sidelngth</span>(<span class="params">sl, s, f, p</span>):</span></span><br><span class="line">    <span class="keyword">return</span> (sl + <span class="number">2</span> * p - f) // s + <span class="number">1</span></span><br><span class="line"></span><br><span class="line">h_o = cal_new_sidelngth(h_i, stride, f_new, padding)</span><br><span class="line">w_o = cal_new_sidelngth(w_i, stride, f_new, padding)</span><br><span class="line"></span><br><span class="line">output = np.empty((h_o, w_o, c_o), dtype=<span class="built_in">input</span>.dtype)</span><br></pre></td></tr></table></figure>
<p>为严谨起见，我这里用统一的函数计算了卷积后的宽高。不考虑dilation的边长公式由<code>cal_new_sidelngth</code>表示。如果对这个公式不理解，可以自己推一推。而考虑dilation时，只需要把原来的卷积核长度<code>f</code>换成新卷积核长度<code>f_new</code>即可。</p>
<blockquote>
<p>初始化<code>output</code>时，我没有像前面初始化<code>weight_new</code>一样使用<code>np.zeros</code>，而是用了<code>np.empty</code>。这是因为<code>weight_new</code>会有一些地方不被访问到，这些地方都应该填0。而<code>output</code>每一个元素都会被访问到并赋值，可以不用令它们初值为0。理论上，<code>np.empty</code>这种不限制初值的初始化方式是最快的，只是使用时一定别忘了要先给每个元素赋值。这种严谨的算法实现思维还是挺重要的，尤其是在用C++实现高性能的底层算法时。</p>
</blockquote>
<p>终于，可以进行卷积计算了。这部分的代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">c_o_per_group = c_o // groups</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i_h <span class="keyword">in</span> <span class="built_in">range</span>(h_o):</span><br><span class="line">    <span class="keyword">for</span> i_w <span class="keyword">in</span> <span class="built_in">range</span>(w_o):</span><br><span class="line">        <span class="keyword">for</span> i_c <span class="keyword">in</span> <span class="built_in">range</span>(c_o):</span><br><span class="line">            i_g = i_c // c_o_per_group</span><br><span class="line">            h_lower = i_h * stride</span><br><span class="line">            h_upper = i_h * stride + f_new</span><br><span class="line">            w_lower = i_w * stride</span><br><span class="line">            w_upper = i_w * stride + f_new</span><br><span class="line">            c_lower = i_g * c_k</span><br><span class="line">            c_upper = (i_g + <span class="number">1</span>) * c_k</span><br><span class="line">            input_slice = input_pad[h_lower:h_upper, w_lower:w_upper,</span><br><span class="line">                                    c_lower:c_upper]</span><br><span class="line">            kernel_slice = weight_new[i_c]</span><br><span class="line">            output[i_h, i_w, i_c] = np.<span class="built_in">sum</span>(input_slice * kernel_slice)</span><br><span class="line">            <span class="keyword">if</span> bias:</span><br><span class="line">                output[i_h, i_w, i_c] += bias[i_c]</span><br></pre></td></tr></table></figure>
<p>来一点一点看这段代码。</p>
<p><code>c_o_per_group = c_o // groups</code>预处理了每组的输出通道数，后面会用到这个数。</p>
<p>为了填入输出张量每一处的值，我们应该遍历输出张量的每一个元素的下标：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i_h <span class="keyword">in</span> <span class="built_in">range</span>(h_o):</span><br><span class="line">    <span class="keyword">for</span> i_w <span class="keyword">in</span> <span class="built_in">range</span>(w_o):</span><br><span class="line">        <span class="keyword">for</span> i_c <span class="keyword">in</span> <span class="built_in">range</span>(c_o):</span><br></pre></td></tr></table></figure>
<p>做卷积时，我们要获取两个东西：被卷积的原图像上的数据、卷积用的卷积核。所以，下一步应该去获取原图像上的数据切片。这个切片可以这样表示</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">input_slice = input_pad[h_lower:h_upper, w_lower:w_upper,</span><br><span class="line">                                    c_lower:c_upper]</span><br></pre></td></tr></table></figure>
<p>宽和高上的截取范围很好计算。只要根据<code>stride</code>确认截取起点，再加上<code>f_new</code>就得到了截取终点。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">h_lower = i_h * stride</span><br><span class="line">h_upper = i_h * stride + f_new</span><br><span class="line">w_lower = i_w * stride</span><br><span class="line">w_upper = i_w * stride + f_new</span><br></pre></td></tr></table></figure>
<p>比较难想的是考虑groups后，通道上的截取范围该怎么获得。这里，不妨再看一次分组卷积的示意图：</p>
<p><img src="/2022/07/24/DLS-note-10-4/1.png" alt></p>
<p>获取通道上的截取范围，就是获取右边那幅图中的输入通道组。究竟是红色的1-4，还是绿色的5-8，还是黄色的9-12。为了知道是哪一个范围，我们要算出当前输出通道对应的组号（颜色），这个组号由下面的算式获得：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">i_g = i_c // c_o_per_group</span><br></pre></td></tr></table></figure>
<p>有了组号，就可以方便地计算通道上的截取范围了。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">c_lower = i_g * c_k</span><br><span class="line">c_upper = (i_g + <span class="number">1</span>) * c_k</span><br></pre></td></tr></table></figure>
<p>整个获取输入切片的代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">i_g = i_c // c_o_per_group</span><br><span class="line">h_lower = i_h * stride</span><br><span class="line">h_upper = i_h * stride + f_new</span><br><span class="line">w_lower = i_w * stride</span><br><span class="line">w_upper = i_w * stride + f_new</span><br><span class="line">c_lower = i_g * c_k</span><br><span class="line">c_upper = (i_g + <span class="number">1</span>) * c_k</span><br><span class="line">input_slice = input_pad[h_lower:h_upper, w_lower:w_upper,</span><br><span class="line">                        c_lower:c_upper]</span><br></pre></td></tr></table></figure>
<p>而卷积核就很容易获取了，直接选中第<code>i_c</code>个卷积核即可：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kernel_slice = weight_new[i_c]</span><br></pre></td></tr></table></figure>
<p>最后是卷积运算，别忘了加上bias。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">output[i_h, i_w, i_c] = np.<span class="built_in">sum</span>(input_slice * kernel_slice)</span><br><span class="line"><span class="keyword">if</span> bias:</span><br><span class="line">    output[i_h, i_w, i_c] += bias[i_c]</span><br></pre></td></tr></table></figure>
<p>写完了所有东西，返回输出结果。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">return</span> output</span><br></pre></td></tr></table></figure>
<h2 id="单元测试"><a href="#单元测试" class="headerlink" title="单元测试"></a>单元测试</h2><p>为了方便地进行单元测试，我使用了pytest这个单元测试库。可以直接pip一键安装：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install pytest</span><br></pre></td></tr></table></figure>
<p>之后就可以用pytest执行我的这份代码，代码里所有以<code>test_</code>开头的函数会被认为是单元测试的主函数。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pytest dldemos/BasicCNN/np_conv.py</span><br></pre></td></tr></table></figure>
<p>完整代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@pytest.mark.parametrize(<span class="params"><span class="string">&#x27;c_i, c_o&#x27;</span>, [(<span class="params"><span class="number">3</span>, <span class="number">6</span></span>), (<span class="params"><span class="number">2</span>, <span class="number">2</span></span>)]</span>)</span></span><br><span class="line"><span class="meta">@pytest.mark.parametrize(<span class="params"><span class="string">&#x27;kernel_size&#x27;</span>, [<span class="number">3</span>, <span class="number">5</span>]</span>)</span></span><br><span class="line"><span class="meta">@pytest.mark.parametrize(<span class="params"><span class="string">&#x27;stride&#x27;</span>, [<span class="number">1</span>, <span class="number">2</span>]</span>)</span></span><br><span class="line"><span class="meta">@pytest.mark.parametrize(<span class="params"><span class="string">&#x27;padding&#x27;</span>, [<span class="number">0</span>, <span class="number">1</span>]</span>)</span></span><br><span class="line"><span class="meta">@pytest.mark.parametrize(<span class="params"><span class="string">&#x27;dilation&#x27;</span>, [<span class="number">1</span>, <span class="number">2</span>]</span>)</span></span><br><span class="line"><span class="meta">@pytest.mark.parametrize(<span class="params"><span class="string">&#x27;groups&#x27;</span>, [<span class="string">&#x27;1&#x27;</span>, <span class="string">&#x27;all&#x27;</span>]</span>)</span></span><br><span class="line"><span class="meta">@pytest.mark.parametrize(<span class="params"><span class="string">&#x27;bias&#x27;</span>, [<span class="literal">False</span>]</span>)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">test_conv</span>(<span class="params">c_i: <span class="built_in">int</span>, c_o: <span class="built_in">int</span>, kernel_size: <span class="built_in">int</span>, stride: <span class="built_in">int</span>, padding: <span class="built_in">str</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">              dilation: <span class="built_in">int</span>, groups: <span class="built_in">str</span>, bias: <span class="built_in">bool</span></span>):</span></span><br><span class="line">    <span class="keyword">if</span> groups == <span class="string">&#x27;1&#x27;</span>:</span><br><span class="line">        groups = <span class="number">1</span></span><br><span class="line">    <span class="keyword">elif</span> groups == <span class="string">&#x27;all&#x27;</span>:</span><br><span class="line">        groups = c_i</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> bias:</span><br><span class="line">        bias = np.random.randn(c_o)</span><br><span class="line">        torch_bias = torch.from_numpy(bias)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        bias = <span class="literal">None</span></span><br><span class="line">        torch_bias = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="built_in">input</span> = np.random.randn(<span class="number">20</span>, <span class="number">20</span>, c_i)</span><br><span class="line">    weight = np.random.randn(c_o, kernel_size, kernel_size, c_i // groups)</span><br><span class="line"></span><br><span class="line">    torch_input = torch.from_numpy(np.transpose(<span class="built_in">input</span>, (<span class="number">2</span>, <span class="number">0</span>, <span class="number">1</span>))).unsqueeze(<span class="number">0</span>)</span><br><span class="line">    torch_weight = torch.from_numpy(np.transpose(weight, (<span class="number">0</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>)))</span><br><span class="line">    torch_output = torch.conv2d(torch_input, torch_weight, torch_bias, stride,</span><br><span class="line">                                padding, dilation, groups).numpy()</span><br><span class="line">    torch_output = np.transpose(torch_output.squeeze(<span class="number">0</span>), (<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>))</span><br><span class="line"></span><br><span class="line">    numpy_output = conv2d(<span class="built_in">input</span>, weight, stride, padding, dilation, groups,</span><br><span class="line">                          bias)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">assert</span> np.allclose(torch_output, numpy_output)</span><br></pre></td></tr></table></figure>
<p>其中，单元测试函数的定义如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@pytest.mark.parametrize(<span class="params"><span class="string">&#x27;c_i, c_o&#x27;</span>, [(<span class="params"><span class="number">3</span>, <span class="number">6</span></span>), (<span class="params"><span class="number">2</span>, <span class="number">2</span></span>)]</span>)</span></span><br><span class="line"><span class="meta">@pytest.mark.parametrize(<span class="params"><span class="string">&#x27;kernel_size&#x27;</span>, [<span class="number">3</span>, <span class="number">5</span>]</span>)</span></span><br><span class="line"><span class="meta">@pytest.mark.parametrize(<span class="params"><span class="string">&#x27;stride&#x27;</span>, [<span class="number">1</span>, <span class="number">2</span>]</span>)</span></span><br><span class="line"><span class="meta">@pytest.mark.parametrize(<span class="params"><span class="string">&#x27;padding&#x27;</span>, [<span class="number">0</span>, <span class="number">1</span>]</span>)</span></span><br><span class="line"><span class="meta">@pytest.mark.parametrize(<span class="params"><span class="string">&#x27;dilation&#x27;</span>, [<span class="number">1</span>, <span class="number">2</span>]</span>)</span></span><br><span class="line"><span class="meta">@pytest.mark.parametrize(<span class="params"><span class="string">&#x27;groups&#x27;</span>, [<span class="string">&#x27;1&#x27;</span>, <span class="string">&#x27;all&#x27;</span>]</span>)</span></span><br><span class="line"><span class="meta">@pytest.mark.parametrize(<span class="params"><span class="string">&#x27;bias&#x27;</span>, [<span class="literal">False</span>]</span>)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">test_conv</span>(<span class="params">c_i: <span class="built_in">int</span>, c_o: <span class="built_in">int</span>, kernel_size: <span class="built_in">int</span>, stride: <span class="built_in">int</span>, padding: <span class="built_in">str</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">              dilation: <span class="built_in">int</span>, groups: <span class="built_in">str</span>, bias: <span class="built_in">bool</span></span>):</span></span><br></pre></td></tr></table></figure>
<p>先别管上面那一堆装饰器，先看一下单元测试中的输入参数。在对某个函数进行单元测试时，要测试该函数的参数在不同取值下的表现。我打算测试我们的<code>conv2d</code>在各种输入通道数、输出通道数、卷积核大小、步幅、填充数、扩充数、分组数、是否加入bias的情况。</p>
<p><code>@pytest.mark.parametrize</code>用于设置单元测试参数的可选值。我设置了6组参数，每组参数有2个可选值，经过排列组合后可以生成<code>2^6=64</code>个单元测试，pytest会自动帮我们执行不同的测试。</p>
<p>在测试函数内，我先预处理了一下输入的参数，并生成了随机的输入张量，使这些参数和<code>conv2d</code>的参数一致。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">test_conv</span>(<span class="params">c_i: <span class="built_in">int</span>, c_o: <span class="built_in">int</span>, kernel_size: <span class="built_in">int</span>, stride: <span class="built_in">int</span>, padding: <span class="built_in">str</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">              dilation: <span class="built_in">int</span>, groups: <span class="built_in">str</span>, bias: <span class="built_in">bool</span></span>):</span></span><br><span class="line">    <span class="keyword">if</span> groups == <span class="string">&#x27;1&#x27;</span>:</span><br><span class="line">        groups = <span class="number">1</span></span><br><span class="line">    <span class="keyword">elif</span> groups == <span class="string">&#x27;all&#x27;</span>:</span><br><span class="line">        groups = c_i</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> bias:</span><br><span class="line">        bias = np.random.randn(c_o)</span><br><span class="line">        torch_bias = torch.from_numpy(bias)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        bias = <span class="literal">None</span></span><br><span class="line">        torch_bias = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="built_in">input</span> = np.random.randn(<span class="number">20</span>, <span class="number">20</span>, c_i)</span><br><span class="line">    weight = np.random.randn(c_o, kernel_size, kernel_size, c_i // groups)</span><br></pre></td></tr></table></figure>
<p>为了确保我们实现的卷积和<code>torch.conv2d</code>是对齐的，我们要用<code>torch.conv2d</code>算一个结果，作为正确的参考值。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">torch_input = torch.from_numpy(np.transpose(<span class="built_in">input</span>, (<span class="number">2</span>, <span class="number">0</span>, <span class="number">1</span>))).unsqueeze(<span class="number">0</span>)</span><br><span class="line">torch_weight = torch.from_numpy(np.transpose(weight, (<span class="number">0</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>)))</span><br><span class="line">torch_output = torch.conv2d(torch_input, torch_weight, torch_bias, stride,</span><br><span class="line">                            padding, dilation, groups).numpy()</span><br><span class="line">torch_output = np.transpose(torch_output.squeeze(<span class="number">0</span>), (<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>))</span><br></pre></td></tr></table></figure>
<p>由于<code>torch</code>里张量的形状格式是NCHW，weight的形状是C’Cff，我这里做了一些形状上的转换。</p>
<p>之后，调用我们自己的卷积函数：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">numpy_output = conv2d(<span class="built_in">input</span>, weight, stride, padding, dilation, groups,</span><br><span class="line">                          bias)</span><br></pre></td></tr></table></figure>
<p>最后，验证一下两个结果是否对齐：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">assert</span> np.allclose(torch_output, numpy_output)</span><br></pre></td></tr></table></figure>
<p>运行前面提到的单元测试命令，pytest会输出很多测试的结果。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pytest dldemos/BasicCNN/np_conv.py</span><br></pre></td></tr></table></figure>
<p>如果看到了类似的输出，就说明我们的代码是正确的。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">========== 64 passed in 1.20s ===============</span><br></pre></td></tr></table></figure>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>在这篇文章中，我介绍了<code>torch.conv2d</code>的等价NumPy实现。同时，我还详细说明了卷积各参数(stride, padding, dilation, groups)的意义。通过阅读本文，相信大家能够深刻地理解一轮卷积是怎么完成的。</p>
<p>如果你也想把这方面的基础打牢，一定一定要自己动手从头写一份代码。在写代码，调bug的过程中，一定会有很多收获。</p>
<p>相比torch里的卷积，这份卷积实现还不够灵活。torch里可以自由输入卷积核的宽高、stride的宽高。而我们默认卷积核是正方形，宽度和高度上的stride是一样的。不过，要让卷积更灵活一点，只需要稍微修改一些预处理数据的代码即可，卷积的核心实现代码是不变的。</p>
<p>其实，在编程框架中，卷积的实现都是很高效的，不可能像我们这样先扩充卷积核，再填充输入图像。这些操作都会引入很多冗余的计算量。为了尽可能利用并行加速卷积的运算，卷积的GPU实现使用了一种叫做im2col的算法。这种算法会把每次卷积乘加用到的输入图像上的数据都放进列向量中，把卷积乘加转换成一次矩阵乘法。有兴趣的话欢迎搜索这方面的知识。</p>
<p>这篇文章仅介绍了卷积操作的正向传播。有了正向传播，反向传播倒没那么了难了。之后有时间的话我会再分享一篇用NumPy实现卷积反向传播的文章。</p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p>本文中的动图来自于 <a target="_blank" rel="noopener" href="https://github.com/vdumoulin/conv_arithmetic">https://github.com/vdumoulin/conv_arithmetic</a></p>
<p>本文中分组卷积的图来自于论文 <a target="_blank" rel="noopener" href="https://www.researchgate.net/publication/321325862_CondenseNet_An_Efficient_DenseNet_using_Learned_Group_Convolutions">https://www.researchgate.net/publication/321325862_CondenseNet_An_Efficient_DenseNet_using_Learned_Group_Convolutions</a></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://zhouyifan.net/2022/07/24/DLS-note-10-3/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Zhou Yifan">
      <meta itemprop="description" content="A foresighted strategist with big-picture thinking. 大局观选手。">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="周弈帆的博客">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/07/24/DLS-note-10-3/" class="post-title-link" itemprop="url">吴恩达《深度学习专项》代码实战（十）：2.用 PyTorch 实现简单的 CNN 二分类器</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-07-24 00:30:54" itemprop="dateCreated datePublished" datetime="2022-07-24T00:30:54+08:00">2022-07-24</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">学习</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E5%AD%A6%E4%B9%A0/%E7%9F%A5%E8%AF%86%E8%AE%B0%E5%BD%95/" itemprop="url" rel="index"><span itemprop="name">知识记录</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>学完了CNN的基本构件，看完了<a href>用TensorFlow实现的CNN</a>，让我们再用PyTorch来搭建一个CNN，并用这个网络完成之前那个简单的猫狗分类任务。</p>
<p>这份PyTorch实现会尽量和TensorFlow实现等价。同时，我也会分享编写此项目过程中发现的PyTorch与TensorFlow的区别。</p>
<p>项目网址：<a target="_blank" rel="noopener" href="https://github.com/SingleZombie/DL-Demos/tree/master/dldemos/BasicCNN">https://github.com/SingleZombie/DL-Demos/tree/master/dldemos/BasicCNN</a></p>
<h2 id="获取数据集"><a href="#获取数据集" class="headerlink" title="获取数据集"></a>获取数据集</h2><p>和之前几次的代码实战任务一样，我们这次还用的是Kaggle上的猫狗数据集。我已经写好了数据预处理的函数。使用如下的接口即可获取数据集：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">train_X, train_Y, test_X, test_Y = get_cat_set(</span><br><span class="line">    <span class="string">&#x27;dldemos/LogisticRegression/data/archive/dataset&#x27;</span>,</span><br><span class="line">    train_size=<span class="number">1500</span>,</span><br><span class="line">    <span class="built_in">format</span>=<span class="string">&#x27;nchw&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(train_X.shape)  <span class="comment"># (m, 3, 224, 224)</span></span><br><span class="line"><span class="built_in">print</span>(train_Y.shape)  <span class="comment"># (m, 1)</span></span><br></pre></td></tr></table></figure>
<p>这次的数据格式和之前项目中的有一些区别。</p>
<p>在使用全连接网络时，每一个输入样本都是一个一维向量。之前在预处理数据集时，我做了一个flatten操作，把图片的所有颜色值塞进了一维向量中。而在CNN中，对于卷积操作，每一个输入样本都是一个三维张量。用OpenCV读取完图片后，不用对图片Resize，直接拿过来用就可以了。</p>
<p>另外，在用NumPy实现时，我们把数据集大小N当作了最后一个参数；在用TensorFlow时，张量格式是”NHWC(数量-高度-宽度-通道数)”。而PyTorch中默认的张量格式是”NCHW(数量-通道数-高度-宽度)”。因此，在预处理数据集时，我令<code>format=&#39;nchw&#39;</code>。</p>
<h2 id="初始化模型"><a href="#初始化模型" class="headerlink" title="初始化模型"></a>初始化模型</h2><p>根据课堂里讲的CNN构建思路，我搭了一个这样的网络。</p>
<p><img src="/2022/07/24/DLS-note-10-3/DLS-note-10-2/1.jpg" alt></p>
<p>由于这个二分类任务比较简单，我在设计时尽可能让可训练参数更少。刚开始用一个大步幅、大卷积核的卷积快速缩小图片边长，之后逐步让图片边长减半、深度翻倍。</p>
<p>这样一个网络用PyTorch实现如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">init_model</span>(<span class="params">device=<span class="string">&#x27;cpu&#x27;</span></span>):</span></span><br><span class="line">    model = nn.Sequential(nn.Conv2d(<span class="number">3</span>, <span class="number">16</span>, <span class="number">11</span>, <span class="number">3</span>), nn.BatchNorm2d(<span class="number">16</span>),</span><br><span class="line">                          nn.ReLU(<span class="literal">True</span>), nn.MaxPool2d(<span class="number">2</span>, <span class="number">2</span>),</span><br><span class="line">                          nn.Conv2d(<span class="number">16</span>, <span class="number">32</span>, <span class="number">5</span>), nn.BatchNorm2d(<span class="number">32</span>),</span><br><span class="line">                          nn.ReLU(<span class="literal">True</span>), nn.MaxPool2d(<span class="number">2</span>, <span class="number">2</span>),</span><br><span class="line">                          nn.Conv2d(<span class="number">32</span>, <span class="number">64</span>, <span class="number">3</span>, padding=<span class="number">1</span>), nn.BatchNorm2d(<span class="number">64</span>),</span><br><span class="line">                          nn.ReLU(<span class="literal">True</span>), nn.Conv2d(<span class="number">64</span>, <span class="number">64</span>, <span class="number">3</span>),</span><br><span class="line">                          nn.BatchNorm2d(<span class="number">64</span>), nn.ReLU(<span class="literal">True</span>),</span><br><span class="line">                          nn.MaxPool2d(<span class="number">2</span>, <span class="number">2</span>), nn.Flatten(),</span><br><span class="line">                          nn.Linear(<span class="number">3136</span>, <span class="number">2048</span>), nn.ReLU(<span class="literal">True</span>),</span><br><span class="line">                          nn.Linear(<span class="number">2048</span>, <span class="number">1</span>), nn.Sigmoid()).to(device)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">weights_init</span>(<span class="params">m</span>):</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(m, nn.Conv2d):</span><br><span class="line">            torch.nn.init.xavier_normal_(m.weight)</span><br><span class="line">            m.bias.data.fill_(<span class="number">0</span>)</span><br><span class="line">        <span class="keyword">elif</span> <span class="built_in">isinstance</span>(m, nn.BatchNorm2d):</span><br><span class="line">            m.weight.data.normal_(<span class="number">1.0</span>, <span class="number">0.02</span>)</span><br><span class="line">            m.bias.data.fill_(<span class="number">0</span>)</span><br><span class="line">        <span class="keyword">elif</span> <span class="built_in">isinstance</span>(m, nn.Linear):</span><br><span class="line">            torch.nn.init.xavier_normal_(m.weight)</span><br><span class="line">            m.bias.data.fill_(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    model.apply(weights_init)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(model)</span><br><span class="line">    <span class="keyword">return</span> model</span><br></pre></td></tr></table></figure>
<p>让我们从函数定义开始一点一点看起。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">init_model</span>(<span class="params">device=<span class="string">&#x27;cpu&#x27;</span></span>):</span></span><br></pre></td></tr></table></figure>
<p>在PyTorch中，所有张量所在的运算设备需要显式指定。我们的模型中带有可学习参数，这些参数都是张量。因此，在初始化模型时，我们要决定参数所在设备。最常见的设备是<code>&#39;cpu&#39;</code>和<code>&#39;cuda:0&#39;</code>。对于模块或者张量，使用<code>x.to(device)</code>即可让对象<code>x</code>中的数据迁移到设备<code>device</code>上。</p>
<p>接着，是初始化模型结构。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">model = nn.Sequential(nn.Conv2d(<span class="number">3</span>, <span class="number">16</span>, <span class="number">11</span>, <span class="number">3</span>), nn.BatchNorm2d(<span class="number">16</span>),</span><br><span class="line">                          nn.ReLU(<span class="literal">True</span>), nn.MaxPool2d(<span class="number">2</span>, <span class="number">2</span>),</span><br><span class="line">                          nn.Conv2d(<span class="number">16</span>, <span class="number">32</span>, <span class="number">5</span>), nn.BatchNorm2d(<span class="number">32</span>),</span><br><span class="line">                          nn.ReLU(<span class="literal">True</span>), nn.MaxPool2d(<span class="number">2</span>, <span class="number">2</span>),</span><br><span class="line">                          nn.Conv2d(<span class="number">32</span>, <span class="number">64</span>, <span class="number">3</span>, padding=<span class="number">1</span>), nn.BatchNorm2d(<span class="number">64</span>),</span><br><span class="line">                          nn.ReLU(<span class="literal">True</span>), nn.Conv2d(<span class="number">64</span>, <span class="number">64</span>, <span class="number">3</span>),</span><br><span class="line">                          nn.BatchNorm2d(<span class="number">64</span>), nn.ReLU(<span class="literal">True</span>),</span><br><span class="line">                          nn.MaxPool2d(<span class="number">2</span>, <span class="number">2</span>), nn.Flatten(),</span><br><span class="line">                          nn.Linear(<span class="number">3136</span>, <span class="number">2048</span>), nn.ReLU(<span class="literal">True</span>),</span><br><span class="line">                          nn.Linear(<span class="number">2048</span>, <span class="number">1</span>), nn.Sigmoid()).to(device)</span><br></pre></td></tr></table></figure>
<p><code>torch.nn.Sequential()</code>用于创建一个串行的网络（前一个模块的输出就是后一个模块的输入）。网络各模块用到的初始化参数的介绍如下：</p>
<ul>
<li><code>Conv2d</code>: 输入通道数、输出通道数、卷积核边长、步幅、填充个数padding。</li>
<li><code>BatchNormalization</code>: 输入通道数。</li>
<li><code>ReLU</code>: 一个bool值<code>inplace</code>。是否使用<code>inplace</code>，就和用<code>a += 1</code>还是<code>a + 1</code>一样，后者会多花一个中间变量来存结果。</li>
<li><code>MaxPool2d</code>: 卷积核边长、步幅。</li>
<li><code>Linear</code>（全连接层）：输入通道数、输出通道数。</li>
</ul>
<blockquote>
<p>相比TensorFlow，PyTorch里的模块更独立一些，不能附加激活函数，不能直接直接写上初始化方法。</p>
<p>TensorFlow是静态图（会有一个类似“编译”的过程，把模块串起来），除了第一个模块外，后续模块都可以不指定输入通道数。而PyTorch是动态图，需要指定某些模块的输入通道数。</p>
</blockquote>
<p>根据之前的设计，把参数填入这些模块即可。 </p>
<p>由于PyTorch在初始化模块时不能自动初始化参数，我们要手动写上初始化参数的逻辑。</p>
<p>在此之前，要先认识一下<code>torch.nn.Module</code>的<code>apply</code>函数。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.apply(weights_init)</span><br></pre></td></tr></table></figure>
<p>PyTorch的模型模块<code>torch.nn.Module</code>是自我嵌套的。一个<code>torch.nn.Module</code>的实例可能由多个<code>torch.nn.Module</code>的实例组成。<code>model.apply(func)</code>可以对某<code>torch.nn.Module</code>实例的所有某子模块执行<code>func</code>函数。我们使用的参数初始化函数叫做<code>weights_init</code>，所以用上面那行代码就可以初始化所有模块。</p>
<p>初始化参数函数是这样写的：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">weights_init</span>(<span class="params">m</span>):</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">isinstance</span>(m, nn.Conv2d):</span><br><span class="line">        torch.nn.init.xavier_normal_(m.weight)</span><br><span class="line">        m.bias.data.fill_(<span class="number">0</span>)</span><br><span class="line">    <span class="keyword">elif</span> <span class="built_in">isinstance</span>(m, nn.BatchNorm2d):</span><br><span class="line">        m.weight.data.normal_(<span class="number">1.0</span>, <span class="number">0.02</span>)</span><br><span class="line">        m.bias.data.fill_(<span class="number">0</span>)</span><br><span class="line">    <span class="keyword">elif</span> <span class="built_in">isinstance</span>(m, nn.Linear):</span><br><span class="line">        torch.nn.init.xavier_normal_(m.weight)</span><br><span class="line">        m.bias.data.fill_(<span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<p>其中，<code>m</code>就是子模块的示例。通过对其进行类型判断，我们可以对不同的模块执行不同的初始化方式。初始化的函数都在<code>torch.nn.init</code>，我这里用的是<code>torch.nn.init.xavier_normal_</code>。</p>
<blockquote>
<p>理论上写了batch normalization的话前一个模块就不用加bias。为了让代码稍微简单一点，我没有做这个优化。</p>
</blockquote>
<p>模型初始化完后，调用<code>print(model)</code>可以查看网络各层的参数信息。</p>
<figure class="highlight plaintext"><figcaption><span>text</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Sequential(</span><br><span class="line">  (0): Conv2d(3, 16, kernel_size=(11, 11), stride=(3, 3))</span><br><span class="line">  (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">  (2): ReLU(inplace=True)</span><br><span class="line">  (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)</span><br><span class="line">    ......</span><br><span class="line">  (18): Linear(in_features=2048, out_features=1, bias=True)</span><br><span class="line">  (19): Sigmoid()</span><br></pre></td></tr></table></figure>
<h2 id="准备优化器和loss"><a href="#准备优化器和loss" class="headerlink" title="准备优化器和loss"></a>准备优化器和loss</h2><p>初始化完模型后，可以用下面的代码初始化优化器与loss。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">model = init_model(device)</span><br><span class="line">optimizer = torch.optim.Adam(model.parameters(), <span class="number">5e-4</span>)</span><br><span class="line">loss_fn = torch.nn.BCELoss()</span><br></pre></td></tr></table></figure>
<p><code>torch.optim.Adam</code>可以初始化一个Adam优化器。它的第一个参数是所有可训练参数，直接对一个<code>torch.nn.Module</code>调用<code>.parameters()</code>即可一键获取参数。它的第二个参数是学习率，这个可以根据实验情况自行调整。</p>
<p><code>torch.nn.BCELoss</code>是二分类用到的交叉熵误差。这里只是对它进行了初始化。在调用时，使用方法是<code>loss(input, target)</code>。<code>input</code>是用于比较的结果，<code>target</code>是被比较的标签。</p>
<h2 id="训练与推理"><a href="#训练与推理" class="headerlink" title="训练与推理"></a>训练与推理</h2><p>接下来，我们来编写模型训练和推理（准确来说是评估）的代码。</p>
<p>先看训练函数。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span>(<span class="params">model: nn.Module,</span></span></span><br><span class="line"><span class="params"><span class="function">          train_X: np.ndarray,</span></span></span><br><span class="line"><span class="params"><span class="function">          train_Y: np.ndarray,</span></span></span><br><span class="line"><span class="params"><span class="function">          optimizer: torch.optim.Optimizer,</span></span></span><br><span class="line"><span class="params"><span class="function">          loss_fn: nn.Module,</span></span></span><br><span class="line"><span class="params"><span class="function">          batch_size: <span class="built_in">int</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">          num_epoch: <span class="built_in">int</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">          device: <span class="built_in">str</span> = <span class="string">&#x27;cpu&#x27;</span></span>):</span></span><br></pre></td></tr></table></figure>
<p>在训练时，我们采用mini-batch策略。因此，开始迭代前，我们要编写预处理mini-batch的代码。</p>
<blockquote>
<p>这部分的代码讲解请参考我之前<a href>有关优化算法的文章</a>。</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">m = train_X.shape[<span class="number">0</span>]</span><br><span class="line">    indices = np.random.permutation(m)</span><br><span class="line">    shuffle_X = train_X[indices, ...]</span><br><span class="line">    shuffle_Y = train_Y[indices, ...]</span><br><span class="line">    num_mini_batch = math.ceil(m / batch_size)</span><br><span class="line">    mini_batch_XYs = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_mini_batch):</span><br><span class="line">        <span class="keyword">if</span> i == num_mini_batch - <span class="number">1</span>:</span><br><span class="line">            mini_batch_X = shuffle_X[i * batch_size:, ...]</span><br><span class="line">            mini_batch_Y = shuffle_Y[i * batch_size:, ...]</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            mini_batch_X = shuffle_X[i * batch_size:(i + <span class="number">1</span>) * batch_size, ...]</span><br><span class="line">            mini_batch_Y = shuffle_Y[i * batch_size:(i + <span class="number">1</span>) * batch_size, ...]</span><br><span class="line">        mini_batch_X = torch.from_numpy(mini_batch_X)</span><br><span class="line">        mini_batch_Y = torch.from_numpy(mini_batch_Y).<span class="built_in">float</span>()</span><br><span class="line">        mini_batch_XYs.append((mini_batch_X, mini_batch_Y))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;Num mini-batch: <span class="subst">&#123;num_mini_batch&#125;</span>&#x27;</span>)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>PyTorch有更方便的实现mini-batch的方法。但为了少引入一些新知识，我这里没有使用。后续文章中会对这部分内容进行介绍。</p>
</blockquote>
<p>这里还有一些有关PyTorch的知识需要讲解。<code>torch.from_numpy</code>可以把一个NumPy数组转换成<code>torch.Tensor</code>。由于标签<code>Y</code>是个整形张量，而PyTorch算loss时又要求标签是个float，这里要调用<code>.float()</code>把张量强制类型转换到float型。同理，其他类型也可以用类似的方法进行转换。</p>
<p>分配好了mini-batch后，就可以开心地调用框架进行训练了。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> e <span class="keyword">in</span> <span class="built_in">range</span>(num_epoch):</span><br><span class="line">        <span class="keyword">for</span> mini_batch_X, mini_batch_Y <span class="keyword">in</span> mini_batch_XYs:</span><br><span class="line">            mini_batch_X = mini_batch_X.to(device)</span><br><span class="line">            mini_batch_Y = mini_batch_Y.to(device)</span><br><span class="line">            mini_batch_Y_hat = model(mini_batch_X)</span><br><span class="line">            loss: torch.Tensor = loss_fn(mini_batch_Y_hat, mini_batch_Y)</span><br><span class="line"></span><br><span class="line">            optimizer.zero_grad()</span><br><span class="line">            loss.backward()</span><br><span class="line">            optimizer.step()</span><br><span class="line"></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;Epoch <span class="subst">&#123;e&#125;</span>. loss: <span class="subst">&#123;loss&#125;</span>&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>由于GPU计算资源有限，只有当我们需要计算某数据时，才把数据用<code>to(device)</code>放到对应设备上。</p>
<p>直接用<code>model(x)</code>即可让模型<code>model</code>执行输入<code>x</code>的前向传播。</p>
<p>之后几行代码就属于训练的常规操作了。先计算loss，再清空优化器的梯度，做反向传播，最后调用优化器更新所有参数。</p>
<p>推理并评估的函数定义如下：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">evaluate</span>(<span class="params">model: nn.Module,</span></span></span><br><span class="line"><span class="params"><span class="function">             test_X: np.ndarray,</span></span></span><br><span class="line"><span class="params"><span class="function">             test_Y: np.ndarray,</span></span></span><br><span class="line"><span class="params"><span class="function">             device=<span class="string">&#x27;cpu&#x27;</span></span>):</span></span><br></pre></td></tr></table></figure></p>
<p>它的实现和之前的NumPy版本极为类似，这里不再重复讲解了。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">test_X = torch.from_numpy(test_X).to(device)</span><br><span class="line">test_Y = torch.from_numpy(test_Y).to(device)</span><br><span class="line">test_Y_hat = model(test_X)</span><br><span class="line">predicts = torch.where(test_Y_hat &gt; <span class="number">0.5</span>, <span class="number">1</span>, <span class="number">0</span>)</span><br><span class="line">score = torch.where(predicts == test_Y, <span class="number">1.0</span>, <span class="number">0.0</span>)</span><br><span class="line">acc = torch.mean(score)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;Accuracy: <span class="subst">&#123;acc&#125;</span>&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h2 id="main函数"><a href="#main函数" class="headerlink" title="main函数"></a>main函数</h2><p>做好了所有准备，现在可以把所有的流程串起来了。让我们看看main函数的所有代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span>():</span></span><br><span class="line">    train_X, train_Y, test_X, test_Y = get_cat_set(</span><br><span class="line">        <span class="string">&#x27;dldemos/LogisticRegression/data/archive/dataset&#x27;</span>,</span><br><span class="line">        train_size=<span class="number">1500</span>,</span><br><span class="line">        <span class="built_in">format</span>=<span class="string">&#x27;nchw&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(train_X.shape)  <span class="comment"># (m, 3, 224, 224)</span></span><br><span class="line">    <span class="built_in">print</span>(train_Y.shape)  <span class="comment"># (m, 1)</span></span><br><span class="line"></span><br><span class="line">    device = <span class="string">&#x27;cuda:0&#x27;</span></span><br><span class="line">    num_epoch = <span class="number">20</span></span><br><span class="line">    batch_size = <span class="number">16</span></span><br><span class="line">    model = init_model(device)</span><br><span class="line">    optimizer = torch.optim.Adam(model.parameters(), <span class="number">5e-4</span>)</span><br><span class="line">    loss_fn = torch.nn.BCELoss()</span><br><span class="line">    train(model, train_X, train_Y, optimizer, loss_fn, batch_size, num_epoch,</span><br><span class="line">          device)</span><br><span class="line">    evaluate(model, test_X, test_Y, device)</span><br></pre></td></tr></table></figure>
<p>这里，我们先准备好了数据集，再初始化好了模型、优化器、loss，之后训练，最后评估。</p>
<p>这里的<code>cuda:0</code>可以改成<code>cpu</code>，这样所有运算都会在CPU上完成。</p>
<h2 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h2><p>由于数据量较少，我只执行了20个epoch。loss已经降到很低了。</p>
<figure class="highlight plaintext"><figcaption><span>text</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">poch 19. loss: 0.0308767631649971</span><br></pre></td></tr></table></figure>
<p>但是，测试集上的精度非常低。</p>
<figure class="highlight plaintext"><figcaption><span>text</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Accuracy: 0.5824999809265137</span><br></pre></td></tr></table></figure>
<p>在完成本项目时，我本来想让这次的PyTorch实现和上次的TensorFlow实现完全等价。但是，上次的loss大概是0.06，准确率是0.74。可以看出，在训练误差上PyTorch模型没什么问题，而准确率却差了很多。我猜测是TensorFlow的代码过于“高级”，隐藏了很多细节。也许它默认的配置里使用了某些正则化手段。而在今天这份PyTorch实现中，我们没有使用任何正则化的方法。</p>
<p>不管怎么说，从训练的角度来看，相比前几周用的全连接网络，CNN的效果出彩很多。相信加入更多训练数据，并使用一些正则化方法的话，模型在测试集上的表现会更好。</p>
<p>PyTorch和TensorFlow在使用体验和性能上更有优劣。相比TensorFlow的高度封装的函数，PyTorch要手写的地方会多一点。不过，在项目逐渐复杂起来，高度封装的函数用不了了之后，还是PyTorch写起来会更方便一点。毕竟PyTorch是动态图，可以随心所欲地写前向推理的过程。也正因为如此，PyTorch的性能会略逊一些。</p>
<p>使用编程框架是不是很爽？可不要得意忘形哦。在之后的文章中，我还会介绍卷积的等价NumPy实现，让我们重温一下“难用”的NumPy，打下坚实的编程基础。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://zhouyifan.net/2022/07/24/DLS-note-10-2/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Zhou Yifan">
      <meta itemprop="description" content="A foresighted strategist with big-picture thinking. 大局观选手。">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="周弈帆的博客">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/07/24/DLS-note-10-2/" class="post-title-link" itemprop="url">吴恩达《深度学习专项》代码实战（十）：1.用 TensorFlow 实现简单的 CNN 二分类器</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-07-24 00:30:51" itemprop="dateCreated datePublished" datetime="2022-07-24T00:30:51+08:00">2022-07-24</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">学习</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E5%AD%A6%E4%B9%A0/%E7%9F%A5%E8%AF%86%E8%AE%B0%E5%BD%95/" itemprop="url" rel="index"><span itemprop="name">知识记录</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>学完了CNN的基本构件，让我们用TensorFlow来搭建一个CNN，并用这个网络完成之前那个简单的猫狗分类任务。</p>
<p>项目网址：<a target="_blank" rel="noopener" href="https://github.com/SingleZombie/DL-Demos/tree/master/dldemos/BasicCNN">https://github.com/SingleZombie/DL-Demos/tree/master/dldemos/BasicCNN</a></p>
<h2 id="获取数据集"><a href="#获取数据集" class="headerlink" title="获取数据集"></a>获取数据集</h2><p>和之前几次的代码实战任务一样，我们这次还用的是Kaggle上的猫狗数据集。我已经写好了数据预处理的函数。使用如下的接口即可获取数据集：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">train_X, train_Y, test_X, test_Y = get_cat_set(</span><br><span class="line">        <span class="string">&#x27;dldemos/LogisticRegression/data/archive/dataset&#x27;</span>, train_size=<span class="number">1500</span>)</span><br><span class="line"><span class="built_in">print</span>(train_X.shape)  <span class="comment"># (m, 224, 224, 3)</span></span><br><span class="line"><span class="built_in">print</span>(train_Y.shape)  <span class="comment"># (m , 1)</span></span><br></pre></td></tr></table></figure>
<p>这次的数据格式和之前项目中的有一些区别。</p>
<p>在使用全连接网络时，每一个输入样本都是一个一维向量。在预处理数据集时，我就做了一个flatten操作，把图片的所有颜色值塞进了一维向量中。而在CNN中，对于卷积操作，每一个输入样本都是一个三维张量。在用OpenCV读取完图片后，不用对图片Resize，直接拿过来用就可以了。</p>
<p>另外，在用NumPy实现时，我们把数据集大小<code>m</code>当作了最后一个参数。而TensorFlow默认张量是”NHWC(数量-高度-宽度-通道数)”格式。在此项目中，我们是按照TensorFlow的格式预处理数据的。</p>
<h2 id="初始化模型"><a href="#初始化模型" class="headerlink" title="初始化模型"></a>初始化模型</h2><p>根据课堂里讲的CNN构建思路，我搭了一个这样的网络。</p>
<p><img src="/2022/07/24/DLS-note-10-2/1.jpg" alt></p>
<p>由于这个二分类任务比较简单，我在设计时尽可能让可训练参数更少。刚开始用一个大步幅、大卷积核的卷积快速缩小图片边长，之后逐步让图片边长减半、深度翻倍。</p>
<p>这样一个网络用TensorFlow实现如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">init_model</span>(<span class="params">input_shape=(<span class="params"><span class="number">224</span>, <span class="number">224</span>, <span class="number">3</span></span>)</span>):</span></span><br><span class="line">    model = tf.keras.Sequential([</span><br><span class="line">        tf.keras.layers.Conv2D(<span class="number">16</span>, <span class="number">11</span>, (<span class="number">3</span>, <span class="number">3</span>), input_shape=input_shape),</span><br><span class="line">        tf.keras.layers.BatchNormalization(<span class="number">3</span>),</span><br><span class="line">        tf.keras.layers.ReLU(),</span><br><span class="line">        tf.keras.layers.MaxPool2D(),</span><br><span class="line">        tf.keras.layers.Conv2D(<span class="number">32</span>, <span class="number">5</span>),</span><br><span class="line">        tf.keras.layers.BatchNormalization(<span class="number">3</span>),</span><br><span class="line">        tf.keras.layers.ReLU(),</span><br><span class="line">        tf.keras.layers.MaxPool2D(),</span><br><span class="line">        tf.keras.layers.Conv2D(<span class="number">64</span>, <span class="number">3</span>, padding=<span class="string">&#x27;same&#x27;</span>),</span><br><span class="line">        tf.keras.layers.BatchNormalization(<span class="number">3</span>),</span><br><span class="line">        tf.keras.layers.ReLU(),</span><br><span class="line">        tf.keras.layers.Conv2D(<span class="number">64</span>, <span class="number">3</span>),</span><br><span class="line">        tf.keras.layers.BatchNormalization(<span class="number">3</span>),</span><br><span class="line">        tf.keras.layers.ReLU(),</span><br><span class="line">        tf.keras.layers.MaxPool2D(),</span><br><span class="line">        tf.keras.layers.Flatten(),</span><br><span class="line">        tf.keras.layers.Dense(<span class="number">2048</span>, <span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">        tf.keras.layers.Dense(<span class="number">1</span>, <span class="string">&#x27;sigmoid&#x27;</span>)</span><br><span class="line">    ])</span><br><span class="line"></span><br><span class="line">    model.summary()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> model</span><br></pre></td></tr></table></figure>
<p><code>tf.keras.Sequential()</code>用于创建一个串行的网络（前一个模块的输出就是后一个模块的输入）。网络各模块用到的初始化参数的介绍如下：</p>
<ul>
<li>Conv2D: 输出通道数、卷积核边长、步幅（要用一个数对表示）、填充方法。</li>
<li>BatchNormalization: 做归一化的维度（全填3即可）。</li>
<li>Dense（全连接层）：输出通道数、激活函数。</li>
</ul>
<p>根据之前的设计，把参数填入这些模块即可。 </p>
<p>另外，TensorFlow维护的是静态图。一种比较简单的建图方法是在第一层里给出<code>input_shape</code>参数，让框架提前算好后续每一层中间结果的形状。</p>
<p>建图成功后，调用<code>model.summary()</code>可以查看网络各层的形状、参数量信息。</p>
<h2 id="训练与推理"><a href="#训练与推理" class="headerlink" title="训练与推理"></a>训练与推理</h2><p>有了数据集和模型，用TensorFlow训练是一件很简单的事情。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span>():</span></span><br><span class="line">    train_X, train_Y, test_X, test_Y = get_cat_set(</span><br><span class="line">        <span class="string">&#x27;dldemos/LogisticRegression/data/archive/dataset&#x27;</span>, train_size=<span class="number">1500</span>)</span><br><span class="line">    <span class="built_in">print</span>(train_X.shape)  <span class="comment"># (m, 224, 224, 3)</span></span><br><span class="line">    <span class="built_in">print</span>(train_Y.shape)  <span class="comment"># (m , 1)</span></span><br><span class="line"></span><br><span class="line">    model = init_model()</span><br><span class="line">    model.<span class="built_in">compile</span>(optimizer=<span class="string">&#x27;adam&#x27;</span>,</span><br><span class="line">                  loss=<span class="string">&#x27;binary_crossentropy&#x27;</span>,</span><br><span class="line">                  metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line"></span><br><span class="line">    model.fit(train_X, train_Y, epochs=<span class="number">20</span>, batch_size=<span class="number">16</span>)</span><br><span class="line">    model.evaluate(test_X, test_Y)</span><br></pre></td></tr></table></figure>
<p>使用<code>init_model</code>初始化模型后，用<code>compile</code>填入模型的优化器、误差函数、评估指标信息。之后，只要用<code>fit</code>输入训练输入、训练标签、epoch数、batch size即可开始训练。训练结束后，用<code>evaluate</code>输入测试输入、测试标签即可在测试集上评估模型。</p>
<p>TensorFlow的这些函数确实非常方便，这里<code>test_X, test_Y, train_X, train_Y</code>其实都是NumPy里的ndarray，可以不用显式地把它们转换成TensorFlow里的张量。</p>
<h2 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h2><p>由于数据量较少，20个epoch后模型在训练集上的精度就快满了：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Epoch <span class="number">20</span>/<span class="number">20</span></span><br><span class="line"><span class="number">188</span>/<span class="number">188</span> [==============================] - 23s 121ms/step - loss: <span class="number">0.0690</span> - accuracy: <span class="number">0.9776</span></span><br></pre></td></tr></table></figure>
<p>测试集上的精度就没那么高了：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">13</span>/<span class="number">13</span> [==============================] - 1s 30ms/step - loss: <span class="number">1.0136</span> - accuracy: <span class="number">0.7375</span></span><br></pre></td></tr></table></figure>
<p>相比前几周用的全连接网络，CNN的效果出彩很多。相信加入更多训练数据的话，模型在测试集上的表现会更好。</p>
<p>另外，TensorFlow的高度封装的函数确实很好用，寥寥几行代码就完成了训练配置、训练、评估。相比用NumPy从零写代码，编程框架的开发效率会高上很多。</p>
<p>下篇文章里，我会介绍本项目的等价PyTorch实现。大家届时可以比较一下两个框架的区别。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://zhouyifan.net/2022/07/11/DLS-note-10/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Zhou Yifan">
      <meta itemprop="description" content="A foresighted strategist with big-picture thinking. 大局观选手。">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="周弈帆的博客">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/07/11/DLS-note-10/" class="post-title-link" itemprop="url">吴恩达《深度学习专项》笔记（十）：卷积神经网络的基础构件</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-07-11 21:10:18" itemprop="dateCreated datePublished" datetime="2022-07-11T21:10:18+08:00">2022-07-11</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">学习</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E5%AD%A6%E4%B9%A0/%E7%9F%A5%E8%AF%86%E8%AE%B0%E5%BD%95/" itemprop="url" rel="index"><span itemprop="name">知识记录</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>前排提示：这周的课有很多知识点都在图中，一定要仔细地看一看图。</p>
<h1 id="课堂笔记"><a href="#课堂笔记" class="headerlink" title="课堂笔记"></a>课堂笔记</h1><h2 id="计算机视觉"><a href="#计算机视觉" class="headerlink" title="计算机视觉"></a>计算机视觉</h2><p>CV(Computer Vision, 计算机视觉)是计算机科学的一个研究领域。该领域研究如何让计算机“理解”图像，从而完成一些只有人类才能完成的高级任务。这些高级任务有：图像分类、目标检测、风格转换等。</p>
<p><img src="/2022/07/11/DLS-note-10/1.jpg" alt></p>
<blockquote>
<p>想具体了解有哪些计算机视觉任务，可以直接去访问OpenMMLab的GitHub主页：<a target="_blank" rel="noopener" href="https://github.com/open-mmlab">https://github.com/open-mmlab</a> 。我随手整理了一下：图像分类、目标检测、语义分割、图像补全、光流、图像超分辨率、自动抠图、姿态识别、视频插帧、视频目标跟踪、文字识别与理解、图像生成、视频理解、3D目标检测与语义分割……</p>
</blockquote>
<p>现在，大多数前沿CV算法是用深度学习实现的。</p>
<p>但是，在CV任务上使用我们之前学的经典神经网络，会碰到一个问题：神经网络输入层的通道数与输入图像尺寸正相关。对于一幅$64\times64\times3$的图像，输入的通道数是$12288$；而对于一幅$1000\times1000\times3$的图像，输入的通道数就高达$3\times 10^6$了。而网络第一层的参数量又与输入的通道数正相关。对于一个通道数高达$3\times 10^6$的输入，假设网络第一个隐藏层有$1000$个神经元，那么这一层的$W$将有$1000 \times 3\times 10^6=3\times 10^9$个参数。有这么多参数，除非有海量的数据，不然网络非常容易过拟合。现有的数据量和计算资源还是跑不动参数这么多的网络的。</p>
<p>因此，在CV中，我们一般不使用之前学的经典神经网络架构，而是使用一种新的网络架构——CNN(Convolutional Neural Network, 卷积神经网络)。</p>
<blockquote>
<p>教材这一段的引入新知识组织得非常棒，从参数量的角度自然而然地从全连接网络过度到卷积神经网络。</p>
</blockquote>
<p>让我们从卷积神经网络最简单的构件——卷积学起，一步一步认识卷积神经网络。</p>
<h2 id="边缘检测"><a href="#边缘检测" class="headerlink" title="边缘检测"></a>边缘检测</h2><p>卷积是一种定义在图像上的操作。在深度学习时代之前，它最常用于图像处理。让我们来看看卷积在图像处理中的一个经典应用——边缘检测，通过这个应用来学习卷积。</p>
<p><img src="/2022/07/11/DLS-note-10/2.jpg" alt></p>
<p>边缘检测的示意图如上所示。输入一张图片，我们希望计算机能够检测出图像纵向和横向的边缘，把有边缘的地方标成白色，没有边缘的地方标成黑色。</p>
<p>我们可以用卷积实现边缘检测。让我们来看看卷积运算是怎么样对数据进行操作的。</p>
<p><img src="/2022/07/11/DLS-note-10/3.jpg" alt></p>
<p>卷积有两个输入：一幅图像和一个卷积核（英文是kernel，也叫做filter滤波器），其中卷积核是一个二维矩阵。我们这里假设图像是一幅单通道$6 \times 6$的矩阵，卷积核是一个$3 \times 3$的矩阵。经过卷积后，我们会得到一个$4 \times 4$的单通道图像（稍后会介绍$4 \times 4$是怎么算出来的）。</p>
<p>卷积操作会依次算出输出图像中每一个格子的值。对于输出左上角第一个格子，它的计算方法如下：</p>
<p><img src="/2022/07/11/DLS-note-10/4.jpg" alt></p>
<p>首先，我们把$3 \times 3$的卷积核“套”在输入图像的左上角。之后，我们把同一个位置的两个数字乘起来。比如图像左上角第一行是$3  0   1$，卷积核第一行是$1 0 1$，做完乘法运算后应该得到$3  0  -1$。最后，把所有乘法结果加起来，这个和就是输出中第一个格子的值。通过计算，这个值是$-5$，我们把它填入到输出图像中。</p>
<p>按同样的道理，我们可以填完第一行剩下的格子：</p>
<p><img src="/2022/07/11/DLS-note-10/5.jpg" alt></p>
<p>从第二行开始，卷积核要往下移一格。</p>
<p><img src="/2022/07/11/DLS-note-10/6.jpg" alt></p>
<p>以此类推，我们可以填完所有格子。大家明白了为什么输出是$4 \times 4$的图像吗？没错，把$3 \times 3$的卷积核放到$6 \times 6$的图像上，只有$4 \times 4$个位置能放得下。</p>
<p>学会了卷积，该怎么用卷积完成边缘检测呢？我们可以看下面这个例子：</p>
<p><img src="/2022/07/11/DLS-note-10/7.jpg" alt></p>
<p>来看左边那幅图像，它左侧是白的，右侧是灰的。很明显，中间有一条纵向的边缘。当我们用图中那个卷积核对图像做卷积操作后，输出的图像中间是白色的（非0值），两侧是黑色的。输出图像用白色标出了原图像的纵向边缘，达到了边缘检测的目的。</p>
<p>刚刚那个卷积核只能检测纵向的边缘。大家应该能猜出，如果我们把卷积核转一下，就能检测横向的边缘了。</p>
<p><img src="/2022/07/11/DLS-note-10/8.jpg" alt></p>
<p>实际上，不仅是横向和纵向，我们还可以通过改变卷积核，检测出图像45°，30°的边缘。同时，卷积核里面的数值也不一定是1和-1，还有各种各样的取值方法。如果大家感兴趣，可以参考数字图像处理中有关边缘检测的介绍。</p>
<h2 id="卷积与交叉相关"><a href="#卷积与交叉相关" class="headerlink" title="卷积与交叉相关"></a>卷积与交叉相关</h2><p>其实，现在我们在课堂上学的和编程框架里用的卷积，在数学上叫做“交叉相关(cross-correlation)”。数学中真正的那个卷积，要先对卷积核做一个旋转180°的操作，再做我们现在的那个卷积的操作。相比交叉相关，数学中的那个卷积能够满足交换律、结合律等一些实用的性质。</p>
<p>但是，在图像处理中，我们是从工程的角度而不是理科的角度使用卷积。要实现多次卷积的操作，只要拿图像多卷几次就好了，不用考虑结合律等复杂的性质。对于计算机来说，旋转卷积核180°是一个费时而多余的操作。因此，我们现在说到的卷积，实际上是一个简化版的卷积，即交叉相关。</p>
<blockquote>
<p>如果大家对这方面的知识感兴趣，欢迎阅读网上的这篇文章：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/33194385">https://zhuanlan.zhihu.com/p/33194385</a></p>
</blockquote>
<h2 id="填充"><a href="#填充" class="headerlink" title="填充"></a>填充</h2><p>卷积后，图像的边长会变小。比如刚刚那个$6 \times 6$的图像经$3 \times 3$卷积后，会得到一个$4 \times 4$的图像。这是因为原图像中只有$4 \times 4$个位置放得下卷积核。</p>
<p>更一般地，如果原图像大小为$n \times n$，卷积核大小$f \times f$，则卷积后的图像为$(n-f+1) \times (n-f+1)$。</p>
<p>卷积操作导致的这种“缩水”现象有两个缺点:1)图像的分辨率会越来越小。最坏的情况下，图像变成了$1 \times 1$的大小，再也无法进行卷积操作了。2)图像中间的数据会被算到多次，而边缘处数据被算的次数较少。</p>
<p><strong>填充(padding)</strong> 操作可以解决这些的问题：在做卷积操作之前，我们可以往图像四周填充一些像素，使得卷积操作后的图像大小不变。比如$6 \times 6$的图像做$3 \times 3$卷积时，可以先把图像填充成$8 \times 8$。这样，卷积后的图像还能保持$6 \times 6$的大小。</p>
<p>填充操作有两个参数：填充的数据和向四周填充的宽度。对于填充的数据，一般情况下，全部填0即可。而对于填充宽度，其取决于卷积核的大小。为了让图像大小不变，我们应该让填充宽度$p$满足$n+2p-f+1=n$，解得$p=\frac{f-1}{2}$。为了让$p$是整数，卷积核边长最好是奇数。</p>
<blockquote>
<p>解释一下$n+2p-f+1=n$这个方程的左侧是怎么得来的。由于填充是上下、左右都填，填充后的图像边长是$n+2p$。根据开始的卷积后图像边长公式$n-f+1$，我们可以得到填充+卷积后边长公式$n+2p-f+1。$</p>
</blockquote>
<p>加入了填充操作后，我们可以把卷积分成两类：<strong>有效卷积</strong>和<strong>等长卷积</strong>。前者不做填充操作，只对图像的有效区域做卷积。而后者会在卷积前做一次填充，保证整个操作的前后图像大小不变。</p>
<h2 id="跨步卷积"><a href="#跨步卷积" class="headerlink" title="跨步卷积"></a>跨步卷积</h2><blockquote>
<p>跨步卷积的英文是strided convolution。strided来源于动词stride，表示“大步走”。我没有在网上找到一个合适的对这里的strided的翻译。我觉得直接翻译成“跨步卷积”就挺好。</p>
<p>还有一个翻译的小细节：做名词时，stride应翻译成“步幅”，而“步长”的英文应该是step。二者在描述人类行走时略有区别。</p>
</blockquote>
<p>之前，每做完一次卷积后，我们都会让卷积核往右移1格；每做完一行卷积后，我们都会让卷积核往下移1格。但实际上，我们可以让卷积核移动得更快一点。卷积核每次移动的长度$s$称为<strong>步幅(stride)</strong>.</p>
<p>跨步卷积的部分计算示意图（第1, 2, 4次计算）如下：</p>
<p><img src="/2022/07/11/DLS-note-10/9.jpg" alt></p>
<p>可以看到，步幅改变后，输出图像的边长也改变了。一般地，卷积后图像边长满足下面这个公式，大家可以自行推导验证一下：</p>
<script type="math/tex; mode=display">
\lfloor \frac{n + 2p - f}{s}+1\rfloor</script><p>其中$\lfloor x \rfloor$表示去掉$x$的小数部分，只保留其整数部分，即向下取整。</p>
<h2 id="在3D数据体上卷积"><a href="#在3D数据体上卷积" class="headerlink" title="在3D数据体上卷积"></a>在3D数据体上卷积</h2><p>之前我们学的卷积都是定义在一个二维单通道图像上的。在一个三通道的图像上，应该怎么进行卷积呢？</p>
<p>其实，对3D数据体的卷积是类似的。对于一个有3个通道的图像，卷积核也应该有3个通道。这样，图像和卷积核就从面变成了体。和2D时一样，我们把两个数据体对应位置的元素相乘，最后再把乘法的结果加起来，放到输出图像对应的格子中。</p>
<p><img src="/2022/07/11/DLS-note-10/10.jpg" alt></p>
<blockquote>
<p>我认为，把三通道的图像表示成$3 \times 6 \times 6$更好理解一些。这样，输入图像的其实是一个二维图像的数组，$3 \times 3 \times 3$的卷积核其实也是一个$3 \times 3$卷积核的数组。我们把数组中下标一样的图像和卷积核做卷积，最后把所有数组的结果加到一起。</p>
<p>图像是用CHW(通道-高-宽)还是HWC表示，这件事并没有一个定论。似乎TensorFlow是用HWC，PyTorch是用CHW。这门课默认使用的是HWC。</p>
</blockquote>
<p>既然输入都可以是多通道图像了，输出图像是不是也可以有多个通道呢？是的，我们只要用多个卷积核来卷图像，就可以得到一个多通道的图像了。</p>
<p><img src="/2022/07/11/DLS-note-10/11.jpg" alt></p>
<p>总结一下，假如输入图像的形状是$n \times n \times n_c$，卷积核的形状则是$f \times f \times n_c$。注意这个$n_c$必须是同一个数。假如有$n_c’$个卷积核，则输出图像的形状是$(n - f + 1) \times (n - f + 1) \times (n_c’)$。</p>
<blockquote>
<p>在某些框架中，卷积核数量会也会当成卷积核的一个维度，比如可以用$n_c’ \times f \times f \times n_c$来表示一个卷积核组。</p>
</blockquote>
<h2 id="卷积神经网络中的卷积层"><a href="#卷积神经网络中的卷积层" class="headerlink" title="卷积神经网络中的卷积层"></a>卷积神经网络中的卷积层</h2><p>现在，我们已经掌握了卷积的基本知识，让我们来看看卷积神经网络中的卷积层长什么样。</p>
<p>卷积在卷积层中的地位，就和乘法操作在传统神经网络隐藏层中的地位一样。因此，在卷积层中，除了基础的卷积操作外，还有添加偏移量、使用激活函数这两步。注意，每有一个输出通道，就有一个$b$。</p>
<p><img src="/2022/07/11/DLS-note-10/12.jpg" alt></p>
<p>现在，我们可以总结一下一个卷积层中涉及的所有中间变量以及它们的形状了。</p>
<p><img src="/2022/07/11/DLS-note-10/13.jpg" alt></p>
<h2 id="池化层与全连接层"><a href="#池化层与全连接层" class="headerlink" title="池化层与全连接层"></a>池化层与全连接层</h2><p>池化层执行的池化操作和卷积类似，都是拿一个小矩阵盖在图像上，根据被小矩阵盖住的元素来算一个结果。因此，池化也有池化边长$f$和池化步幅$s$这两个参数。而与卷积不同的是，池化是一个没有可学习参数的操作，它的结果完全取决于输入。比如对于最大池化，每一步计算都会算出被覆盖区域的最大值。</p>
<p><img src="/2022/07/11/DLS-note-10/14.jpg" alt></p>
<p>比如上图中，我们令池化边长为2，步幅为2。这样，就等于把一个$4 \times 4$的图像分成了$2 \times 2$个等大的区域。对于每一个区域，我们算一个最大值。</p>
<p>一般情况下，最常用的池化就是这种边长为2，步幅为2的池化。做完该操作后，图像的边长会缩小至原来的$\frac{1}{2}$。</p>
<p>除了最大池化，还有计算区域内所有数平均值的平均池化。但现在几乎只用最大池化，不用平均池化了。</p>
<p>没有人知道池化层究竟为什么这么有用。一种可能的解释是：池化层忽略了细节，保留了关键信息，使后续网络能够只关注之前输出的最值/平均值。</p>
<p>全连接层其实就是我们之前学的经典神经网络中的层。前一层的每一个神经元和后一层的每一个神经元直接都有连接。当然，在把图像喂入全连接层之前，一定别忘了做flatten操作，把图像中所有数据平铺成一个一维向量。</p>
<h2 id="CNN示例"><a href="#CNN示例" class="headerlink" title="CNN示例"></a>CNN示例</h2><p>学完了CNN所有的基础构件，我们或许会感到疑惑：每个卷积层、池化层、全连接层都有那么多超参数，而且层与层之间可以随意地排列组合。该怎么搭建一个CNN呢？不急，让我们来看一个CNN的实例：</p>
<p><img src="/2022/07/11/DLS-note-10/15.jpg" alt></p>
<p>这个网络是经典网络LeNet-5的改进版，它被用于一个10-分类任务。我们会在下周正式学习这个网络。现在，让我们通过概览这个网络来找出一些搭建CNN的规律。</p>
<p>网络按照“卷积-池化-卷积-池化-全连接-全连接-softmax”的顺序执行。通常情况下，CNN都是执行若干次卷积，后面跟一次池化。等所有卷积核池化做完，才会做全连接操作。全连接之后就是由softmax激活的输出层。</p>
<p>另外，图像的形状也有一些规律。在卷积核池化的过程中，图像的边长不断变小，而通道数会不断变大。</p>
<p>下周，我们会继续认识一些经典的CNN架构，这些经典架构能够启发我们，帮助我们更好地搭建自己的CNN。</p>
<h2 id="为什么用卷积？"><a href="#为什么用卷积？" class="headerlink" title="为什么用卷积？"></a>为什么用卷积？</h2><p>这周，我们一直都在讲卷积。而卷积具体有哪些优点呢？</p>
<p>首先，卷积最大的优势就是需要的参数量少。回想这周开头讲的参数量问题。对于图像数据，如果用全连接网络的话，网络的参数会非常多。而卷积的两个性质，使得需要的参数量大大降低。这两个性质是权重共享与稀疏连接。</p>
<p>权重共享：对于输入图像的所有位置来说，卷积核的参数是共享的。这种设计是十分合理的。比如在边缘检测中，只要我们用同样一个<code>[[1, 0, -1], [1, 0, -1]， [1, 0, -1]]</code>的卷积核卷网络，就能检测出垂直方向的边缘。这样，卷积操作的参数量就只由卷积核参数决定，而与图像大小无关。</p>
<p>稀疏连接：卷积核的大小通常很小，也就是卷积操作的一个输出只会由少部分的输入决定。这样，相比一个输出要由所有输入决定的全连接网络，参数量得到进一步的减少。</p>
<p>除了减少参数量外，这两个特性还让网络更加不容易过拟合。回想之前学过的dropout，卷积的这些特性就和扔掉了部分激活输出一样。</p>
<p>另外，卷积操作还适合捕捉平移不变性（translation invariance)。这个词的意思是说，如果一张图里画了一个小猫，如果你把图片往右移动几格，那么图片里还是一个小猫。由于同样的卷积操作会用在所有像素上，这种平移后不变的特性非常容易被CNN捕捉。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>在这堂课中，我们认识了CNN的三大基础构件：卷积、池化、全连接。其中，卷积和池化是新学的知识。这堂课的内容非常多，也非常重要，让我们来回顾一下。</p>
<ul>
<li>CNN 的优点<ul>
<li>CNN 与全连接网络的参数比较</li>
<li>权重共享、稀疏连接</li>
</ul>
</li>
<li>卷积操作<ul>
<li>基本运算流程</li>
<li>填充</li>
<li>步幅</li>
<li>示例：边缘检测</li>
</ul>
</li>
<li>卷积层<ul>
<li>对多通道图像卷积</li>
<li>输出多通道图像</li>
<li>加上bias，送入激活函数</li>
</ul>
</li>
<li>池化层<ul>
<li>运算流程</li>
<li>最大池化与平均池化</li>
</ul>
</li>
<li>CNN 示例<ul>
<li>如何组合不同类别的层：卷积接池化，最后全连接。</li>
<li>图像边长变小，通道数变大。</li>
</ul>
</li>
</ul>
<p>由于深度学习编程框架通常会帮我们实现好卷积，卷积的实现细节倒没有那么重要。在这周的课里，最重要的是一些宏观的知识。我们要知道卷积有哪些参数、哪些超参数，了解卷积的优点。同时，还要知道卷积和其他构件是如何组成一个CNN的。</p>
<p>在这周的编程实战里，我们会用框架（TensorFlow和PyTorch）实现一个简单的CNN，完成图像分类任务。有时间多的话，我还会介绍一下如何用NumPy实现卷积的正向和反向传播。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://zhouyifan.net/2022/07/10/DLS-note-summary-3/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Zhou Yifan">
      <meta itemprop="description" content="A foresighted strategist with big-picture thinking. 大局观选手。">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="周弈帆的博客">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/07/10/DLS-note-summary-3/" class="post-title-link" itemprop="url">吴恩达《深度学习专项》第三阶段总结与第四阶段预览</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-07-10 01:39:41" itemprop="dateCreated datePublished" datetime="2022-07-10T01:39:41+08:00">2022-07-10</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">学习</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E5%AD%A6%E4%B9%A0/%E7%9F%A5%E8%AF%86%E8%AE%B0%E5%BD%95/" itemprop="url" rel="index"><span itemprop="name">知识记录</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="第三阶段回顾"><a href="#第三阶段回顾" class="headerlink" title="第三阶段回顾"></a>第三阶段回顾</h1><p>在过去两周里，我们学习了改进深度学习模型的一些策略。让我们来回顾一下。</p>
<p>首先，我们应该设置好任务的目标。选取开发/测试集时，应参考实际应用中使用的数据分布。设置优化指标时，应使用单一目标。可以设置一个最优化目标和多个满足目标。</p>
<p>在搭建模型时，我们可以根据现有的数据量、问题的难易度，选择端到端学习或者是多阶段学习。</p>
<p>训练模型前，如果有和该任务相似的预训练模型，我们可以采取迁移学习，把其他任务的模型权重搬过来；如果我们的模型要完成多个相似的任务，可以同时训练多个任务的模型。</p>
<p>有了目标，搭好了模型之后，就可以开始训练模型了。有了训练好的模型后，我们可以根据模型的训练误差、训练开发误差、开发误差来诊断模型当前存在的问题。当然，在诊断之前，我们可以先估计一下人类在该问题上的最低误差，以此为贝叶斯误差的一个估计。通过比较贝叶斯误差和训练误差，我们能知道模型是否存在偏差问题；通过比较训练误差和训练开发误差，我们能知道模型是否存在方差问题；通过比较训练开发误差和开发误差，我们能知道模型是否存在数据不匹配问题。</p>
<p>另一方面，如果在改进模型时碰到了问题，不妨采取错误分析技术，看看模型究竟错在哪。我们可以拿出开发集的一个子集，统计一下模型的具体错误样例，看看究竟是模型在某些条件下表现得不好，还是标错的数据太多了。</p>
<p>这些内容可能比较偏向于工程经验，没有过多的数学理论。但是，相信大家在搭建自己的深度学习项目时，这些知识一定能派上用场。</p>
<h1 id="第四阶段预览"><a href="#第四阶段预览" class="headerlink" title="第四阶段预览"></a>第四阶段预览</h1><p>在这之后，我们要分别学习两大类神经网络：处理图像的网络和处理序列数据的网络。在第四门课《卷积神经网络》中，我们就会学习能够处理图像问题的卷积神经网络。一起来看看接下来要学的内容吧。</p>
<p>《卷积神经网络》的课需花四周学完。第一周，我们会学习卷积神经网络的基本构件，建立对卷积神经网络的基本认识，为后续的学习做准备。具体的内容有：</p>
<ul>
<li>卷积操作<ul>
<li>从卷积核到卷积</li>
<li>卷积的属性——填充、步幅</li>
<li>卷积层</li>
</ul>
</li>
<li>池化操作</li>
<li>卷积神经网络示例</li>
</ul>
<p>最简单的计算机视觉任务是图像分类。第二周，我们将学习一系列图像分类网络。这些网络不仅能在图像分类上取得优秀的成绩，还是很多其他计算机视觉任务的基石。通过学习它们，我们不仅能见识一些经典网络的架构，更能从中学习到搭建卷积神经网络的一般规律。其内容有：</p>
<ul>
<li>早期神经网络<ul>
<li>LeNet-5</li>
<li>AlexNet</li>
<li>VGG</li>
</ul>
</li>
<li>残差神经网络</li>
<li>Inception 网络</li>
<li>MobileNet</li>
<li>搭建卷积网络项目<ul>
<li>使用开源代码</li>
<li>迁移学习</li>
<li>数据增强</li>
</ul>
</li>
</ul>
<p>第三周，我们将学习计算机视觉中一个比较热门的任务——目标检测。目标检测要求算法不仅能辨别出图片中的物体，还要能把物体精确地框出来。我们会一步一步学习如何搭建完成目标检测的卷积神经网络：</p>
<ul>
<li>目标定位与关键点检测</li>
<li>使用卷积神经网络的目标检测<ul>
<li>滑动窗口算法</li>
<li>基于卷积的滑动窗口</li>
</ul>
</li>
<li>YOLO 算法<ul>
<li>结合目标定位与滑动窗口</li>
<li>交并比(IoU)</li>
<li>NMS（非极大值抑制）</li>
<li>锚框(Anchor boxes)</li>
</ul>
</li>
<li>R-CNN 系列算法简介</li>
</ul>
<p>此外，这周还会稍微提及另一个计算机视觉任务——语义分割的基本知识：</p>
<ul>
<li>基于U-Net的语义分割<ul>
<li>反卷积</li>
<li>U-Net架构</li>
</ul>
</li>
</ul>
<p>最后一周，第四周，我们又会认识两个新任务：人脸检测与神经网络风格迁移。具体的内容有：</p>
<ul>
<li>人脸检测<ul>
<li>人脸检测问题与一次性学习</li>
<li>孪生神经网络</li>
<li>三元组误差</li>
<li>转化成二分类问题</li>
</ul>
</li>
<li>神经网络风格迁移<ul>
<li>风格迁移简介</li>
<li>利用神经网络学到的东西</li>
<li>风格迁移中的误差</li>
<li>推广到1维和3维</li>
</ul>
</li>
</ul>
<p>相比之前的课，学习第四门课时需要花更多的精力，主要因为以下几点：</p>
<ol>
<li>课程难度变高。</li>
<li>课程的编程练习很多。</li>
<li>课堂上介绍了很多论文作为拓展学习的方向。</li>
</ol>
<p>如果你未来要以计算机视觉为研究方向的话，这四周的内容一定要认真掌握。同时，编程练习和论文阅读也不能落下。据我估计，如果要打好计算机视觉方向上的坚实的基础，至少还要多花费两周时间去认真阅读经典论文，做好相关的技术调研。</p>
<p>在未来的几周里，我仅会上传课堂笔记，并尽最大可能复现一下课后的习题。在所有的五门课上完后（大约2个月后），我会回过头来补充计算机视觉相关的论文阅读笔记、项目实现笔记，对视频课中没来得及讲完的内容查缺补漏，以呈现一套翔实的深度学习学习笔记，辅助大家更好地入门深度学习。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://zhouyifan.net/2022/07/08/20220707-ZeroDCE/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Zhou Yifan">
      <meta itemprop="description" content="A foresighted strategist with big-picture thinking. 大局观选手。">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="周弈帆的博客">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/07/08/20220707-ZeroDCE/" class="post-title-link" itemprop="url">Zero-DCE 论文解读 | 无需参考数据的实时低光照增强算法</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-07-08 00:06:31" itemprop="dateCreated datePublished" datetime="2022-07-08T00:06:31+08:00">2022-07-08</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AE%B0%E5%BD%95/" itemprop="url" rel="index"><span itemprop="name">记录</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AE%B0%E5%BD%95/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/" itemprop="url" rel="index"><span itemprop="name">论文阅读</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>拍照时，我们可能辛辛苦苦地找了个角度，却忘记了调整光线，拍出了黑乎乎的照片：</p>
<p><img src="/2022/07/08/20220707-ZeroDCE/1.jpg" alt></p>
<p>这种情况下，最常见的补救方法是P图。打开PhotoShop，按下”ctrl+m”，就能够打开调整图像亮度的界面：</p>
<p><img src="/2022/07/08/20220707-ZeroDCE/2.jpg" alt></p>
<p>这个界面中间灰色的区域表示图像的亮度分布。坐标轴横轴表示亮度，纵轴表示对应亮度的像素的数量。可以看出，整幅图片非常暗，亮度低的像素占了大多数。</p>
<p>为了提亮图片，我们可以调整中间那条曲线。这条曲线表示如何把某一种亮度映射到另一种亮度上。初始情况下，曲线是$y=x$，也就是不改变原图片的亮度。由于低亮度的像素占比较多，我打算构造一个对低亮度像素进行较大增强，而尽可能保持高亮度像素的曲线。其运行结果如下：</p>
<p><img src="/2022/07/08/20220707-ZeroDCE/3.jpg" alt></p>
<p>嗯，不错。看起来图像确实变亮了不少。但感觉图片看上去还不够自然。有没有一种自动帮我们提亮图像的工具呢？</p>
<p>Zero-DCE就是一个利用深度学习自动调亮图片的算法。让我们看看它的运行结果：</p>
<p><img src="/2022/07/08/20220707-ZeroDCE/4.jpg" alt></p>
<p>哇！这也太强了。除了效果好之外，Zero-DCE还有许多亮点：</p>
<ul>
<li>不需要带标注的数据，甚至不需要参考数据（这里的参考数据指一张暗图对应的亮图）！</li>
<li>训练数据少，训练时间短，只需约30分钟。</li>
<li>推理速度极快。在手机上也能实时运行。</li>
</ul>
<p>让我们来读一下Zero-DCE的论文，看看这个算法是怎么实现的。看完论文后，我还会解读一下官方的PyTorch代码实现。</p>
<h1 id="Zero-DCE-论文解读"><a href="#Zero-DCE-论文解读" class="headerlink" title="Zero-DCE 论文解读"></a>Zero-DCE 论文解读</h1><h2 id="核心思想"><a href="#核心思想" class="headerlink" title="核心思想"></a>核心思想</h2><p>自从CNN（卷积神经网络）火了以后，很多图像问题都可以用CNN来解决：把图像输入进CNN，乱卷一通，最后根据任务的需要，输出分类的概率（图像分类）、检测框和类别（目标检测）或另一幅图像（超分辨率）。</p>
<p>同时，对于输出也是一幅图像的问题，人们会利用GAN（生成对抗网络）能生成图像的特性，尝试用GAN来解决问题。比如在超分辨率任务中，GAN就得到了广泛的使用。</p>
<p>而图像提亮问题恰好就是一个输入、输出都是图像的问题。在此之前，既有基于CNN的方法，也有基于GAN的方法。人们尝试构造更精巧的网络，希望网络能输出亮度更合适的图像。</p>
<p>可是，Zero-DCE别出心裁，返璞归真地用了一种更简单的方式来生成亮度更合适的图像。还记得本文开头提到的，PhotoShop里的那个亮度映射曲线吗？实际上，我们只需要一条简简单单的曲线，把不同亮度的像素映射到一个新的亮度上，就足以产生亮度恰好合适的图像了。Zero-DCE就是用神经网络来拟合一条亮度映射曲线，再根据曲线和原图像生成提亮图像。整个计算过程是可导的，可以轻松地用梯度下降法优化神经网络。</p>
<p>另外，与其他一些任务不同，「亮度」是一个很贴近数学的属性。对于物品的种类、文字的意思这种抽象信息，我们很难用数字来表达。而亮度用一个数字来表示就行了。因此，在图像提亮问题中，我们不一定需要带标签的训练数据，而是可以根据图像本身的某些性质，自动判断出一幅图像是不是“亮度合理”的。</p>
<p>为了让计算机自动判断生成图像的亮度、与原图像的相似度等和图像质量相关的属性，Zero-DCE在训练中使用了一些新颖的误差函数。通过用这些误差函数约束优化过程，算法既能保证生成出来的图片亮度合理，又能保证图片较为真实、贴近原图像。</p>
<p>拟合亮度映射的曲线、不需要标签的误差函数，这两项精巧的设计共同决定了Zero-DCE算法的优势。原论文总结了该工作的三条贡献：</p>
<ol>
<li>这是第一个不需要参考结果的低光照增强网络，直接避免了统计学习中的过拟合问题。算法能够适应不同光照条件下的图片。</li>
<li>该工作设计了一种随输入图像而变的映射曲线。该曲线是高阶的。每个像素有一条单独的曲线。曲线能高效地完成映射过程。</li>
<li>本作的方法表明，在缺乏参考图像时，可以设计一个与任务相关而与参考图像无关的误差，以完成深度图像增强模型的训练。</li>
</ol>
<p>除了学术上的贡献外，算法也十分易用。算法的提亮效果优于其他方法，训练速度和推理速度更是冠绝一方。</p>
<p>接下来，让我们详细探究一下亮度映射曲线、误差函数这两大亮点究竟是怎么设计的。</p>
<h2 id="提亮曲线"><a href="#提亮曲线" class="headerlink" title="提亮曲线"></a>提亮曲线</h2><p>本文使用的亮度映射曲线被称作<strong>提亮曲线(Light-Enhancement Curve, LE-curve)</strong>。设计该曲线时，应满足几个原则：</p>
<ol>
<li>由于亮度值落在区间$[0, 1]$，为保证亮度值的值域不变，曲线在0处值要为0，在1处值要为1。</li>
<li>曲线必须是单调递增的。不然可能会出现图像中原本较亮的地方反而变暗。</li>
<li>曲线公式必须简单，以保证可导。</li>
</ol>
<p>因此，本作使用了如下的公式描述曲线：</p>
<script type="math/tex; mode=display">
LE(I(\mathbf{x}); \alpha)=I(\mathbf{x})+\alpha I(\mathbf{x})(1-I(\mathbf{x}))</script><p>其中，$\mathbf{x}$是像素坐标，$\alpha \in [-1, 1]$是可学习参数，$LE(I(\mathbf{x}); \alpha)$是输入$I(\mathbf{x})$的增强图像（三个颜色通道分别处理）。这个函数非常巧妙，大家可以验证一下它是不是满足刚刚那三条原则。</p>
<p>$\alpha$是公式里唯一一个可变参数。我们来看看不同的$\alpha$能产生怎样的曲线；</p>
<p><img src="/2022/07/08/20220707-ZeroDCE/5.jpg" alt></p>
<p>可以看出，$\alpha$虽然能够上下调节曲线，但由于曲线本质上是一个二次函数，曲线的变化还不够丰富。为了拟合更复杂的曲线，本作<strong>迭代</strong>嵌套了这个函数。也就是说：</p>
<script type="math/tex; mode=display">
\begin{aligned}
LE_1(\mathbf{x})&=I(\mathbf{x})+\alpha_1 I(\mathbf{x})(1-I(\mathbf{x})) \\
LE_2(\mathbf{x})&=LE_1(\mathbf{x})+\alpha_2 LE_1(\mathbf{x})(1-LE_1(\mathbf{x})) \\
......
\end{aligned}</script><p>一般地，</p>
<script type="math/tex; mode=display">
LE_n(\mathbf{x})=LE_{n-1}(\mathbf{x})+\alpha_n LE_{n-1}(\mathbf{x})(1-LE_{n-1}(\mathbf{x})) \\</script><p>迭代嵌套开始那个二次函数，就能够表示一个更高次的函数了。每一轮迭代，都有一个新的参数$\alpha_n$。本作令最大的$n$为8，即调用二次函数8次，拟合某个$2^8$次函数。</p>
<p>但是，我们不希望每个像素都用同样的提亮函数。比如如果图像中某个地方亮着灯，那么这个地方的像素值就不用改变。因此，每个像素应该有独立的$\alpha$。最终的提亮函数为：</p>
<script type="math/tex; mode=display">
LE_n(\mathbf{x})=LE_{n-1}(\mathbf{x})+A_n(\mathbf{x}) LE_{n-1}(\mathbf{x})(1-LE_{n-1}(\mathbf{x}))</script><p>这一改动还是很有必要的。下图显示了某输入图片在不同像素处的$\alpha$的绝对值：</p>
<p><img src="/2022/07/08/20220707-ZeroDCE/6.jpg" alt></p>
<p>可以看出，在较亮的地方，图像没有变化，$\alpha$几乎为0；而在较暗的地方，$\alpha$的数值也较大。</p>
<p>知道了要拟合的目标曲线的公式，下面我们来看看拟合该曲线的神经网络长什么样。</p>
<p><img src="/2022/07/08/20220707-ZeroDCE/7.jpg" alt></p>
<p>由于要拟合的数据不是很复杂，本作使用到的网络DCE-Net非常简单。它一共有7层（6个隐藏层，1个输出层）。所有层都是普通的3x3等长(stride=1)卷积层。为保持相邻像素间的联系，卷积层后不使用Batch Normalization。隐藏层激活函数为ReLU，由于输出落在$[-1, 1]$，输出层的激活函数是tanh。如图所示，6个隐藏层使用了和U-Net类似的对称跳连。3、4层的输出会拼接到一起再送入第5层，2、5层输出拼接送入第6层，1、6层输出拼接送入第7层。经过输出层后，每个像素有24个通道——有RGB 3个颜色通道，每个通道有8个参数。</p>
<blockquote>
<p>似乎开源代码里没有去掉Batch Normalization。</p>
</blockquote>
<p>看完了网络结构与其输出的意义，我们继续看一下误差函数是怎么设置的。</p>
<h2 id="无需参考的误差函数"><a href="#无需参考的误差函数" class="headerlink" title="无需参考的误差函数"></a>无需参考的误差函数</h2><p>为了能不使用参考数据，本作精心设计了四个误差函数，以从不同的角度约束增强后的图像。</p>
<h3 id="空间一致误差-Spatial-Consistency-Loss"><a href="#空间一致误差-Spatial-Consistency-Loss" class="headerlink" title="空间一致误差(Spatial Consistency Loss)"></a>空间一致误差(Spatial Consistency Loss)</h3><p>图像增强后，我们肯定不希望图像的内容发生改变。更准确一点描述，我们不希望某像素的值和其相邻像素的值的差发生过大的改变。因此，我们可以设置下述误差：</p>
<script type="math/tex; mode=display">
L_{spa}=\frac{1}{K}\Sigma_{i=1}^{K}\Sigma_{j\in \Omega(i)}(|Y_i-Y_j|-|I_i-I_j|)^2</script><p>，其中$K$是像素数，$i$是对像素的遍历。$\Omega(i)$是第$i$个像素的4邻域。$Y, I$分别是增强图像和输入图像。</p>
<p>但实际上，我们的要求不必那么苛刻，不用要求每个像素和周围像素的相对值都不改变。在实现中，$i$其实是一个$4 \times 4$的一个“大像素”区域，每个大像素的值是其中所有像素值的平均值。在实现时，大像素可以通过平均池化来求得。因此，上式中的$K$其实指的是大像素的数量，$Y, I$分别是增强图像和输入图像经池化后得到的图像。</p>
<p><img src="/2022/07/08/20220707-ZeroDCE/9.jpg" alt></p>
<h3 id="曝光控制误差-Exposure-Control-Loss"><a href="#曝光控制误差-Exposure-Control-Loss" class="headerlink" title="曝光控制误差(Exposure Control Loss)"></a>曝光控制误差(Exposure Control Loss)</h3><p>为了不让某些地方过暗，某些地方过亮，我们可以让极端亮度更少，即让每个像素的亮度更靠近某个中间值。这个约束可以用如下的误差函数表达：</p>
<script type="math/tex; mode=display">
L_{exp}=\frac{1}{M}\Sigma_{k=1}^{M}|Y_k-E|</script><p>，其中常数$E$描述了亮度的中间值，根据经验可以取0.6。和之前的$Y$类似，这里的$Y$也是一个大像素区域中亮度的平均值。大像素宽度可调，文中使用的宽度是16。$M$是大像素的总个数。</p>
<h3 id="颜色恒定误差-Color-Constancy-Loss"><a href="#颜色恒定误差-Color-Constancy-Loss" class="headerlink" title="颜色恒定误差(Color Constancy Loss)"></a>颜色恒定误差(Color Constancy Loss)</h3><p>根据前人研究中的某些结论，图像某一颜色通道的数值不应显著超出其他通道。因此，有如下误差：</p>
<script type="math/tex; mode=display">
L_{col}=\Sigma_{\forall(p, q)\in\epsilon}(J_p-J_q)^2, \epsilon=\lbrace(R, G), (R, B), (G, B)\rbrace</script><p>，这里，$(p, q)$遍历了三个颜色通道中所有两两组合，$J_p$表示颜色通道$p$的亮度平均值。</p>
<h3 id="光照平滑误差-Illumination-Smoothness-Loss"><a href="#光照平滑误差-Illumination-Smoothness-Loss" class="headerlink" title="光照平滑误差(Illumination Smoothness Loss)"></a>光照平滑误差(Illumination Smoothness Loss)</h3><p>为了保持相邻像素的单调关系，即让相邻像素之间的亮度改变不是那么显著，我们需要让相邻像素间的参数$\alpha \in A$更相近一点。这种要求可以这样表示：</p>
<script type="math/tex; mode=display">
L_{tv_A}=\frac{1}{M}\Sigma_{n=1}^N\Sigma_{c\in \xi}(|\nabla_x A_n^c|+|\nabla_y A_n^c|)^2,\xi=\lbrace R, G, B\rbrace</script><p>，其中，$N$是迭代次数，$\nabla_x, \nabla_y$分别是水平和垂直的梯度算子。对于图像，水平梯度和垂直梯度就是和左方、上方相邻像素之间的数值的差。</p>
<blockquote>
<p>网上公开出来的论文中，这个公式少了一个左绝对值号。</p>
</blockquote>
<h3 id="总误差"><a href="#总误差" class="headerlink" title="总误差"></a>总误差</h3><p>总误差即上述四个误差的加权和：</p>
<script type="math/tex; mode=display">
L_{total}=W_1L_{spa}+W_2L_{exp}+W_3L_{col}+W_4L_{tv_A}</script><blockquote>
<p>理论上，描述4个量的相对加权关系至少要3个权重（默认剩下一个权重为1）。但是，原论文只写了两个权重。而代码里却有3个权重。我认为是论文没写清楚。</p>
</blockquote>
<p>在开源代码中，上述四个权重分别为$W_1=1, W_2=10, W_3=5, W_4=200$。</p>
<p>这四个误差中，有几个误差的作用十分重要。大家可以看看去掉某项误差后，网络的复原效果：</p>
<p><img src="/2022/07/08/20220707-ZeroDCE/8.jpg" alt></p>
<p>去掉$L_{spa}$后，生成出来的图像勉强还行。剩下的误差，哪怕去掉任何一个，生成图像的效果都会很差劲。</p>
<h2 id="Zero-DCE"><a href="#Zero-DCE" class="headerlink" title="Zero-DCE++"></a>Zero-DCE++</h2><p>Zero-DCE是发表在CVPR会议上的。之后，Zero-DCE的拓展版Zero-DCE++发到了TPAMI期刊上。期刊版版面足够，原论文中一些来不及讲清的地方（比如空间一致误差）在期刊版中都有更详尽的说明。大家如果想读论文，建议直接读期刊版本的。论文层层递进，逻辑非常清楚，非常适合从头到尾读一遍。</p>
<p>Zero-DCE++在方法上主要是对性能上进行了一些增强，而没有改进原作的核心思想。拓展点有：</p>
<ol>
<li>和MobileNet类似，把普通卷积替换成更快的逐通道可分卷积(depthwise separable convolution)。</li>
<li>经研究，8次迭代中，每次的参数$\alpha$都差不多。因此，可以让网络只输出3个值，而不是24个值。</li>
<li>由于该任务对图像尺寸不敏感，为了减小卷积开销，可以一开始对图像下采样，最后再上采样回来。</li>
</ol>
<p>经优化后，参数量减少8倍，运算量在一般大小的图像上减少上百倍，训练只需20分钟。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>Zero-DCE是一个简单优美的低光照增强算法。该算法巧妙地建模了光照增强问题，并创造性地使用了和参考数据无关的误差，竟然让基于深度学习的低光照增强算法做到了训练块、性能高、对数据要求低。希望这篇文章用到的思想也能启发其他图像任务。</p>
<p>然而，本文的第一作者在指导我们时说道：“低光图片增强问题要解决两件事：图像去模糊和亮度增强。而Zero-DCE只能完成后者。同时，低光图片的特例也非常多。现在想做一个低光照增强的商业应用是很困难的。”是啊，想让低光照增强落地，用手机瞬间点亮拍暗了的照片，任重而道远啊。</p>
<h1 id="Zero-DCE-开源代码的使用"><a href="#Zero-DCE-开源代码的使用" class="headerlink" title="Zero-DCE 开源代码的使用"></a>Zero-DCE 开源代码的使用</h1><p>代码可以在 <a target="_blank" rel="noopener" href="https://github.com/Li-Chongyi/Zero-DCE">https://github.com/Li-Chongyi/Zero-DCE</a> 里找到。</p>
<p>由于算法没那么复杂，实现所需的代码并不多。同时，这份代码也写得比较工整清楚。整份代码读起来还是非常轻松的。</p>
<h2 id="安装与使用"><a href="#安装与使用" class="headerlink" title="安装与使用"></a>安装与使用</h2><p>直接clone仓库：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git clone git@github.com:Li-Chongyi/Zero-DCE.git</span><br></pre></td></tr></table></figure>
<p>之后，切到内侧的文件夹：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cd Zero-DCE/Zero-DCE_code</span><br></pre></td></tr></table></figure>
<p>直接运行脚本就行了：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python lowlight_test.py </span><br></pre></td></tr></table></figure>
<p>注意！！这份代码对Windows不太友好，有一处路径操作写得不好。在<code>lowlight_test.py</code>这份文件中，有一坨完成<code>os.makedirs()</code>的代码，建议改成：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">dir</span>, fn = os.path.split(result_path)</span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(<span class="built_in">dir</span>):</span><br><span class="line">    os.makedirs(<span class="built_in">dir</span>)</span><br></pre></td></tr></table></figure>
<p>同时，代码用VSCode打开后编辑，会出现莫名其妙的缩进不对齐问题。建议拿个格式化工具修一下。为了编辑这份代码，我不得不把所有缩进重新调了一遍。</p>
<p>这是我跑的一个结果，效果很不错：</p>
<p><img src="/2022/07/08/20220707-ZeroDCE/10.jpg" alt></p>
<h2 id="代码选读"><a href="#代码选读" class="headerlink" title="代码选读"></a>代码选读</h2><p>代码实现中有一些可以讲一讲的地方。</p>
<p>看一下神经网络的实现：</p>
<p><img src="/2022/07/08/20220707-ZeroDCE/11.jpg" alt></p>
<p>整个神经网络部分还是很简明的。</p>
<p>那个求第一个误差空间一致误差<code>L_spa</code>的代码是很炫酷的。让我们忽略掉那个合成大像素的操作，直接看一下这里和相邻像素的差是怎么实现的。</p>
<p>首先，这里定义了一堆“参数”。</p>
<p><img src="/2022/07/08/20220707-ZeroDCE/12.jpg" alt></p>
<p>之后，这些参数被扔进了卷积里，用来卷原图像和增强图像。这是在干什么呢？</p>
<p><img src="/2022/07/08/20220707-ZeroDCE/13.jpg" alt></p>
<p>原来啊，在深度学习时代之前，卷积本来就是图像处理里的一个普普通通的操作。开始那张图定义的不是参数，而是<code>3x3</code>常量卷积核。用那几个卷积核卷积图像，可以得到图像和上下左右之间的差。</p>
<p>这种写法很帅，但是增加了很多计算量。文件里有很多没删干净的代码，不知道是不是本来还有其他设计。</p>
<p>在第四个误差<code>L_TV</code>里，也有一个要算和相邻像素之间的差的梯度计算。这份实现就写得老实多了。</p>
<p><img src="/2022/07/08/20220707-ZeroDCE/14.jpg" alt></p>
<p>这份代码中就是这里有一点难看懂，其他地方都是非常基础的PyTorch调用，非常适合初学者用来学习PyTorch。</p>
<h1 id="彩蛋"><a href="#彩蛋" class="headerlink" title="彩蛋"></a>彩蛋</h1><p>其实我的头像一开始也拍得很暗。我是拿PS把这张照片提亮的。</p>
<p><img src="/2022/07/08/20220707-ZeroDCE/15.jpg" alt></p>
<p>非常凑巧，我在提亮这张照片时，也是用PS里的那个曲线迭代了几次。每次的曲线也恰巧都是一个二次函数。其实现过程和这篇工作如出一辙。</p>
<p>那么，让Zero-DCE来增强这幅图像，能达到怎样的效果呢？</p>
<p><img src="/2022/07/08/20220707-ZeroDCE/15_res.jpg" alt></p>
<p>看来，这个算法还是不太行啊。脸部的光照过于均匀，以至于失去了真实性。头发也白了。比我自己P的差多了。而且，我根本不会用PS，只是随手调了一下，P得也不是很好。AI想战胜人类，还是早了一万年啊。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/5/"><i class="fa fa-angle-left" aria-label="Previous page"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/5/">5</a><span class="page-number current">6</span><a class="page-number" href="/page/7/">7</a><span class="space">&hellip;</span><a class="page-number" href="/page/14/">14</a><a class="extend next" rel="next" href="/page/7/"><i class="fa fa-angle-right" aria-label="Next page"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Zhou Yifan</p>
  <div class="site-description" itemprop="description">A foresighted strategist with big-picture thinking. 大局观选手。</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">136</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">22</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">59</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2024</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Zhou Yifan</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://mist.theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Mist</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

</body>
</html>
